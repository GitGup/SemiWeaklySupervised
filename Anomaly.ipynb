{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a51ad95-8898-4ff8-b34c-32b10200f15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fa34132-ce9d-4c73-b9b8-9c0eb9d473e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# Check if tensorflow is using GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1639fc-28b1-4530-ab19-4114c2f0db3c",
   "metadata": {},
   "source": [
    "Referencing: https://arxiv.org/pdf/2212.11285.pdf\n",
    "\n",
    "We start off by loading in 1,000,000 background dijet events and 100,000 signal dijet events. The signal comes from the process Z$\\rightarrow$ X($\\rightarrow$ $q\\bar{q}$) Y$\\rightarrow$($q\\bar{q}$) where Z is 3.5 TeV. X is 500 GeV and Y is 100 GeV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbf36cb3-02cc-487b-85a7-4fbf5ee16d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_QCD = pd.read_hdf(\"/global/cfs/projectdirs/m3246/AnomalyDetection/LHCO/events_anomalydetection_DelphesPythia8_v2_qcd_features.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9cf47ae-311d-4c6e-b8c8-7208364ed33d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pxj1</th>\n",
       "      <th>pyj1</th>\n",
       "      <th>pzj1</th>\n",
       "      <th>mj1</th>\n",
       "      <th>tau1j1</th>\n",
       "      <th>tau2j1</th>\n",
       "      <th>tau3j1</th>\n",
       "      <th>pxj2</th>\n",
       "      <th>pyj2</th>\n",
       "      <th>pzj2</th>\n",
       "      <th>mj2</th>\n",
       "      <th>tau1j2</th>\n",
       "      <th>tau2j2</th>\n",
       "      <th>tau3j2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1467.239990</td>\n",
       "      <td>611.502014</td>\n",
       "      <td>511.101990</td>\n",
       "      <td>38.896000</td>\n",
       "      <td>8.290650</td>\n",
       "      <td>4.836080</td>\n",
       "      <td>4.260190</td>\n",
       "      <td>1403.579956</td>\n",
       "      <td>-674.551025</td>\n",
       "      <td>-451.670990</td>\n",
       "      <td>237.893997</td>\n",
       "      <td>79.815102</td>\n",
       "      <td>21.010300</td>\n",
       "      <td>16.757601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1211.239990</td>\n",
       "      <td>347.315002</td>\n",
       "      <td>547.963013</td>\n",
       "      <td>389.532013</td>\n",
       "      <td>191.804001</td>\n",
       "      <td>99.562798</td>\n",
       "      <td>70.872200</td>\n",
       "      <td>619.341003</td>\n",
       "      <td>-62.177299</td>\n",
       "      <td>-1944.040039</td>\n",
       "      <td>22.999201</td>\n",
       "      <td>8.042180</td>\n",
       "      <td>6.335090</td>\n",
       "      <td>5.525370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1229.619995</td>\n",
       "      <td>649.857971</td>\n",
       "      <td>8.089170</td>\n",
       "      <td>72.155502</td>\n",
       "      <td>47.168098</td>\n",
       "      <td>37.243198</td>\n",
       "      <td>33.658199</td>\n",
       "      <td>1196.250000</td>\n",
       "      <td>-647.896973</td>\n",
       "      <td>-1283.109985</td>\n",
       "      <td>78.230698</td>\n",
       "      <td>15.292900</td>\n",
       "      <td>13.944200</td>\n",
       "      <td>10.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-693.304016</td>\n",
       "      <td>-1046.729980</td>\n",
       "      <td>1716.910034</td>\n",
       "      <td>55.797798</td>\n",
       "      <td>24.788500</td>\n",
       "      <td>6.890140</td>\n",
       "      <td>5.813400</td>\n",
       "      <td>747.961975</td>\n",
       "      <td>994.250000</td>\n",
       "      <td>-412.966003</td>\n",
       "      <td>359.113007</td>\n",
       "      <td>175.209000</td>\n",
       "      <td>103.500999</td>\n",
       "      <td>84.447098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1488.199951</td>\n",
       "      <td>-25.370100</td>\n",
       "      <td>-30.989700</td>\n",
       "      <td>84.891502</td>\n",
       "      <td>26.878799</td>\n",
       "      <td>15.517200</td>\n",
       "      <td>13.260400</td>\n",
       "      <td>1415.640015</td>\n",
       "      <td>20.905100</td>\n",
       "      <td>223.630997</td>\n",
       "      <td>77.506500</td>\n",
       "      <td>57.986000</td>\n",
       "      <td>34.147400</td>\n",
       "      <td>26.660601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999994</th>\n",
       "      <td>-646.442017</td>\n",
       "      <td>-1295.150024</td>\n",
       "      <td>1331.800049</td>\n",
       "      <td>37.011299</td>\n",
       "      <td>21.006800</td>\n",
       "      <td>12.873700</td>\n",
       "      <td>8.898860</td>\n",
       "      <td>274.566986</td>\n",
       "      <td>1019.390015</td>\n",
       "      <td>-504.290985</td>\n",
       "      <td>90.375000</td>\n",
       "      <td>61.218800</td>\n",
       "      <td>20.514500</td>\n",
       "      <td>15.854600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>-286.550995</td>\n",
       "      <td>-1310.829956</td>\n",
       "      <td>-1510.910034</td>\n",
       "      <td>147.516998</td>\n",
       "      <td>60.997799</td>\n",
       "      <td>41.356201</td>\n",
       "      <td>28.225700</td>\n",
       "      <td>252.884995</td>\n",
       "      <td>1085.420044</td>\n",
       "      <td>759.314026</td>\n",
       "      <td>58.769901</td>\n",
       "      <td>42.276402</td>\n",
       "      <td>8.637120</td>\n",
       "      <td>7.852020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>918.562988</td>\n",
       "      <td>951.195984</td>\n",
       "      <td>-1622.569946</td>\n",
       "      <td>32.242199</td>\n",
       "      <td>5.894110</td>\n",
       "      <td>5.004100</td>\n",
       "      <td>3.992740</td>\n",
       "      <td>-266.285004</td>\n",
       "      <td>-1284.189941</td>\n",
       "      <td>185.007996</td>\n",
       "      <td>136.389008</td>\n",
       "      <td>70.623901</td>\n",
       "      <td>49.508499</td>\n",
       "      <td>40.708599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1447.219971</td>\n",
       "      <td>-547.710999</td>\n",
       "      <td>827.945007</td>\n",
       "      <td>396.112000</td>\n",
       "      <td>181.406998</td>\n",
       "      <td>152.207993</td>\n",
       "      <td>86.676804</td>\n",
       "      <td>-932.369995</td>\n",
       "      <td>165.005005</td>\n",
       "      <td>-2806.959961</td>\n",
       "      <td>56.471600</td>\n",
       "      <td>14.446400</td>\n",
       "      <td>10.258900</td>\n",
       "      <td>8.874700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>200.035995</td>\n",
       "      <td>-1252.869995</td>\n",
       "      <td>27.924900</td>\n",
       "      <td>363.790985</td>\n",
       "      <td>139.281998</td>\n",
       "      <td>31.751499</td>\n",
       "      <td>22.884300</td>\n",
       "      <td>-583.494995</td>\n",
       "      <td>1096.890015</td>\n",
       "      <td>-1194.410034</td>\n",
       "      <td>105.186996</td>\n",
       "      <td>36.687000</td>\n",
       "      <td>23.652201</td>\n",
       "      <td>19.462601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999999 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pxj1         pyj1         pzj1         mj1      tau1j1  \\\n",
       "0      -1467.239990   611.502014   511.101990   38.896000    8.290650   \n",
       "1      -1211.239990   347.315002   547.963013  389.532013  191.804001   \n",
       "2      -1229.619995   649.857971     8.089170   72.155502   47.168098   \n",
       "3       -693.304016 -1046.729980  1716.910034   55.797798   24.788500   \n",
       "4      -1488.199951   -25.370100   -30.989700   84.891502   26.878799   \n",
       "...             ...          ...          ...         ...         ...   \n",
       "999994  -646.442017 -1295.150024  1331.800049   37.011299   21.006800   \n",
       "999995  -286.550995 -1310.829956 -1510.910034  147.516998   60.997799   \n",
       "999996   918.562988   951.195984 -1622.569946   32.242199    5.894110   \n",
       "999997  1447.219971  -547.710999   827.945007  396.112000  181.406998   \n",
       "999998   200.035995 -1252.869995    27.924900  363.790985  139.281998   \n",
       "\n",
       "            tau2j1     tau3j1         pxj2         pyj2         pzj2  \\\n",
       "0         4.836080   4.260190  1403.579956  -674.551025  -451.670990   \n",
       "1        99.562798  70.872200   619.341003   -62.177299 -1944.040039   \n",
       "2        37.243198  33.658199  1196.250000  -647.896973 -1283.109985   \n",
       "3         6.890140   5.813400   747.961975   994.250000  -412.966003   \n",
       "4        15.517200  13.260400  1415.640015    20.905100   223.630997   \n",
       "...            ...        ...          ...          ...          ...   \n",
       "999994   12.873700   8.898860   274.566986  1019.390015  -504.290985   \n",
       "999995   41.356201  28.225700   252.884995  1085.420044   759.314026   \n",
       "999996    5.004100   3.992740  -266.285004 -1284.189941   185.007996   \n",
       "999997  152.207993  86.676804  -932.369995   165.005005 -2806.959961   \n",
       "999998   31.751499  22.884300  -583.494995  1096.890015 -1194.410034   \n",
       "\n",
       "               mj2      tau1j2      tau2j2     tau3j2  \n",
       "0       237.893997   79.815102   21.010300  16.757601  \n",
       "1        22.999201    8.042180    6.335090   5.525370  \n",
       "2        78.230698   15.292900   13.944200  10.013500  \n",
       "3       359.113007  175.209000  103.500999  84.447098  \n",
       "4        77.506500   57.986000   34.147400  26.660601  \n",
       "...            ...         ...         ...        ...  \n",
       "999994   90.375000   61.218800   20.514500  15.854600  \n",
       "999995   58.769901   42.276402    8.637120   7.852020  \n",
       "999996  136.389008   70.623901   49.508499  40.708599  \n",
       "999997   56.471600   14.446400   10.258900   8.874700  \n",
       "999998  105.186996   36.687000   23.652201  19.462601  \n",
       "\n",
       "[999999 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_QCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01c26fcc-24e2-401e-8f60-c71c168529d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"/global/cfs/projectdirs/m3246/AnomalyDetection/LHCO/events_anomalydetection_DelphesPythia8_v2_Wprime_features.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "874a6f00-dd55-49a1-a8b0-f80267d5ff3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pxj1</th>\n",
       "      <th>pyj1</th>\n",
       "      <th>pzj1</th>\n",
       "      <th>mj1</th>\n",
       "      <th>tau1j1</th>\n",
       "      <th>tau2j1</th>\n",
       "      <th>tau3j1</th>\n",
       "      <th>pxj2</th>\n",
       "      <th>pyj2</th>\n",
       "      <th>pzj2</th>\n",
       "      <th>mj2</th>\n",
       "      <th>tau1j2</th>\n",
       "      <th>tau2j2</th>\n",
       "      <th>tau3j2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1698.670044</td>\n",
       "      <td>-884.039978</td>\n",
       "      <td>723.843018</td>\n",
       "      <td>105.035004</td>\n",
       "      <td>83.721703</td>\n",
       "      <td>46.282101</td>\n",
       "      <td>13.635700</td>\n",
       "      <td>1539.439941</td>\n",
       "      <td>372.238007</td>\n",
       "      <td>-295.865997</td>\n",
       "      <td>461.574005</td>\n",
       "      <td>431.343994</td>\n",
       "      <td>52.344799</td>\n",
       "      <td>37.284901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1246.660034</td>\n",
       "      <td>-1133.010010</td>\n",
       "      <td>-921.987000</td>\n",
       "      <td>159.865997</td>\n",
       "      <td>133.781998</td>\n",
       "      <td>58.968601</td>\n",
       "      <td>30.377399</td>\n",
       "      <td>-1218.489990</td>\n",
       "      <td>1108.380005</td>\n",
       "      <td>182.147003</td>\n",
       "      <td>514.883972</td>\n",
       "      <td>462.654999</td>\n",
       "      <td>138.789001</td>\n",
       "      <td>67.805801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420.975006</td>\n",
       "      <td>-1739.790039</td>\n",
       "      <td>281.553986</td>\n",
       "      <td>93.665901</td>\n",
       "      <td>77.925797</td>\n",
       "      <td>10.605900</td>\n",
       "      <td>6.916520</td>\n",
       "      <td>-510.779999</td>\n",
       "      <td>1484.069946</td>\n",
       "      <td>227.175995</td>\n",
       "      <td>475.316986</td>\n",
       "      <td>217.113998</td>\n",
       "      <td>29.424000</td>\n",
       "      <td>21.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161.048996</td>\n",
       "      <td>-1664.859985</td>\n",
       "      <td>-2005.099976</td>\n",
       "      <td>116.327003</td>\n",
       "      <td>61.819698</td>\n",
       "      <td>38.143600</td>\n",
       "      <td>18.414400</td>\n",
       "      <td>-188.942993</td>\n",
       "      <td>1556.900024</td>\n",
       "      <td>-561.664001</td>\n",
       "      <td>561.236023</td>\n",
       "      <td>348.181000</td>\n",
       "      <td>102.625000</td>\n",
       "      <td>53.422699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-564.754028</td>\n",
       "      <td>-1315.599976</td>\n",
       "      <td>-1087.410034</td>\n",
       "      <td>513.015991</td>\n",
       "      <td>276.446991</td>\n",
       "      <td>50.629799</td>\n",
       "      <td>35.460999</td>\n",
       "      <td>326.164001</td>\n",
       "      <td>1050.239990</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>108.752998</td>\n",
       "      <td>89.666603</td>\n",
       "      <td>40.928699</td>\n",
       "      <td>17.055799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>-206.662003</td>\n",
       "      <td>-1729.280029</td>\n",
       "      <td>357.635010</td>\n",
       "      <td>96.165001</td>\n",
       "      <td>58.014500</td>\n",
       "      <td>11.731300</td>\n",
       "      <td>6.174070</td>\n",
       "      <td>218.800003</td>\n",
       "      <td>1714.890015</td>\n",
       "      <td>-210.578995</td>\n",
       "      <td>472.475006</td>\n",
       "      <td>259.884003</td>\n",
       "      <td>40.806999</td>\n",
       "      <td>31.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1069.660034</td>\n",
       "      <td>659.874023</td>\n",
       "      <td>218.751007</td>\n",
       "      <td>126.183998</td>\n",
       "      <td>122.486000</td>\n",
       "      <td>27.608700</td>\n",
       "      <td>17.924801</td>\n",
       "      <td>-956.169006</td>\n",
       "      <td>-297.311005</td>\n",
       "      <td>-2204.350098</td>\n",
       "      <td>108.890999</td>\n",
       "      <td>21.177200</td>\n",
       "      <td>10.582400</td>\n",
       "      <td>9.138590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>-1286.619995</td>\n",
       "      <td>-86.162598</td>\n",
       "      <td>-1366.270020</td>\n",
       "      <td>115.719002</td>\n",
       "      <td>109.853996</td>\n",
       "      <td>29.830200</td>\n",
       "      <td>22.489201</td>\n",
       "      <td>1145.729980</td>\n",
       "      <td>136.792007</td>\n",
       "      <td>1216.780029</td>\n",
       "      <td>489.053009</td>\n",
       "      <td>416.747009</td>\n",
       "      <td>84.599998</td>\n",
       "      <td>66.767502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>-149.330002</td>\n",
       "      <td>1781.459961</td>\n",
       "      <td>-58.690899</td>\n",
       "      <td>508.045013</td>\n",
       "      <td>495.290985</td>\n",
       "      <td>82.283600</td>\n",
       "      <td>43.567902</td>\n",
       "      <td>84.726601</td>\n",
       "      <td>-1378.569946</td>\n",
       "      <td>-1485.469971</td>\n",
       "      <td>91.104897</td>\n",
       "      <td>79.120102</td>\n",
       "      <td>46.537300</td>\n",
       "      <td>23.227301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1584.699951</td>\n",
       "      <td>-731.156982</td>\n",
       "      <td>-196.348007</td>\n",
       "      <td>114.938004</td>\n",
       "      <td>83.769897</td>\n",
       "      <td>12.898200</td>\n",
       "      <td>9.031230</td>\n",
       "      <td>-1515.079956</td>\n",
       "      <td>783.245972</td>\n",
       "      <td>498.704010</td>\n",
       "      <td>553.737000</td>\n",
       "      <td>366.188995</td>\n",
       "      <td>192.139008</td>\n",
       "      <td>81.398201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99999 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pxj1         pyj1         pzj1         mj1      tau1j1  \\\n",
       "0     -1698.670044  -884.039978   723.843018  105.035004   83.721703   \n",
       "1      1246.660034 -1133.010010  -921.987000  159.865997  133.781998   \n",
       "2       420.975006 -1739.790039   281.553986   93.665901   77.925797   \n",
       "3       161.048996 -1664.859985 -2005.099976  116.327003   61.819698   \n",
       "4      -564.754028 -1315.599976 -1087.410034  513.015991  276.446991   \n",
       "...            ...          ...          ...         ...         ...   \n",
       "99994  -206.662003 -1729.280029   357.635010   96.165001   58.014500   \n",
       "99995  1069.660034   659.874023   218.751007  126.183998  122.486000   \n",
       "99996 -1286.619995   -86.162598 -1366.270020  115.719002  109.853996   \n",
       "99997  -149.330002  1781.459961   -58.690899  508.045013  495.290985   \n",
       "99998  1584.699951  -731.156982  -196.348007  114.938004   83.769897   \n",
       "\n",
       "          tau2j1     tau3j1         pxj2         pyj2         pzj2  \\\n",
       "0      46.282101  13.635700  1539.439941   372.238007  -295.865997   \n",
       "1      58.968601  30.377399 -1218.489990  1108.380005   182.147003   \n",
       "2      10.605900   6.916520  -510.779999  1484.069946   227.175995   \n",
       "3      38.143600  18.414400  -188.942993  1556.900024  -561.664001   \n",
       "4      50.629799  35.460999   326.164001  1050.239990  1201.000000   \n",
       "...          ...        ...          ...          ...          ...   \n",
       "99994  11.731300   6.174070   218.800003  1714.890015  -210.578995   \n",
       "99995  27.608700  17.924801  -956.169006  -297.311005 -2204.350098   \n",
       "99996  29.830200  22.489201  1145.729980   136.792007  1216.780029   \n",
       "99997  82.283600  43.567902    84.726601 -1378.569946 -1485.469971   \n",
       "99998  12.898200   9.031230 -1515.079956   783.245972   498.704010   \n",
       "\n",
       "              mj2      tau1j2      tau2j2     tau3j2  \n",
       "0      461.574005  431.343994   52.344799  37.284901  \n",
       "1      514.883972  462.654999  138.789001  67.805801  \n",
       "2      475.316986  217.113998   29.424000  21.020300  \n",
       "3      561.236023  348.181000  102.625000  53.422699  \n",
       "4      108.752998   89.666603   40.928699  17.055799  \n",
       "...           ...         ...         ...        ...  \n",
       "99994  472.475006  259.884003   40.806999  31.226000  \n",
       "99995  108.890999   21.177200   10.582400   9.138590  \n",
       "99996  489.053009  416.747009   84.599998  66.767502  \n",
       "99997   91.104897   79.120102   46.537300  23.227301  \n",
       "99998  553.737000  366.188995  192.139008  81.398201  \n",
       "\n",
       "[99999 rows x 14 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b3adbce-25f0-4389-a115-e694802d94cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Jet Mass Distributions')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['mj1'],bins=np.linspace(0,600,20))\n",
    "plt.xlabel(\"Mass [GeV]\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Jet Mass Distributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "472adaa6-938f-4e12-ae2e-cdbe211d0815",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 J 1788.55 -0.300279 -2.51608 130.279 0 0.0289343 0.0153102 0.0126833 0.010346 0.00825964  P 4.64413 -0.377384 3.00207  P 2.47947 -0.425799 3.02334  P 2.68613 -0.39458 -2.608  P 5.84707 -0.404504 -2.54133  P 24.9416 -0.408844 -2.52053  P 6.58412 -0.387347 -2.54543  P 13.1517 -0.350432 -2.59254  P 13.7381 -0.300859 -2.52212  P 4.55674 -0.286343 -2.52545  P 517.142 -0.286492 -2.50205 \n",
      "\n",
      "0 1 J 1643.32 -0.173344 0.717105 95.8961 0 0.0424313 0.0221081 0.0140335 0.0108518 0.00877299  P 1.75001 -0.530883 0.585762  P 2.74298 -0.297844 0.694373  P 5.4756 -0.195946 0.630677  P 7.35714 -0.200437 0.647468  P 9.16487 -0.119969 0.704896  P 5.77878 -0.125155 0.709119  P 6.37682 -0.141306 0.773328  P 8.23397 -0.155549 0.732862  P 29.6409 -0.186092 0.763671  P 2.24246 -0.170876 0.729569  P 245.519 -0.180535 0.735561 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"/global/cfs/projectdirs/m3246/AnomalyDetection/ILC/Delphes-3.5.0/LHCO_RnD_qq/LHCO_RnD_qq.txt\")\n",
    "\n",
    "jets = []\n",
    "count = 0\n",
    "for line in file:\n",
    "    if count == 2:\n",
    "        break\n",
    "    print(line)\n",
    "    jets += [line.split(\"J\")[1].split(\"P\")[0].split()]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d84ddc16-9bdb-4964-882d-f8db41e4f5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1788.55',\n",
       "  '-0.300279',\n",
       "  '-2.51608',\n",
       "  '130.279',\n",
       "  '0',\n",
       "  '0.0289343',\n",
       "  '0.0153102',\n",
       "  '0.0126833',\n",
       "  '0.010346',\n",
       "  '0.00825964'],\n",
       " ['1643.32',\n",
       "  '-0.173344',\n",
       "  '0.717105',\n",
       "  '95.8961',\n",
       "  '0',\n",
       "  '0.0424313',\n",
       "  '0.0221081',\n",
       "  '0.0140335',\n",
       "  '0.0108518',\n",
       "  '0.00877299']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74e751ad-3731-4908-a40e-3d53afa0d19a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ljet = [jets[2*n] for n in range(int(len(jets)/2))]\n",
    "sjet = [jets[2*n+1] for n in range(int(len(jets)/2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec57e185-b108-4d49-8a6e-9d602a0b1a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1788.55',\n",
       "  '-0.300279',\n",
       "  '-2.51608',\n",
       "  '130.279',\n",
       "  '0',\n",
       "  '0.0289343',\n",
       "  '0.0153102',\n",
       "  '0.0126833',\n",
       "  '0.010346',\n",
       "  '0.00825964']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ljet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a256173c-6db9-488e-917a-f5e89ae59167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computemjj_pd(event):\n",
    "    px1 = event[[\"pxj1\"]].to_numpy()\n",
    "    py1 = event[[\"pyj1\"]].to_numpy()\n",
    "    pz1 = event[[\"pzj1\"]].to_numpy()\n",
    "    pE1 = np.sqrt(px1**2+py1**2+pz1**2+event[[\"mj1\"]].to_numpy()**2)\n",
    "    \n",
    "    px2 = event[[\"pxj2\"]].to_numpy()\n",
    "    py2 = event[[\"pyj2\"]].to_numpy()\n",
    "    pz2 = event[[\"pzj2\"]].to_numpy()\n",
    "    pE2 = np.sqrt(px1**2+py1**2+pz1**2+event[[\"mj2\"]].to_numpy()**2)\n",
    "    \n",
    "    m2 = (pE1+pE2)**2-(px1+px2)**2-(py1+py2)**2-(pz1+pz2)**2\n",
    "    return np.array(np.sqrt(m2)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd77cfaa-083f-472c-b291-3050fb718da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computemjj_txt(event):\n",
    "    pT1 = np.array([float(event[2*i][0]) for i in range(int(len(event)/2))])\n",
    "    eta1 = np.array([float(event[2*i][1]) for i in range(int(len(event)/2))])\n",
    "    phi1 = np.array([float(event[2*i][2]) for i in range(int(len(event)/2))])\n",
    "    m1 = np.array([float(event[2*i][3]) for i in range(int(len(event)/2))])\n",
    "    px1 = pT1*np.cos(phi1)\n",
    "    py1 = pT1*np.sin(phi1)\n",
    "    pz1 = pT1*np.sinh(eta1)\n",
    "    pE1 = np.sqrt(px1**2+py1**2+pz1**2+m1**2)\n",
    "    \n",
    "    pT2 = np.array([float(event[2*i+1][0]) for i in range(int(len(event)/2))])\n",
    "    eta2 = np.array([float(event[2*i+1][1]) for i in range(int(len(event)/2))])\n",
    "    phi2 = np.array([float(event[2*i+1][2]) for i in range(int(len(event)/2))])\n",
    "    m2 = np.array([float(event[2*i+1][3]) for i in range(int(len(event)/2))])\n",
    "    px2 = pT2*np.cos(phi2)\n",
    "    py2 = pT2*np.sin(phi2)\n",
    "    pz2 = pT2*np.sinh(eta2)\n",
    "    pE2 = np.sqrt(px2**2+py2**2+pz2**2+m2**2)\n",
    "    \n",
    "    m2 = (pE1+pE2)**2-(px1+px2)**2-(py1+py2)**2-(pz1+pz2)**2\n",
    "    return np.array(np.sqrt(m2)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6ae4f16-8096-43cf-8e19-9983f63bc64f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3674.182176987098"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 100\n",
    "file = open(\"/global/cfs/projectdirs/m3246/AnomalyDetection/ILC/Delphes-3.5.0/LHCO_RnD_qq/LHCO_RnD_qq_\"+str(m)+\"_\"+str(m)+\".txt\")\n",
    "jets_m_m = []\n",
    "for line in file:\n",
    "    jets_m_m+=[line.split(\"J\")[1].split(\"P\")[0].split()]\n",
    "    pass\n",
    "computemjj_txt(jets_m_m)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b973cdf7-fd7f-453a-a3e8-d5c93560f393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180286"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jets_m_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c5dc45-f8c3-4ac7-afab-dfea17f527bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mass_range = [0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6]\n",
    "if (False):\n",
    "    lmass_vec = {}\n",
    "    x = {}\n",
    "    mjjs = {}\n",
    "\n",
    "    mu_m = 0.\n",
    "    mu_t = 0.\n",
    "    sd_m = 0.\n",
    "    sd_t = 0.\n",
    "\n",
    "    for m1 in mass_range:\n",
    "        for m2 in mass_range:\n",
    "\n",
    "            print(\"on ...\",m1,m2)\n",
    "\n",
    "            ltau1_m_m = []\n",
    "            ltau2_m_m = []\n",
    "            stau1_m_m = []\n",
    "            stau2_m_m = []\n",
    "            if (m1>0 and m2>0):\n",
    "                myfile = open(\"/global/cfs/projectdirs/m3246/AnomalyDetection/ILC/Delphes-3.5.0/LHCO_RnD_qq/LHCO_RnD_qq_\"+str(int(m1*100))+\"_\"+str(int(100*m2))+\".txt\")\n",
    "                jets_m_m = []\n",
    "                for line in myfile:\n",
    "                    jets_m_m+=[line.split(\"J\")[1].split(\"P\")[0].split()]\n",
    "                    pass\n",
    "                ljet_m_m = [jets_m_m[2*n] for n in range(int(len(jets_m_m)/2))]\n",
    "                sjet_m_m = [jets_m_m[2*n+1] for n in range(int(len(jets_m_m)/2))]\n",
    "\n",
    "                lmass_m_m = np.array([float(ljet_m_m[i][3]) for i in range(len(ljet_m_m))])/1000.\n",
    "                smass_m_m = np.array([float(sjet_m_m[i][3]) for i in range(len(sjet_m_m))])/1000.\n",
    "\n",
    "                ltau1_m_m = np.array([float(ljet_m_m[i][5]) for i in range(len(ljet_m_m))])\n",
    "                ltau2_m_m = np.array([float(ljet_m_m[i][6]) for i in range(len(ljet_m_m))])\n",
    "\n",
    "                stau1_m_m = np.array([float(sjet_m_m[i][5]) for i in range(len(ljet_m_m))])\n",
    "                stau2_m_m = np.array([float(sjet_m_m[i][6]) for i in range(len(ljet_m_m))])\n",
    "\n",
    "                mjj = computemjj_txt(jets_m_m)/1000.\n",
    "                mjjs[m1,m2] = mjj\n",
    "                passcut = (mjj > 3.3) * (mjj < 3.7)\n",
    "                lmass_m_m = lmass_m_m[passcut]\n",
    "                smass_m_m = smass_m_m[passcut]\n",
    "                ltau1_m_m = ltau1_m_m[passcut]\n",
    "                ltau2_m_m = ltau2_m_m[passcut]\n",
    "                stau1_m_m = stau1_m_m[passcut]\n",
    "                stau2_m_m = stau2_m_m[passcut]\n",
    "                pass\n",
    "            elif m1==0 and m2==0:\n",
    "                df_QCD = pd.read_hdf(\"/global/cfs/projectdirs/m3246/AnomalyDetection/LHCO/events_anomalydetection_DelphesPythia8_v2_qcd_features.h5\")\n",
    "                lmass_m_m = np.array(df_QCD[[\"mj1\"]]).flatten()/1000.\n",
    "                smass_m_m = np.array(df_QCD[[\"mj2\"]]).flatten()/1000.\n",
    "                ltau1_m_m = np.array(df_QCD[[\"tau1j1\"]]).flatten()\n",
    "                ltau2_m_m = np.array(df_QCD[[\"tau2j1\"]]).flatten()\n",
    "                stau1_m_m = np.array(df_QCD[[\"tau1j2\"]]).flatten()\n",
    "                stau2_m_m = np.array(df_QCD[[\"tau2j2\"]]).flatten()\n",
    "                mjj = computemjj_pd(df_QCD)/1000.\n",
    "                mjjs[m1,m2] = mjj\n",
    "                passcut = (mjj > 3.3) * (mjj < 3.7)\n",
    "                lmass_m_m = lmass_m_m[passcut]\n",
    "                smass_m_m = smass_m_m[passcut]\n",
    "                ltau1_m_m = ltau1_m_m[passcut]\n",
    "                ltau2_m_m = ltau2_m_m[passcut]\n",
    "                stau1_m_m = stau1_m_m[passcut]\n",
    "                stau2_m_m = stau2_m_m[passcut]\n",
    "\n",
    "                mu_m = np.mean(lmass_m_m)\n",
    "                mu_t = np.mean(ltau2_m_m/(ltau1_m_m+0.0001))\n",
    "                sd_m = np.std(lmass_m_m)\n",
    "                sd_t = np.std(ltau2_m_m/(ltau1_m_m+0.0001))\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            ms = np.stack([lmass_m_m,smass_m_m],axis=1)\n",
    "            ts = np.stack([ltau2_m_m/(ltau1_m_m+0.0001),stau2_m_m/(stau1_m_m+0.001)],axis=1)\n",
    "            order1 = [np.argmax(ms[i]) for i in range(len(ms))]\n",
    "            order2 = [np.argmin(ms[i]) for i in range(len(ms))]\n",
    "            mJ1 = np.array([ms[i][order1[i]] for i in range(len(ms))])\n",
    "            mJ2 = np.array([ms[i][order2[i]] for i in range(len(ms))])\n",
    "            x[m1,m2] = np.stack([(mJ2 - mu_m)/sd_m,\n",
    "                                    ((mJ1 - mJ2) - mu_m)/sd_m,\n",
    "                                    ([ts[i][order2[i]] for i in range(len(ts))] - mu_t)/sd_t,\n",
    "                                    ([ts[i][order1[i]] for i in range(len(ts))] - mu_t)/sd_t],axis=1)\n",
    "            lmass_vec[m1,m2]=lmass_m_m\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "    x_array = []\n",
    "    for m1 in mass_range:\n",
    "        for m2 in mass_range:\n",
    "            if (m1==0 and m2>0 or m2==0 and m1>0):\n",
    "                continue\n",
    "            x_array+=[x[m1,m2]]\n",
    "    np.save(\"x_array\", x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e4d3043-90b8-492d-8c1a-1b45ec3a8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in data \n",
    "x = {}\n",
    "x_array_read = np.load(\"x_array.npy\",allow_pickle=True)\n",
    "mycounter = -1\n",
    "for m1 in mass_range:\n",
    "    for m2 in mass_range:\n",
    "        if (m1==0 and m2>0 or m2==0 and m1>0):\n",
    "            continue\n",
    "        mycounter+=1\n",
    "        x[m1,m2] = x_array_read[mycounter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e982c79c-ebc9-4330-ba3f-020a3d9c4a48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.08511704, -0.13951411,  0.29623825, -1.38625319],\n",
       "       [-0.99621376, -0.3906208 ,  1.87209617, -1.20087092],\n",
       "       [-1.10503705,  1.30397829,  1.37879233, -0.51460752],\n",
       "       ...,\n",
       "       [-0.8137767 , -0.68498134, -0.48486568, -1.80944097],\n",
       "       [-0.60554108, -0.3927861 ,  1.66516101, -0.46855806],\n",
       "       [-1.03992653,  0.32502271,  1.51100575, -1.56040698]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8695136e-87e9-46ff-8c38-24504ca2a192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_vals_100 = np.concatenate([x[0,0],x[1,1]])\n",
    "y_vals_100 = np.concatenate([np.zeros(len(x[0,0])),np.ones(len(x[1,1]))])\n",
    "X_train_100, X_val_100, Y_train_100, Y_val_100 = train_test_split(x_vals_100, y_vals_100, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9dd69b8d-2704-4bcd-a3f4-4cac42859ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.08511704, -0.13951411,  0.29623825, -1.38625319],\n",
       "       [-0.99621376, -0.3906208 ,  1.87209617, -1.20087092],\n",
       "       [-1.10503705,  1.30397829,  1.37879233, -0.51460752],\n",
       "       ...,\n",
       "       [-0.72849452, -1.20127827, -1.46586875, -0.17525045],\n",
       "       [-0.71564546, -1.27923195, -1.13014702,  0.1427768 ],\n",
       "       [-0.69956274, -1.30933612, -0.96529716, -0.55303517]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d37fda62-a40a-4b64-a02f-8668a9bddeac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgup-singh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gup-singh/Anomaly/runs/2d7tbm98\" target=\"_blank\">vital-bush-41</a></strong> to <a href=\"https://wandb.ai/gup-singh/Anomaly\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initializies wandb config\n",
    "if not wandb.run:\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"Anomaly\",\n",
    "        group=\"Dedicated\",\n",
    "        entity='gup-singh',\n",
    "\n",
    "        config={\n",
    "            \"layer_1\": 256,\n",
    "            \"activation_1\": \"relu\",\n",
    "            \"layer_2\": 256,\n",
    "            \"activation_2\": \"relu\",\n",
    "            \"layer_3\": 256,\n",
    "            \"activation_3\": \"relu\",\n",
    "            \"output_layer\": 1,\n",
    "            \"output_activation\": \"sigmoid\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"metric\": \"accuracy\",\n",
    "            \"epoch\": 20,\n",
    "            \"batch_size\": 1024\n",
    "        }\n",
    "    )\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e648787-8408-4c0f-be9a-31f0d1b2181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        config = wandb.config\n",
    "        self.dense1 = Dense(config.layer_1, activation=config.activation_1)\n",
    "        \n",
    "        self.dense2 = Dense(config.layer_2, activation=config.activation_2)\n",
    "        \n",
    "        self.dense3 = Dense(config.layer_3, activation=config.activation_3)\n",
    "        \n",
    "        self.dense4 = Dense(config.output_layer, activation=config.output_activation)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        x = self.dense4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38640130-1c28-4ed7-9862-77aaa2f58a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  1280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,121\n",
      "Trainable params: 133,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 12:44:20.543131: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 12:44:21.540238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15495 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:c3:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.build(input_shape=(None, X_train_100.shape[1]))\n",
    "model.compile(loss=config.loss, optimizer=config.optimizer, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865c4829-8a9b-4ecd-b563-7380a0240867",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 60/193 [========>.....................] - ETA: 0s - loss: 0.3233 - accuracy: 0.8690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 12:44:24.861565: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/193 [==========================>...] - ETA: 0s - loss: 0.2487 - accuracy: 0.8995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 2s 6ms/step - loss: 0.2443 - accuracy: 0.9014 - val_loss: 0.1867 - val_accuracy: 0.9259\n",
      "Epoch 2/20\n",
      "173/193 [=========================>....] - ETA: 0s - loss: 0.1821 - accuracy: 0.9267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1815 - accuracy: 0.9271 - val_loss: 0.1830 - val_accuracy: 0.9262\n",
      "Epoch 3/20\n",
      "162/193 [========================>.....] - ETA: 0s - loss: 0.1797 - accuracy: 0.9273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 6ms/step - loss: 0.1794 - accuracy: 0.9277 - val_loss: 0.1788 - val_accuracy: 0.9281\n",
      "Epoch 4/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9283 - val_loss: 0.1791 - val_accuracy: 0.9278\n",
      "Epoch 5/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9281 - val_loss: 0.1818 - val_accuracy: 0.9261\n",
      "Epoch 6/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9288 - val_loss: 0.1816 - val_accuracy: 0.9269\n",
      "Epoch 7/20\n",
      "176/193 [==========================>...] - ETA: 0s - loss: 0.1775 - accuracy: 0.9284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1776 - accuracy: 0.9284 - val_loss: 0.1775 - val_accuracy: 0.9284\n",
      "Epoch 8/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.9289 - val_loss: 0.1781 - val_accuracy: 0.9279\n",
      "Epoch 9/20\n",
      "165/193 [========================>.....] - ETA: 0s - loss: 0.1756 - accuracy: 0.9293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1762 - accuracy: 0.9291 - val_loss: 0.1769 - val_accuracy: 0.9285\n",
      "Epoch 10/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9292 - val_loss: 0.1772 - val_accuracy: 0.9282\n",
      "Epoch 11/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9294 - val_loss: 0.1806 - val_accuracy: 0.9273\n",
      "Epoch 12/20\n",
      "171/193 [=========================>....] - ETA: 0s - loss: 0.1757 - accuracy: 0.9292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1757 - accuracy: 0.9290 - val_loss: 0.1756 - val_accuracy: 0.9288\n",
      "Epoch 13/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9289 - val_loss: 0.1771 - val_accuracy: 0.9283\n",
      "Epoch 14/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9293 - val_loss: 0.1767 - val_accuracy: 0.9285\n",
      "Epoch 15/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.9293 - val_loss: 0.1764 - val_accuracy: 0.9288\n",
      "Epoch 16/20\n",
      "176/193 [==========================>...] - ETA: 0s - loss: 0.1747 - accuracy: 0.9294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1747 - accuracy: 0.9293 - val_loss: 0.1755 - val_accuracy: 0.9285\n",
      "Epoch 17/20\n",
      "168/193 [=========================>....] - ETA: 0s - loss: 0.1739 - accuracy: 0.9296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1745 - accuracy: 0.9293 - val_loss: 0.1751 - val_accuracy: 0.9294\n",
      "Epoch 18/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9294 - val_loss: 0.1769 - val_accuracy: 0.9286\n",
      "Epoch 19/20\n",
      "165/193 [========================>.....] - ETA: 0s - loss: 0.1740 - accuracy: 0.9294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124419-2d7tbm98/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1736 - accuracy: 0.9296 - val_loss: 0.1747 - val_accuracy: 0.9291\n",
      "Epoch 20/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9301 - val_loss: 0.1749 - val_accuracy: 0.9293\n"
     ]
    }
   ],
   "source": [
    "myhistory = model.fit(x_vals_100, y_vals_100, epochs=config.epoch, validation_data=(X_val_100, Y_val_100),batch_size=config.batch_size, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6aa950c-4790-466d-8f3f-867da3a0a19d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▅▅▁▃▆▅▆▆▄▇▆▆▇▆█▆▇█</td></tr><tr><td>val_loss</td><td>█▆▃▄▅▅▃▃▂▂▄▂▂▂▂▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.93007</td></tr><tr><td>best_epoch</td><td>18</td></tr><tr><td>best_val_loss</td><td>0.17475</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.1737</td></tr><tr><td>val_accuracy</td><td>0.92929</td></tr><tr><td>val_loss</td><td>0.17486</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vital-bush-41</strong>: <a href=\"https://wandb.ai/gup-singh/Anomaly/runs/2d7tbm98\" target=\"_blank\">https://wandb.ai/gup-singh/Anomaly/runs/2d7tbm98</a><br/>Synced 5 W&B file(s), 1 media file(s), 28 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230925_124419-2d7tbm98/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303cf48d-50d6-4203-bff5-dfd452387b24",
   "metadata": {},
   "source": [
    "Analysis of Models begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "40b790d6-6abd-49d2-b7e3-0bcc38935d69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhsUlEQVR4nO3deXwTZeI/8E+S5uiZXtADCuWSSygItAKiqJWCyqEghyiHirsKuGzFBX4KRVm/HHYRtVhPwBtEgXVRQVopi1iOpXIjAgIFelGg95E0md8f06QNPdMmmaT9vF+veTWZPDN5pmnph+camSAIAoiIiIhaEbnUFSAiIiJyNAYgIiIianUYgIiIiKjVYQAiIiKiVocBiIiIiFodBiAiIiJqdRiAiIiIqNVhACIiIqJWhwGIiIiIWh0GICJyWTKZDEuXLrX6uIsXL0Imk2HDhg02rxMRuQYGICJqlg0bNkAmk0Emk+GXX36p8bogCAgLC4NMJsPDDz8sQQ2bLiUlBTKZDN98843UVSEiG2MAIiKb0Gg0+PLLL2vs37NnD65cuQK1Wi1BrYiIascAREQ28eCDD2Lz5s2oqKiw2P/ll19iwIABCA4OlqhmREQ1MQARkU1MmTIF169fx65du8z7dDodvvnmGzz++OO1HlNcXIwXX3wRYWFhUKvV6N69O+Lj4yEIgkW58vJy/P3vf0ebNm3g7e2NMWPG4MqVK7We8+rVq3jqqacQFBQEtVqN3r17Y926dba70Fr8+eefeOyxx+Dv7w8PDw/ceeed+P7772uUe+edd9C7d294eHjAz88PAwcOtGg1KywsxLx58xAeHg61Wo22bdvigQceQFpaml3rT9QaMQARkU2Eh4dj8ODB+Oqrr8z7fvzxR+Tn52Py5Mk1yguCgDFjxuDNN9/EyJEjsXr1anTv3h0vvfQSYmNjLco+88wzWLNmDUaMGIEVK1ZAqVTioYceqnHO7Oxs3HnnnUhKSsKcOXPw1ltvoWvXrnj66aexZs0am1+z6T2HDBmCnTt34vnnn8frr7+OsrIyjBkzBlu3bjWX+/DDD/HCCy+gV69eWLNmDV599VX069cPBw4cMJf561//isTERIwfPx7vvvsu5s+fD3d3d5w+fdoudSdq1QQiomZYv369AEA4dOiQkJCQIHh7ewslJSWCIAjCY489Jtx7772CIAhCx44dhYceesh83LZt2wQAwj//+U+L802YMEGQyWTCuXPnBEEQhCNHjggAhOeff96i3OOPPy4AEOLi4sz7nn76aSEkJETIzc21KDt58mRBq9Wa63XhwgUBgLB+/fp6r2337t0CAGHz5s11lpk3b54AQNi7d695X2FhodCpUychPDxcMBgMgiAIwtixY4XevXvX+35arVaYPXt2vWWIyDbYAkRENjNx4kSUlpZi+/btKCwsxPbt2+vs/vrhhx+gUCjwwgsvWOx/8cUXIQgCfvzxR3M5ADXKzZs3z+K5IAj49ttvMXr0aAiCgNzcXPMWExOD/Px8u3Ql/fDDD4iMjMRdd91l3ufl5YVnn30WFy9exKlTpwAAvr6+uHLlCg4dOlTnuXx9fXHgwAFkZGTYvJ5EZIkBiIhspk2bNoiOjsaXX36JLVu2wGAwYMKECbWWvXTpEkJDQ+Ht7W2xv2fPnubXTV/lcjm6dOliUa579+4Wz69du4a8vDx88MEHaNOmjcU2c+ZMAEBOTo5NrvPW67i1LrVdx4IFC+Dl5YXIyEh069YNs2fPxr59+yyOWbVqFU6cOIGwsDBERkZi6dKl+PPPP21eZyIC3KSuABG1LI8//jhmzZqFrKwsjBo1Cr6+vg55X6PRCAB44oknMH369FrL9O3b1yF1qU3Pnj1x5swZbN++HTt27MC3336Ld999F0uWLMGrr74KQGxBGzZsGLZu3YqffvoJb7zxBlauXIktW7Zg1KhRktWdqCViCxAR2dQjjzwCuVyO/fv319n9BQAdO3ZERkYGCgsLLfb//vvv5tdNX41GI86fP29R7syZMxbPTTPEDAYDoqOja93atm1ri0uscR231qW26wAAT09PTJo0CevXr0d6ejoeeugh86Bpk5CQEDz//PPYtm0bLly4gICAALz++us2rzdRa8cAREQ25eXlhcTERCxduhSjR4+us9yDDz4Ig8GAhIQEi/1vvvkmZDKZucXD9PXtt9+2KHfrrC6FQoHx48fj22+/xYkTJ2q837Vr15pyOQ168MEHcfDgQaSmppr3FRcX44MPPkB4eDh69eoFALh+/brFcSqVCr169YIgCNDr9TAYDMjPz7co07ZtW4SGhqK8vNwudSdqzdgFRkQ2V1cXVHWjR4/Gvffei5dffhkXL15EREQEfvrpJ/z73//GvHnzzGN++vXrhylTpuDdd99Ffn4+hgwZguTkZJw7d67GOVesWIHdu3cjKioKs2bNQq9evXDjxg2kpaUhKSkJN27caNL1fPvtt+YWnVuvc+HChfjqq68watQovPDCC/D398cnn3yCCxcu4Ntvv4VcLv4/c8SIEQgODsbQoUMRFBSE06dPIyEhAQ899BC8vb2Rl5eH9u3bY8KECYiIiICXlxeSkpJw6NAh/Otf/2pSvYmoHtJOQiMiV1d9Gnx9bp0GLwjidPG///3vQmhoqKBUKoVu3boJb7zxhmA0Gi3KlZaWCi+88IIQEBAgeHp6CqNHjxYuX75cYxq8IAhCdna2MHv2bCEsLExQKpVCcHCwcP/99wsffPCBuYy10+Dr2kxT38+fPy9MmDBB8PX1FTQajRAZGSls377d4lzvv/++cPfddwsBAQGCWq0WunTpIrz00ktCfn6+IAiCUF5eLrz00ktCRESE4O3tLXh6egoRERHCu+++W28diahpZIJwy5KrRERERC0cxwARERFRq8MARERERK0OAxARERG1OgxARERE1OowABEREVGrwwBERERErQ4XQqyF0WhERkYGvL29IZPJpK4OERERNYIgCCgsLERoaKh5EdK6MADVIiMjA2FhYVJXg4iIiJrg8uXLaN++fb1lGIBq4e3tDUD8Bvr4+EhcGyIiImqMgoIChIWFmf+O14cBqBambi8fHx8GICIiIhfTmOErHARNRERErQ4DEBEREbU6DEBERETU6nAMEBEROTWDwQC9Xi91NcgJKJVKKBQKm5yLAYiIiJySIAjIyspCXl6e1FUhJ+Lr64vg4OBmr9PHAERERE7JFH7atm0LDw8PLkzbygmCgJKSEuTk5AAAQkJCmnU+BiAiInI6BoPBHH4CAgKkrg45CXd3dwBATk4O2rZt26zuMA6CJiIip2Ma8+Ph4SFxTcjZmH4mmjsujAGIiIicFru96Fa2+plgACIiIqJWhwGIiIjIiYWHh2PNmjWNLp+SkgKZTGb32XMbNmyAr6+vXd/DnjgImoiIyIaGDx+Ofv36WRVa6nPo0CF4eno2uvyQIUOQmZkJrVZrk/dvqRiAHEhXYcT14nIYBaCdr7vU1SEiIokIggCDwQA3t4b/DLdp08aqc6tUKgQHBze1aq0Gu8AcaOtvVzB4+c94eetxqatCRER2MGPGDOzZswdvvfUWZDIZZDIZLl68aO6W+vHHHzFgwACo1Wr88ssvOH/+PMaOHYugoCB4eXlh0KBBSEpKsjjnrV1gMpkMH330ER555BF4eHigW7du+O6778yv39oFZuqq2rlzJ3r27AkvLy+MHDkSmZmZ5mMqKirwwgsvwNfXFwEBAViwYAGmT5+OcePGWXX9iYmJ6NKlC1QqFbp3747PPvvM/JogCFi6dCk6dOgAtVqN0NBQvPDCC+bX3333XXTr1g0ajQZBQUGYMGGCVe9tLQYgB/L3VAMAbhTrJK4JEZHrEQQBJboKSTZBEBpVx7feeguDBw/GrFmzkJmZiczMTISFhZlfX7hwIVasWIHTp0+jb9++KCoqwoMPPojk5GT89ttvGDlyJEaPHo309PR63+fVV1/FxIkTcezYMTz44IOYOnUqbty4UWf5kpISxMfH47PPPsN///tfpKenY/78+ebXV65ciS+++ALr16/Hvn37UFBQgG3btjXqmk22bt2Kv/3tb3jxxRdx4sQJ/OUvf8HMmTOxe/duAMC3336LN998E++//z7Onj2Lbdu2oU+fPgCA//3vf3jhhRfw2muv4cyZM9ixYwfuvvtuq97fWuwCcyB/TxUA4HoRAxARkbVK9Qb0WrJTkvc+9VoMPFQN/8nUarVQqVTw8PCotRvqtddewwMPPGB+7u/vj4iICPPzZcuWYevWrfjuu+8wZ86cOt9nxowZmDJlCgDg//7v//D222/j4MGDGDlyZK3l9Xo93nvvPXTp0gUAMGfOHLz22mvm19955x0sWrQIjzzyCAAgISEBP/zwQ4PXW118fDxmzJiB559/HgAQGxuL/fv3Iz4+Hvfeey/S09MRHByM6OhoKJVKdOjQAZGRkQCA9PR0eHp64uGHH4a3tzc6duyI/v37W/X+1mILkAMFVAagmyUMQERErdHAgQMtnhcVFWH+/Pno2bMnfH194eXlhdOnTzfYAtS3b1/zY09PT/j4+JhvEVEbDw8Pc/gBxNtImMrn5+cjOzvbHEYAQKFQYMCAAVZd2+nTpzF06FCLfUOHDsXp06cBAI899hhKS0vRuXNnzJo1C1u3bkVFRQUA4IEHHkDHjh3RuXNnPPnkk/jiiy9QUlJi1ftbiy1ADuTvJQagEp0BZXoDNErb3NGWiKg1cFcqcOq1GMne2xZunc01f/587Nq1C/Hx8ejatSvc3d0xYcIE6HT1/0dZqVRaPJfJZDAajVaVb2y3nq2EhYXhzJkzSEpKwq5du/D888/jjTfewJ49e+Dt7Y20tDSkpKTgp59+wpIlS7B06VIcOnTIblPt2QLkQN5qNygV4gqW1zkOiIjIKjKZDB4qN0k2a1YfVqlUMBgMjSq7b98+zJgxA4888gj69OmD4OBgXLx4sYnfoabRarUICgrCoUOHzPsMBgPS0tKsOk/Pnj2xb98+i3379u1Dr169zM/d3d0xevRovP3220hJSUFqaiqOHxcnBrm5uSE6OhqrVq3CsWPHcPHiRfz888/NuLL6sQXIgWQyGfw9VcguKMeNIh2nwhMRtUDh4eE4cOAALl68CC8vL/j7+9dZtlu3btiyZQtGjx4NmUyGxYsX19uSYy9z587F8uXL0bVrV/To0QPvvPMObt68aVXwe+mllzBx4kT0798f0dHR+M9//oMtW7aYZ7Vt2LABBoMBUVFR8PDwwOeffw53d3d07NgR27dvx59//om7774bfn5++OGHH2A0GtG9e3d7XTJbgBzNNBPsenG5xDUhIiJ7mD9/PhQKBXr16oU2bdrUO55n9erV8PPzw5AhQzB69GjExMTgjjvucGBtRQsWLMCUKVMwbdo0DB48GF5eXoiJiYFGo2n0OcaNG4e33noL8fHx6N27N95//32sX78ew4cPBwD4+vriww8/xNChQ9G3b18kJSXhP//5DwICAuDr64stW7bgvvvuQ8+ePfHee+/hq6++Qu/eve10xYBMcHQnoAsoKCiAVqtFfn4+fHx8bHruJz46gF/O5WL1xAg8ekd7m56biKilKCsrw4ULF9CpUyer/giTbRiNRvTs2RMTJ07EsmXLpK6Ohfp+Nqz5+80uMAczTYXnWkBEROQsLl26hJ9++gn33HMPysvLkZCQgAsXLuDxxx+Xump2wy4wBzOvBcQARERETkIul2PDhg0YNGgQhg4diuPHjyMpKQk9e/aUump2wxYgBzOtBXSDiyESEZGTCAsLqzGDq6VjC5CDmdYCYgsQERGRdBiAHMzcAsRZYERERJJhAHIwPw8OgiYiIpIaA5CDBbALjIiISHIMQA5mWgixsKwCugrHr/ZJREREDEAO5+uuhLxyZXHeFZ6IiEgaDEAOJpfLzOOArnMqPBER3WL48OGYN2+e+Xl4eDjWrFlT7zEymQzbtm1r9nvb6jyuwCkC0Nq1axEeHg6NRoOoqCgcPHiwzrIffvghhg0bBj8/P/j5+SE6Orre8n/9618hk8ka/OFxJK4GTUTUMo0ePRojR46s9bW9e/dCJpPh2LFjVp3z0KFDePbZZ21RPbOlS5eiX79+NfZnZmZi1KhRNn0vZyV5ANq0aRNiY2MRFxeHtLQ0REREICYmBjk5ObWWT0lJwZQpU7B7926kpqYiLCwMI0aMwNWrV2uU3bp1K/bv34/Q0FB7X4ZVqlaD5lR4IqKW5Omnn8auXbtw5cqVGq+tX78eAwcORN++fa06Z5s2beDh4WGrKtYrODgYarXaIe8lNckD0OrVqzFr1izMnDkTvXr1wnvvvQcPDw+sW7eu1vJffPEFnn/+efTr1w89evTARx99BKPRiOTkZItyV69exdy5c/HFF19AqVQ64lIazTQTjC1AREQty8MPP4w2bdpgw4YNFvuLioqwefNmjBs3DlOmTEG7du3g4eGBPn364Kuvvqr3nLd2gZ09exZ33303NBoNevXqhV27dtU4ZsGCBbjtttvg4eGBzp07Y/HixdDr9QCADRs24NVXX8XRo0chk8kgk8nM9b21C+z48eO477774O7ujoCAADz77LMoKioyvz5jxgyMGzcO8fHxCAkJQUBAAGbPnm1+L2cm6a0wdDodDh8+jEWLFpn3yeVyREdHIzU1tVHnKCkpgV6vh7+/v3mf0WjEk08+iZdeegm9e/e2eb2bi11gRERNIAiAvkSa91Z6ADJZg8Xc3Nwwbdo0bNiwAS+//DJklcds3rwZBoMBTzzxBDZv3owFCxbAx8cH33//PZ588kl06dIFkZGRDZ7faDTi0UcfRVBQEA4cOID8/HyL8UIm3t7e2LBhA0JDQ3H8+HHMmjUL3t7e+Mc//oFJkybhxIkT2LFjB5KSkgAAWq22xjmKi4sRExODwYMH49ChQ8jJycEzzzyDOXPmWAS83bt3IyQkBLt378a5c+cwadIk9OvXD7NmzWrweqQkaQDKzc2FwWBAUFCQxf6goCD8/vvvjTrHggULEBoaiujoaPO+lStXws3NDS+88EKjzlFeXo7y8qruqIKCgkYd11SmqfBcC4iIyAr6EuD/JBrS8P8yAJVno4o+9dRTeOONN7Bnzx4MHz4cgNj9NX78eHTs2BHz5883l507dy527tyJr7/+ulEBKCkpCb///jt27txpHt7xf//3fzXG7bzyyivmx+Hh4Zg/fz42btyIf/zjH3B3d4eXlxfc3NwQHBxc53t9+eWXKCsrw6effgpPT/HaExISMHr0aKxcudL8t9vPzw8JCQlQKBTo0aMHHnroISQnJzt9AJK8C6w5VqxYgY0bN2Lr1q3QaDQAgMOHD+Ott97Chg0bzMm7IcuXL4dWqzVvYWFh9qy2+XYYNxmAiIhanB49emDIkCHmoRznzp3D3r178fTTT8NgMGDZsmXo06cP/P394eXlhZ07dyI9Pb1R5z59+jTCwsIsxrYOHjy4RrlNmzZh6NChCA4OhpeXF1555ZVGv0f194qIiDCHHwAYOnQojEYjzpw5Y97Xu3dvKBQK8/OQkJA6x/E6E0lbgAIDA6FQKJCdnW2xPzs7u95UCgDx8fFYsWIFkpKSLAaU7d27Fzk5OejQoYN5n8FgwIsvvog1a9bg4sWLNc61aNEixMbGmp8XFBTYNQRVDYJmACIiajSlh9gSI9V7W+Hpp5/G3LlzsXbtWqxfvx5dunTBPffcg5UrV+Ktt97CmjVr0KdPH3h6emLevHnQ6Wz39yA1NRVTp07Fq6++ipiYGGi1WmzcuBH/+te/bPYe1d06zlYmk8FodP6FfiUNQCqVCgMGDEBycjLGjRsHAOYBzXPmzKnzuFWrVuH111/Hzp07MXDgQIvXnnzySYvuMACIiYnBk08+iZkzZ9Z6PrVa7dBR7wEcA0REZD2ZrNHdUFKbOHEi/va3v+HLL7/Ep59+iueeew4ymQz79u3D2LFj8cQTTwAQ/+b98ccf6NWrV6PO27NnT1y+fBmZmZkICQkBAOzfv9+izK+//oqOHTvi5ZdfNu+7dOmSRRmVSgWDwdDge23YsAHFxcXmVqB9+/ZBLpeje/fujaqvM5O8Cyw2NhYffvghPvnkE5w+fRrPPfcciouLzWFl2rRpFoOkV65cicWLF2PdunUIDw9HVlYWsrKyzKPSAwICcPvtt1tsSqUSwcHBTvOB+XMWGBFRi+bl5YVJkyZh0aJFyMzMxIwZMwAA3bp1w65du/Drr7/i9OnT+Mtf/lKjF6Q+0dHRuO222zB9+nQcPXoUe/futQg6pvdIT0/Hxo0bcf78ebz99tvYunWrRZnw8HBcuHABR44cQW5ursU4WJOpU6dCo9Fg+vTpOHHiBHbv3o25c+fiySefrDF21xVJHoAmTZqE+Ph4LFmyBP369cORI0ewY8cO8zc3PT0dmZmZ5vKJiYnQ6XSYMGECQkJCzFt8fLxUl2A1UxfYzRIdDEZB4toQEZE9PP3007h58yZiYmLMY3ZeeeUV3HHHHYiJicHw4cMRHBxs7gFpDLlcjq1bt6K0tBSRkZF45pln8Prrr1uUGTNmDP7+979jzpw56NevH3799VcsXrzYosz48eMxcuRI3HvvvWjTpk2tU/E9PDywc+dO3LhxA4MGDcKECRNw//33IyEhwfpvhhOSCYLAv8C3KCgogFarRX5+Pnx8fGx+fr3BiG4v/wgAOPxKNAK8WseiU0REjVVWVoYLFy6gU6dO5kkuRED9PxvW/P2WvAWoNVIq5NC6i4PG2A1GRETkeAxAEgngTDAiIiLJMABJhKtBExERSYcBSCJcC4iIiEg6DEASMbcAFTEAERHVhfN06Fa2+plgAJJIVRdYzbUXiIhaO9PqwiUlEt38lJyW6Wfi1hWorSXpStCtGbvAiIjqplAo4Ovra76nlIeHR6Pv70gtkyAIKCkpQU5ODnx9fS3uP9YUDEASCeBq0ERE9TLdE9IVbqxJjuPr69vg/UIbgwFIIv6e4uKHDEBERLWTyWQICQlB27Ztodfrpa4OOQGlUtnslh8TBiCJcB0gIqLGUSgUNvujR2TCQdASMd8PrFjHWQ5EREQOxgAkEVMAqjAKKCitkLg2RERErQsDkEQ0SgU8VWKT7nVOhSciInIoBiAJ+XMmGBERkSQYgCTEmWBERETSYACSUABviEpERCQJBiAJcTVoIiIiaTAASYgtQERERNJgAJKQPwMQERGRJBiAJMQuMCIiImkwAEmo6oaoXAeIiIjIkRiAJGSeBl/EFiAiIiJHYgCSUPUbovJ+YERERI7DACQh0xig8gojSnQGiWtDRETUejAASchDpYDKTfwIOBOMiIjIcRiAJCSTySy6wYiIiMgxGIAkVrUWEGeCEREROQoDkMTMawFxJhgREZHDMABJjLfDICIicjwGIImZ1wJiACIiInIYBiCJmVaD5iBoIiIix2EAkhhviEpEROR4DEAS4w1RiYiIHI8BSGIBnAZPRETkcAxAEjO1AN0s1ktcEyIiotaDAUhiAZWzwIrKK1BewfuBEREROYJTBKC1a9ciPDwcGo0GUVFROHjwYJ1lP/zwQwwbNgx+fn7w8/NDdHR0jfJLly5Fjx494OnpaS5z4MABe19Gk/i4u8FNLgPAgdBERESOInkA2rRpE2JjYxEXF4e0tDREREQgJiYGOTk5tZZPSUnBlClTsHv3bqSmpiIsLAwjRozA1atXzWVuu+02JCQk4Pjx4/jll18QHh6OESNG4Nq1a466rEaTyWTw42rQREREDiUTBEGQsgJRUVEYNGgQEhISAABGoxFhYWGYO3cuFi5c2ODxBoMBfn5+SEhIwLRp02otU1BQAK1Wi6SkJNx///0NntNUPj8/Hz4+PtZdUBOMXPNf/J5ViE+fisTdt7Wx+/sRERG1RNb8/Za0BUin0+Hw4cOIjo4275PL5YiOjkZqamqjzlFSUgK9Xg9/f/863+ODDz6AVqtFRERErWXKy8tRUFBgsTkS1wIiIiJyLEkDUG5uLgwGA4KCgiz2BwUFISsrq1HnWLBgAUJDQy1CFABs374dXl5e0Gg0ePPNN7Fr1y4EBgbWeo7ly5dDq9Wat7CwsKZdUBNxLSAiIiLHknwMUHOsWLECGzduxNatW6HRaCxeu/fee3HkyBH8+uuvGDlyJCZOnFjnuKJFixYhPz/fvF2+fNkR1TfjWkBERESOJWkACgwMhEKhQHZ2tsX+7OxsBAcH13tsfHw8VqxYgZ9++gl9+/at8bqnpye6du2KO++8Ex9//DHc3Nzw8ccf13outVoNHx8fi82ReENUIiIix5I0AKlUKgwYMADJycnmfUajEcnJyRg8eHCdx61atQrLli3Djh07MHDgwEa9l9FoRHm5c7aw+HtxFhgREZEjuUldgdjYWEyfPh0DBw5EZGQk1qxZg+LiYsycORMAMG3aNLRr1w7Lly8HAKxcuRJLlizBl19+ifDwcPNYIS8vL3h5eaG4uBivv/46xowZg5CQEOTm5mLt2rW4evUqHnvsMcmusz4BHARNRETkUJIHoEmTJuHatWtYsmQJsrKy0K9fP+zYscM8MDo9PR1yeVVDVWJiInQ6HSZMmGBxnri4OCxduhQKhQK///47PvnkE+Tm5iIgIACDBg3C3r170bt3b4deW2P5eTAAEREROZLk6wA5I0evA/RHdiFGvPlfaN2VOBo3wu7vR0RE1BK5zDpAJDJNg88v1UNvMEpcGyIiopaPAcgJ+HmoIBNvB4abJewGIyIisjcGICegkMvg664EwHFAREREjsAA5CTMt8PgVHgiIiK7YwByEgGViyHydhhERET2xwDkJHhDVCIiIsdhAHIS5tWgGYCIiIjsjgHISfCGqERERI7DAOQkTF1gN4v1EteEiIio5WMAchKmAHSdLUBERER2xwDkJEyzwDgImoiIyP4YgJwEZ4ERERE5DgOQkwionAV2s0QPo5H3pyUiIrInBiAn4echBiCDUUB+KQdCExER2RMDkJNQucnhrXEDwLWAiIiI7I0ByIkEcBwQERGRQzAAORF/LoZIRETkEAxATsSfN0QlIiJyCAYgJ+LvqQQA3ChiACIiIrInBiAnwhYgIiIix2AAciIcBE1EROQYDEBOhKtBExEROQYDkBPx9zLdEJUBiIiIyJ4YgJxIAKfBExEROQQDkBOp3gUmCLwfGBERkb0wADmRgMpZYHqDgMLyColrQ0RE1HIxADkRd5UC7koFAK4FREREZE8MQE7G1A3GgdBERET2wwDkZAIqZ4LdZAAiIiKyGwYgJ8O1gIiIiOyPAcjJsAuMiIjI/hiAnAzXAiIiIrI/BiAnwxuiEhER2R8DkJPhDVGJiIjsjwHIyXAQNBERkf05RQBau3YtwsPDodFoEBUVhYMHD9ZZ9sMPP8SwYcPg5+cHPz8/REdHW5TX6/VYsGAB+vTpA09PT4SGhmLatGnIyMhwxKU0m/mGqFwIkYiIyG4kD0CbNm1CbGws4uLikJaWhoiICMTExCAnJ6fW8ikpKZgyZQp2796N1NRUhIWFYcSIEbh69SoAoKSkBGlpaVi8eDHS0tKwZcsWnDlzBmPGjHHkZTUZu8CIiIjsTyZIfNfNqKgoDBo0CAkJCQAAo9GIsLAwzJ07FwsXLmzweIPBAD8/PyQkJGDatGm1ljl06BAiIyNx6dIldOjQocFzFhQUQKvVIj8/Hz4+PtZdUDMVlunRZ+lPAIDTr42Eu0rh0PcnIiJyVdb8/Za0BUin0+Hw4cOIjo4275PL5YiOjkZqamqjzlFSUgK9Xg9/f/86y+Tn50Mmk8HX17fW18vLy1FQUGCxScVL7QalQgYAuM6p8ERERHYhaQDKzc2FwWBAUFCQxf6goCBkZWU16hwLFixAaGioRYiqrqysDAsWLMCUKVPqTIPLly+HVqs1b2FhYdZdiA3JZDIOhCYiIrIzyccANceKFSuwceNGbN26FRqNpsbrer0eEydOhCAISExMrPM8ixYtQn5+vnm7fPmyPavdIK4FREREZF9uUr55YGAgFAoFsrOzLfZnZ2cjODi43mPj4+OxYsUKJCUloW/fvjVeN4WfS5cu4eeff663L1CtVkOtVjftIuzAPBCaM8GIiIjsQtIWIJVKhQEDBiA5Odm8z2g0Ijk5GYMHD67zuFWrVmHZsmXYsWMHBg4cWON1U/g5e/YskpKSEBAQYJf62wu7wIiIiOxL0hYgAIiNjcX06dMxcOBAREZGYs2aNSguLsbMmTMBANOmTUO7du2wfPlyAMDKlSuxZMkSfPnllwgPDzePFfLy8oKXlxf0ej0mTJiAtLQ0bN++HQaDwVzG398fKpVKmgu1Am+ISkREZF+SB6BJkybh2rVrWLJkCbKystCvXz/s2LHDPDA6PT0dcnlVQ1ViYiJ0Oh0mTJhgcZ64uDgsXboUV69exXfffQcA6Nevn0WZ3bt3Y/jw4Xa9HlvgDVGJiIjsS/IABABz5szBnDlzan0tJSXF4vnFixfrPVd4eDgkXtqo2UyrQbMLjIiIyD5cehZYSxXALjAiIiK7YgByQqZp8GwBIiIisg8GICfkz2nwREREdsUA5IRMXWCF5RXQVRglrg0REVHLwwDkhLTuSijk4v3AbpawFYiIiMjWGICckFwug5+HEgBwnd1gRERENscA5KS4GjQREZH9MAA5qarVoLkYIhERka0xADmpAE6FJyIishsGICfFLjAiIiL7YQByUrwhKhERkf0wADmpAC8uhkhERGQvDEBOil1gRERE9sMA5KT8PTgLjIiIyF4YgJyUvxdbgIiIiOyFAchJmbrA8kr1MBgFiWtDRETUsjAAOSm/yi4wQeD9wIiIiGyNAchJKRVyaN3F+4GxG4yIiMi2GICcWIBpLSBOhSciIrIpBiAnxqnwRERE9sEA5MSqAhCnwhMREdkSA5ATM60GzdthEBER2RYDkBNjFxgREZF9MAA5MX9PNQAGICIiIltjAHJiAWwBIiIisgsGICfGLjAiIiL7YAByYqYAxEHQREREtsUA5MRMs8BuFusgCLwfGBERka0wADkxUwtQhVFAQWmFxLUhIiJqORiAnJjaTQEvtRsA4DoXQyQiIrIZBiAnx4HQREREtscA5OQ4EJqIiMj2GICcHNcCIiIisj0GICfnxwBERERkc00KQJcvX8aVK1fMzw8ePIh58+bhgw8+sFnFSGRqAbpexABERERkK00KQI8//jh2794NAMjKysIDDzyAgwcP4uWXX8Zrr71m9fnWrl2L8PBwaDQaREVF4eDBg3WW/fDDDzFs2DD4+fnBz88P0dHRNcpv2bIFI0aMQEBAAGQyGY4cOWJ1nZxF1SBozgIjIiKylSYFoBMnTiAyMhIA8PXXX+P222/Hr7/+ii+++AIbNmyw6lybNm1CbGws4uLikJaWhoiICMTExCAnJ6fW8ikpKZgyZQp2796N1NRUhIWFYcSIEbh69aq5THFxMe666y6sXLmyKZfnVDgImoiIyPbcmnKQXq+HWi3eqTwpKQljxowBAPTo0QOZmZlWnWv16tWYNWsWZs6cCQB477338P3332PdunVYuHBhjfJffPGFxfOPPvoI3377LZKTkzFt2jQAwJNPPgkAuHjxolV1cUam1aA5BoiIiMh2mtQC1Lt3b7z33nvYu3cvdu3ahZEjRwIAMjIyEBAQ0Ojz6HQ6HD58GNHR0VUVkssRHR2N1NTURp2jpKQEer0e/v7+1l1ENeXl5SgoKLDYnIW/pxg0GYCIiIhsp0kBaOXKlXj//fcxfPhwTJkyBREREQCA7777ztw11hi5ubkwGAwICgqy2B8UFISsrKxGnWPBggUIDQ21CFHWWr58ObRarXkLCwtr8rlsLaBaFxjvB0ZERGQbTeoCGz58OHJzc1FQUAA/Pz/z/meffRYeHh42q1xDVqxYgY0bNyIlJQUajabJ51m0aBFiY2PNzwsKCpwmBJnGAOkqjCjWGcy3xiAiIqKma9Jf09LSUgiCYA4/ly5dwtatW9GzZ0/ExMQ0+jyBgYFQKBTIzs622J+dnY3g4OB6j42Pj8eKFSuQlJSEvn37Wn8R1ajVavOYJmfjoVJA7SZHeYURN4p0DEBEREQ20KQusLFjx+LTTz8FAOTl5SEqKgr/+te/MG7cOCQmJjb6PCqVCgMGDEBycrJ5n9FoRHJyMgYPHlzncatWrcKyZcuwY8cODBw4sCmX4DJkMlm1bjBOhSciIrKFJgWgtLQ0DBs2DADwzTffICgoCJcuXcKnn36Kt99+26pzxcbG4sMPP8Qnn3yC06dP47nnnkNxcbF5Vti0adOwaNEic/mVK1di8eLFWLduHcLDw5GVlYWsrCwUFRWZy9y4cQNHjhzBqVOnAABnzpzBkSNHGj2uyNn4cyYYERGRTTWpP6WkpATe3t4AgJ9++gmPPvoo5HI57rzzTly6dMmqc02aNAnXrl3DkiVLkJWVhX79+mHHjh3mgdHp6emQy6tyWmJiInQ6HSZMmGBxnri4OCxduhSAOBjbFKAAYPLkyTXKuBLOBCMiIrKtJgWgrl27Ytu2bXjkkUewc+dO/P3vfwcA5OTkwMfHx+rzzZkzB3PmzKn1tZSUFIvnjVnbZ8aMGZgxY4bV9XBWvCEqERGRbTWpC2zJkiWYP38+wsPDERkZaR6v89NPP6F///42rSBVvx0GAxAREZEtNKkFaMKECbjrrruQmZlpXgMIAO6//3488sgjNqsciXg7DCIiIttq8pzq4OBgBAcHm+8K3759e6sWQaTGYxcYERGRbTWpC8xoNOK1116DVqtFx44d0bFjR/j6+mLZsmUwGo22rmOrxxYgIiIi22pSC9DLL7+Mjz/+GCtWrMDQoUMBAL/88guWLl2KsrIyvP766zatZGtXdUNUrgNERERkC00KQJ988gk++ugj813gAaBv375o164dnn/+eQYgGzNPgy9iCxAREZEtNKkL7MaNG+jRo0eN/T169MCNGzeaXSmyZOoCK9YZUKY3SFwbIiIi19ekABQREYGEhIQa+xMSEpp9Xy6qyUfjBje5DAAHQhMREdlCk7rAVq1ahYceeghJSUnmNYBSU1Nx+fJl/PDDDzatIIn3A/PzVOFaYTluFOsQ6usudZWIiIhcWpNagO655x788ccfeOSRR5CXl4e8vDw8+uijOHnyJD777DNb15GAajdEZQsQERFRczV5HaDQ0NAag52PHj2Kjz/+GB988EGzK0aWqlaD5kwwIiKi5mpSCxA5nnktIM4EIyIiajYGIBfB1aCJiIhshwHIRZjXAmIAIiIiajarxgA9+uij9b6el5fXnLpQPfy9OAiaiIjIVqwKQFqttsHXp02b1qwKUe3YBUZERGQ7VgWg9evX26se1AB/BiAiIiKb4RggF2FeB6iI0+CJiIiaiwHIRZhagArKKqA3GCWuDRERkWtjAHIRvh4qyMTbgeFmCbvBiIiImoMByEUo5DL4eXAcEBERkS0wALkQ80BorgZNRETULAxALsSfN0QlIiKyCQYgF8K1gIiIiGyDAciFsAWIiIjINhiAXEhVCxDXAiIiImoOBiAXwtWgiYiIbIMByIX4e4l3hL/OWWBERETNwgDkQvy5DhAREZFNMAC5EHaBERER2QYDkAsJ8BID0M0SHYxGQeLaEBERuS4GIBdiuhWGUQDySvUS14aIiMh1MQC5EJWbHN4aNwCcCk9ERNQcDEAuxrQWEGeCERERNR0DkIvhQGgiIqLmc4oAtHbtWoSHh0Oj0SAqKgoHDx6ss+yHH36IYcOGwc/PD35+foiOjq5RXhAELFmyBCEhIXB3d0d0dDTOnj1r78twCH/PyrWAGICIiIiaTPIAtGnTJsTGxiIuLg5paWmIiIhATEwMcnJyai2fkpKCKVOmYPfu3UhNTUVYWBhGjBiBq1evmsusWrUKb7/9Nt577z0cOHAAnp6eiImJQVlZmaMuy254Q1QiIqLmkwmCIOl86qioKAwaNAgJCQkAAKPRiLCwMMydOxcLFy5s8HiDwQA/Pz8kJCRg2rRpEAQBoaGhePHFFzF//nwAQH5+PoKCgrBhwwZMnjy5wXMWFBRAq9UiPz8fPj4+zbtAG1u543ckppzHjCHhWDqmt9TVISIichrW/P2WtAVIp9Ph8OHDiI6ONu+Ty+WIjo5Gampqo85RUlICvV4Pf39/AMCFCxeQlZVlcU6tVouoqKg6z1leXo6CggKLzVkF8I7wREREzSZpAMrNzYXBYEBQUJDF/qCgIGRlZTXqHAsWLEBoaKg58JiOs+acy5cvh1arNW9hYWHWXorDmAZB32QAIiIiajLJxwA1x4oVK7Bx40Zs3boVGo2myedZtGgR8vPzzdvly5dtWEvb8mcLEBERUbO5SfnmgYGBUCgUyM7OttifnZ2N4ODgeo+Nj4/HihUrkJSUhL59+5r3m47Lzs5GSEiIxTn79etX67nUajXUanUTr8KxAipngXEhRCIioqaTtAVIpVJhwIABSE5ONu8zGo1ITk7G4MGD6zxu1apVWLZsGXbs2IGBAwdavNapUycEBwdbnLOgoAAHDhyo95yuwt+rahaYxOPXiYiIXJakLUAAEBsbi+nTp2PgwIGIjIzEmjVrUFxcjJkzZwIApk2bhnbt2mH58uUAgJUrV2LJkiX48ssvER4ebh7X4+XlBS8vL8hkMsybNw///Oc/0a1bN3Tq1AmLFy9GaGgoxo0bJ9Vl2oxpELTeIKCwvAI+GqXENSIiInI9kgegSZMm4dq1a1iyZAmysrLQr18/7NixwzyIOT09HXJ5VUNVYmIidDodJkyYYHGeuLg4LF26FADwj3/8A8XFxXj22WeRl5eHu+66Czt27GjWOCFnoVEq4KFSoERnwI0iHQMQERFRE0i+DpAzcuZ1gADgrpU/48rNUnz73BAM6OgndXWIiIicgsusA0RNw9WgiYiImocByAVV3RCVM8GIiIiaggHIBflxLSAiIqJmYQByQeYusCIGICIioqZgAHJB/ubFEBmAiIiImoIByAXxhqhERETNwwDkgvw5C4yIiKhZGIBcUPXbYRAREZH1GIBcUFUXGKfBExERNQUDkAsydYGV6Y0o0VVIXBsiIiLXwwDkgrzUblApxI/uOqfCExERWY0ByAXJZDIOhCYiImoGBiAXxQBERETUdAxALiqAM8GIiIiajAHIRbEFiIiIqOkYgFyUP1eDJiIiajIGIBdlviEq1wIiIiKyGgOQi+INUYmIiJqOAchFsQuMiIio6RiAXBRngRERETUdA5CLMs8C40rQREREVmMAclGmQdCF5RUorzBIXBsiIiLXwgDkonw0SijkMgDAzWK9xLUhIiJyLQxALkoul8HPQwkAuM6p8ERERFZhAHJhXA2aiIioaRiAXBgDEBERUdMwALmwgMrFEK9zJhgREZFVGIBcGFuAiIiImoYByIVxNWgiIqKmYQByYVWrQXMWGBERkTUYgFwYu8CIiIiahgHIhbELjIiIqGkYgFyYaRYYW4CIiIiswwDkwkwtQHklelQYjBLXhoiIyHUwALkw060wACCvlPcDIyIiaizJA9DatWsRHh4OjUaDqKgoHDx4sM6yJ0+exPjx4xEeHg6ZTIY1a9bUKFNYWIh58+ahY8eOcHd3x5AhQ3Do0CE7XoF03BRy+FaGIHaDERERNZ6kAWjTpk2IjY1FXFwc0tLSEBERgZiYGOTk5NRavqSkBJ07d8aKFSsQHBxca5lnnnkGu3btwmeffYbjx49jxIgRiI6OxtWrV+15KZIxD4TmatBERESNJmkAWr16NWbNmoWZM2eiV69eeO+99+Dh4YF169bVWn7QoEF44403MHnyZKjV6hqvl5aW4ttvv8WqVatw9913o2vXrli6dCm6du2KxMREe1+OJAI4FZ6IiMhqkgUgnU6Hw4cPIzo6uqoycjmio6ORmprapHNWVFTAYDBAo9FY7Hd3d8cvv/xS53Hl5eUoKCiw2FxF1VpAXAyRiIiosSQLQLm5uTAYDAgKCrLYHxQUhKysrCad09vbG4MHD8ayZcuQkZEBg8GAzz//HKmpqcjMzKzzuOXLl0Or1Zq3sLCwJr2/FPxNN0RlCxAREVGjST4I2tY+++wzCIKAdu3aQa1W4+2338aUKVMgl9d9qYsWLUJ+fr55u3z5sgNr3DzsAiMiIrKem1RvHBgYCIVCgezsbIv92dnZdQ5wbowuXbpgz549KC4uRkFBAUJCQjBp0iR07ty5zmPUanWtY4pcAVeDJiIisp5kLUAqlQoDBgxAcnKyeZ/RaERycjIGDx7c7PN7enoiJCQEN2/exM6dOzF27Nhmn9MZmW+IyllgREREjSZZCxAAxMbGYvr06Rg4cCAiIyOxZs0aFBcXY+bMmQCAadOmoV27dli+fDkAceD0qVOnzI+vXr2KI0eOwMvLC127dgUA7Ny5E4IgoHv37jh37hxeeukl9OjRw3zOlsbPg11gRERE1pI0AE2aNAnXrl3DkiVLkJWVhX79+mHHjh3mgdHp6ekWY3cyMjLQv39/8/P4+HjEx8fjnnvuQUpKCgAgPz8fixYtwpUrV+Dv74/x48fj9ddfh1KpREvELjAiIiLryQRBEKSuhLMpKCiAVqtFfn4+fHx8pK5OvTLzSzF4+c9QyGU4+89RkMtlUleJiIhIEtb8/W5xs8BaG1MLkMEooKCM9wMjIiJqDAYgF6d2U8BLLfZkshuMiIiocRiAWgB/rgVERERkFQagFoA3RCUiIrIOA1ALwNWgiYiIrMMA1ALwhqhERETWYQBqAfy9uBYQERGRNRiAWgB2gREREVmHAagF8PcUb+TKAERERNQ4DEAtAFuAiIiIrMMA1AJwHSAiIiLrMAC1ANVviMpbuxERETWMAagFCKicBaarMKJYZ5C4NkRERM6PAagF8FC5QaMUP8obXA2aiIioQQxAjmanLqqAyplg17kYIhERUYMYgByp5AbwyWjg7C6bn5oDoYmIiBqPAciRUhOAi3uBr6cDGb/Z9NTVB0ITERFR/RiAHOmehUDn4YC+GPhiInDzos1OzRYgIiKixmMAciQ3FTDxMyDodqA4B/h8gtgtZgMMQERERI3HAORoGh9g6mbApz1w/Szw1RRAX9bs05q7wDgLjIiIqEEMQFLwCQWe+AZQa4HL+4GtzwJGY7NOWXU7DM4CIyIiaggDkFTa9gQmfwEoVMCpfwM/vdKs07ELjIiIqPEYgKTUaRgwLlF8vH8tkLq2yacyrQbNWWBEREQNYwCSWp8JQPSr4uOdLwMntzbpNP6VCyGyBYiIiKhhDEDOYOjfgEGzAAjAlr8Al1KtPoWpC6xEZ0CZnvcDIyIiqg8DkDOQyYBRK4HuDwGGcuCrycC1P6w6hY/GDUqFDAC7wYiIiBrCAOQs5Apg/EdA+0FAWR7w+XigMLvRh8tkMvh5VA6E5lR4IiKiejEAOROVBzBlI+DfGchPB758DCgvavThVbfD4FR4IiKi+jAAORvPQOCJbwGPQCDzKLB5OmDQN+pQ00wwDoQmIiKqHwOQM/LvDDz+NeDmDpxLArb/HRCEhg+rnAn22f5L+C39pr1rSURE5LIYgJxV+wHAY+sBmRz47TNgz6oGD4npHQQ3uQy/pefhkXd/xVMbDuH4lXwHVJaIiMi1yAShEU0LrUxBQQG0Wi3y8/Ph4+MjbWUOfQx8Hys+HrsW6P9EvcUv3yjBOz+fxbdpV2Ewih/tA72C8Pfo29ArVOJrISIisiNr/n4zANXCqQIQACS9CvyyGpC7AY9vArpGN3jIhdxivJN8FtuOXEVlDsKDfYIxL/o23BbkbecKExEROR4DUDM5XQASBGDLs8DxrwGVFzDzByAkolGHnsspxFvJ57D9WAYEQVxyaHTfUPwtuhu6tPGyc8WJiIgchwGomZwuAAFAhQ74Yjxw4b+AVxDwTBLg26HRh5/JKsSapD/w44ksAIBcBozr3w4v3NcN4YGe9qo1ERGRw1jz91vyQdBr165FeHg4NBoNoqKicPDgwTrLnjx5EuPHj0d4eDhkMhnWrFlTo4zBYMDixYvRqVMnuLu7o0uXLli2bBlcPue5qYBJnwNtewNF2cDnE4DSxs/06h7sjcQnBmD73LsQ3TMIRgHYknYV96/egwXfHMPlGyV2rDwREZFzkTQAbdq0CbGxsYiLi0NaWhoiIiIQExODnJycWsuXlJSgc+fOWLFiBYKDg2sts3LlSiQmJiIhIQGnT5/GypUrsWrVKrzzzjv2vBTH0GiBqZsB71Ag9wywcSqgL7PqFLe30+Kj6QPx79lDMbx7GxiMAjb97zLu+1cKXt56HBl5pXaqPBERkfOQtAssKioKgwYNQkJCAgDAaDQiLCwMc+fOxcKFC+s9Njw8HPPmzcO8efMs9j/88MMICgrCxx9/bN43fvx4uLu74/PPP29UvZyyC6y67JPAupFAeQHQ+xFg/DpA3rQse/jSTby56w/8ci4XAKBSyDElMgyz7+2Ktj4aW9aaiIjIrlyiC0yn0+Hw4cOIjq6a0SSXyxEdHY3UVOvvhm4yZMgQJCcn448/xJuJHj16FL/88gtGjRpV5zHl5eUoKCiw2JxaUG+xO0yuBE5uBXYtbvKpBnT0w+fPRGHTs3ciqpM/dAYjPkm9hGGrdmPZ9lO4VsjbahARUcsjWQDKzc2FwWBAUFCQxf6goCBkZWU1+bwLFy7E5MmT0aNHDyiVSvTv3x/z5s3D1KlT6zxm+fLl0Gq15i0sLKzJ7+8wne8Bxr0rPk5NAPa/16zTRXUOwMZn78SXz0RhQEc/lFcY8fEvF3D3qt1Y/uNp3l6DiIhaFMkHQdva119/jS+++AJffvkl0tLS8MknnyA+Ph6ffPJJnccsWrQI+fn55u3y5csOrHEz9J0I3L9EfLxjIXDqu2adTiaTYUjXQHzz18H45KlIRLTXolRvwPt7/sSwlT8jfucZ5JUwCBERketzk+qNAwMDoVAokJ2dbbE/Ozu7zgHOjfHSSy+ZW4EAoE+fPrh06RKWL1+O6dOn13qMWq2GWq1u8ntK6q5YIP8K8L91wJZZgFdboMOdzTqlTCbDPbe1wd3dAvHz7zlYvesPnMwoQMLuc/j4lwuI7hWEMRGhuPu2QKjdFDa6ECIiIseRrAVIpVJhwIABSE5ONu8zGo1ITk7G4MGDm3zekpISyG8ZEKxQKGA0Gpt8TqcmkwGj3gBuGwVUlAFfTQb2JwLXz9vg1DLc3zMI2+fehfeeGIAewd4o1Rvwn6MZmPXp/zDwn0l4afNR/PePa6gwtNDvLxERtUiStQABQGxsLKZPn46BAwciMjISa9asQXFxMWbOnAkAmDZtGtq1a4fly5cDEAdOnzp1yvz46tWrOHLkCLy8vNC1a1cAwOjRo/H666+jQ4cO6N27N3777TesXr0aTz31lDQX6QgKN2DCx8Ano4Grh8XusB0LAb9OQLcHgG4jgPC7AKV7k04vk8kw8vZgxPQOwrEr+fjuaAa2H8tAdkE5Nh++gs2HryDAU4VRfYIxJqIdBnb0g1wus/FFEhER2Y7kK0EnJCTgjTfeQFZWFvr164e3334bUVFRAIDhw4cjPDwcGzZsAABcvHgRnTp1qnGOe+65BykpKQCAwsJCLF68GFu3bkVOTg5CQ0MxZcoULFmyBCqVqlF1cvpp8HUpKwDSPgXO/gRc+hUw6qtec9MA4cPEQNQ1Ggjo0qy3MhoFHLp4A/85loEfjmdZDJIO9tHg4b4hGB0Rir7ttZDJGIaIiMj+eCuMZnLZAFRdeaF424yzPwFnk4CCK5av+3epbB16AOh4F6Bs+po/FQYj9p2/jv8czcDOE1koLK8wv9bB3wOjI8Qw1CPYRb+XRETkEhiAmqlFBKDqBAHIOQ2c2wWc3QWkpwLGqpACN3eg091VrUP+NVvZGqtMb8B//7iG/xzLRNKpbJTqDebXbgvywui+oXg4IhSdeP8xIiKyMQagZmpxAehWZQXAnymVgSgJKMywfD2gW7XWoaGAW9NmyJXoKpB0Ogf/OZqBPWeuQVdtoHSfdlqMjgjBw31DEerbtLFJRERE1TEANVOLD0DVCYJ4aw1z69B+QKhqtYHSA+h0D9AtGuj6AODXsUlvk1+qx08ns/Dd0Qz8ev46DMaqH7tB4X4YHRGKUbeHoI23iy5HQEREkmMAaqZWFYBuVZpn2TpUdMuq3MF9gHsWAj0eEqfgN0FuUTl+PJGF/xzNwMELN8z75TKgcxsv+Huq4O+hgp+nCv6eSvh5qBDgpYKfhwr+nirzc3elggOsiYjIjAGomVp1AKpOEICs41WtQ5cPVrUOtY8EopcC4UOb9RaZ+aX4/lgm/nM0A0ev5Ft1rNpNbg5E/p5Vm/hcCX9PNfw8leZApfVQwmgESvUGcdMZUKYXN9PzUtNznQGleiNK9QaU1/Z6tTKmcxiMAoK1GrTzdRc3v6qv7X094OPuxsBGRGRHDEDNxABUh5IbQOpaYP+7gL5E3NdtBHB/HBB8e7NPf+VmCdKvl+B6sQ43S3S4UazDzWIdbpTocaO4HDeK9eLzYp3FeCJX4aV2qxGMqgKSOwK91Fw/iYioGRiAmokBqAGFWcCeVcDhDZUtQjLxvmT3vtzkMULWEAQBJToDblSGoRslOnMwMgUnMTzpza/dLNGh2rAjqBRyaJRyuKsUcFcqoFEqzI/dlQpozPvlNfa5V5bVKKsdqxRvCZKRX4qrN0txNU/8anp+vRE3k1Up5Aj11VQFI1+Pao/dEeitglIhh5tcxpYkIqJaMAA1EwNQI10/D/y8DDi5VXwuVwKDngHung94Bkpbt1sYjAKKyirgppBBo1RA4eCWllKdQQxFeaaAVGIRlLIKyiwCWkNUCjmUChmUbnIoFfKq5wrxudJNDlX15wo5VG7Vn9/ymkIGb43SoivRtHmoONaKiFwDA1AzMQBZKeM3IGmpOHgaAFTewJC5wODZgNpLypq5DL3BiKz8smoBqdrXyk1XIU23n8pNjoBqg8/NA9E9xYHqt37181A5PGDaSoXBiBvFOuQUluNaUTmuFYqb2k2O3qFa9Ar1gdZd2fw3MhqAzKPAhT3Alf8BbXsCkX8BvNo0/9xErRgDUDMxADXR+d1iEMo8Ij73bAPc/Q9gwAzArXG3IaHaGY0CSvUGVBgE6AxG6Kttugqh6rHBCL1BgL7CiAqjEbrKx1WvV5atsHyuqzCioExf1a1YrMP1Yl2TQpdMBvi6K6tCUeUgdR93JbzUbuKmcYOPxg1eaiW8NOI+78qvtm5xEgQBheUVyCmoDDTVgo3l8zJcL9ahoX8RO/h7oHeoj7i106J3qA/aejewkrogADf+BP7cDfy5R1ylvSzPsoybO3DHNPE/D75hzbpmotaKAaiZGICawWgETm0Tu8Zu/Cnu8wsH7n0FuH08IJdLWTuyQm1jrW4U3fK42pirG8U65JfqGz5xA+QyVAYipTksmQKSKSSZgpN35X65XIbrRTrkFJbVEmzKUW5FkJPLgAAvNdp4qdHGW41ALzWKyvU4cbUAV/NKaz2mrbcavUN9cHtlIOodqkV7ZQFkF/aKLaN/ptS8HY3aR7w/X/sBwOn/iC2pACB3A/pOBu6aBwR2a9L3kKi1YgBqJgYgGzDoxRuz7lkJFGWL+4L7APcvBbre3+Q1hKxWmgdknxCn8+f+AXgEirf68O8sbp5tHFeXVkBvMCKvxLIlyTSDr6hcj6LyChSWVVR9NT8WX7NmHJS1vNVuaONTFWzMW7Xnbb018Pesuwsvr0SHUxkFOJGRj5MZBThxNR9/5hZDEABPlCJKfhp3yU9giPwkesgvWxxrlKsgC4uErMtwoPO9QEg/QOEmvigIYkja+y/g4t7KI2RArzHAXbFAaL9a62M0iq1beSU65JXokVeqr3pcokdeqQ4FpRUQIEAGGWQyQAZUfpWZf/TFr7W/Lj6XmctZHAfATSGHp0oBD7UbPFUKeKrd4KlWwENV1aLnafqqcuNMR7IrBqBmYgCyIV2xOG1+39tAeYG4L3wYEP2q+D9fWxEEIP+yGHTM2zEgL73+41RegF8ny1Dk31l87h3KFisHEgSxm6+orAIFlcFIDEh6y9BU7WtRZXDSGQS08VKhjbemRrBpW9mK465S2LbCFTrgyiHoz+1G+R8/w+PaUciFqnvsGQUZTgodsc94O/YZb8chY3fIlB7oEeKN20OrWopuC/aCUi43BxndxQPwS0tA4NVk87nO+tyJHX6PIw09K0OOGHTyS/V2DY324K5UwFNtCkU1Q1PVczE0Bfto0D3YGx0DPF12bBk5DgNQMzEA2UHJDfF/twc/AAyVU8J7jgHuX2J9M3+FDsg9UzPslNWxkKI2TGx9atNdbBG68Sdw44IYmFDPj79CXRWMbg1J2rCq/71T62A0AjknK7u09gCX9lWth2Xi1wnoPBz68Htw3rM/jl1X4GRla9GpzAKU6Aw1TquQyyAIQo0g012WjufcvsNoeSoUMvHFQ8bbsLZiLFKM/SC2v4g8VAr4uiuh9VDBz0MJXw8ltO7iY2+NEnKZ+JMuCIAAwTzOSRCEyn2Wrwnii+b9gOVrprIQAL1BQImuAsU6A0rKxWBaojOgWFeBknIDissrUKxrfuueRilHt7be6B7sjR7B4tfuwd5o46XmLEUyYwBqJgYgO8q7DKQsB45+BQhGQKYA+j8BDF8I+ITWLF+9C8sUdHJ+B4y1jDWRuwFteophJ7iPuDhj0O2Ah3/tdakoF1uIbvxZFYpMj/MuAcaK2o8zvZdvh1tajbqI7+sT0qRvDUlIEMQWytI8cXByaR5QerPqsWnGVsl1y+M8AoHO9wCdh4v3zKtnHSyDUcDF68U4cTUfpzIKxC60jHzklVT9LLsrFfDzEIOMOJBciU7ya4i+uRF9r22HQhDLFvv1RP7AuXDrPQ5aLw3UbjZu3WqM8qLK/3gUAB2iAHe/OosKgoDyCqMYhsorw5Gu8nF5ZXjSVYan8qrwVFRegcs3S/BHdiHK9LWP4/L3VKF7kGUwui3IG55q6f+DIggCw5mDMQA1EwOQA+ScBpJfA878ID530wBRfwXaD6oWeOrpwlJrqwWdPlUtPE28c30NhgqxhejmhZrh6OZFoKKs7mO9gsTxHSER4tiNkAjApx3HGtmbIAC6omoh5qZloKlvX1m+GMgbovQUb//SqTL0tO3VrG5SQRCQXVAOuQzwcVdCo6wnyBRkAvvXAv9bL14nIAbvofOAiMm2+9mvjb5MvGlyRhpwNU0csJ17pup7JpMD7QYAXe4Tt3YDAIUNlguoZDAKSL9RgjNZBfg9qxBnKreL14vrbFnq4O9hEYp6BHsjPMATbgrrPy/ThICbJeICqzdLxMVV80r0Fl9vFFvuK9FVoI23GiFad4RoNVVffTXm52291U2qE9WOAaiZGIAcKH2/OHU+PbXuMtoONcOObwfpAoXRCBRmVgtEleHo2hlxoHVtf0g9AqvCkCkcSXkNrqyiXAzQWceAzGPi1+vnxTBTX6tdY7hpAI0v4O4rtmiYHvt2FANPuwHSL+lQcgM4+CFwIFEMb4A4Xm3IXGDAdEDl2bzzGyqAa6ergk5GGpB9qvZWV592gNIduH7Ocr/aB+h0N9DlXjEQ+XduXp3qUKY34Gx2EX7PKhBDUXYhfs8qxLXC8lrLq9zk6NrGy6KlyGAULELMzcrxVbeGGXvdfkcuA9p6W4Yi09dgrQahvhq09dZw/FMjMQA1EwOQgwkC8MdO4Jc3xUHTFmHn9nqb1p2Orrjyf8pHxG6TzCPiH2uh5tgPuPtXBqJqLUV+nRiKqisrEFsETUEn85j4x7m+oKNQ1R5iGrNP2cB6Ps6kvEi8HU1qghjIAfFn6s7ngMhZjfu9MRrF8JJRGXauponf59paOD0CgNA7gHZ3AKH9xc07WHwt/4q4Dtj5n8UxUqU3LI/17VjVOtTpbvF7bkc3inVVoShLDEV/ZBfWOgbLGio3Ofw8lPDzUMHX/FUca+XvWfXY9NVdpcC1wnJk5JUhM78UWfllyMgvQ1Z+KTLyypBdUIaKRgyOUshlaOuttghIwVpxxmJ1t/41v/XM1f/c13jXWqrh4+6G4Mr3C/RSu0QIYwBqJgYgsil9qfg/6MzfqoJRzuna/0et0VaFopB+4ubfuXXMRivKqQw6R6sCj2ktqVtpfIGQvkBwX/F71aaHePsVja/YItGaQmRFuTim7pc1YmskIM5uHPQ0cOdswDtI3CcI4tg2c8tO5c+jrrDmOdU+4ve13R1i6Ant3/gWS6NR/AzP/yyGovT9lj/rMjnQbuAt3WX2H69jNAq4crPUHIx+zy7E+ZwiqNzk8PVQwd8cXFTw86wKMaaw4++pgrvStot0Go0CcovKLUJRVkEZMvLEsJSZLz43OMFUP4VchiBvNYKrtU6ZgpgzdecxADUTAxDZXUU5kHOqMhAdEUNR9smqGXLVqbzFP/YBXcQuGje1OEPN9Ni0KUyPNWI3jZtG3BSqW/ZVKyuXYPCsIIjjqKp3YWUeA4qyai/v064y6PSt+qoNa10hpzEMFeIipHtXi7PVAPFz7jVWHLyd8VvNlhlAXIE6pG9V0Gl3hzig31ahu7xInDF3/mdxy/3D8nUHdZe5KoMpJOXd0oKUX4aCWxYerR7Obv3tqP7rUvO1mscJENe9ysovQ3ZheaNCmFwGtPFWi61GPppbQpLYktTWR23XQfsMQM3EAESSqNCJ3TuZR6tairJP1D/gurnkbtVCkUocuKpQNe6xXFltfwNlBWPVuJ2s41VrQlmQiUsiBPcVuz9D+gLBEYBngP2uvyUydSnv/Rdw5aDla3IlENS7KuiE3iG2njlySQeL7rLdVeOYTPzCq1qHwofZvbvM5kwtbZcPiV/DooAOd9p0ULijmUJY5i0tVabnmflid57e0Lg4EeilQrBWg3u7t8WLI7rbtK4MQM3EAEROw6AXB1dnHhFnARnKxdajinIxGBl04tcK09fyyjJl1cqVVzuurHGznexNoRJnUFXvxgrq3fwBvFRFEMSWlz92iGNwQu8Qv8fONM7JdFNYU3fZ5QO3dJcpxDBsnkAQAbR1smvQl4r/YblyELh8ELhyqGr1exO1Vmzhui0G6PpAi7zprdEo4HqxrrKVqloXXmVAMgWm6vcXfPSOdlg9sZ9N68EA1EwMQNSiGSpqD0sGnRi4DLrKraLaY33THhv14mOjAQjoWhV42nR36f8Rk5001F0GVK33VX0CQdDtgMrDMXXMvyIGtcuHxNCTeazmeD65m/hz7hsGXPzllvWjZOK4p9tigG4jxGtoJd25giDgZone3J0X4KVC/w62neTCANRMDEBERE4g/wpw9bDlrMpbF6MExIHVgbdVLTEREiGGbbV3896/olx838sHK1t4DgGFGTXLebYFwiLFrX2kGMqU7uJrRoM48PzsTrFrMuuY5bFewUC3B8RA1Hl48+vcyjEANRMDEBGRExIEoOBqZRiqNlaurgH0AV1vmVXZt/7lAQoyqrqxLh8UA9etExNkCnF5jvaR4viesEFiF2NjW3EKMoGzP4nb+d2AvrjqNblSXGizW4wYiAK6NO6cZMYA1EwMQERELqQwqyoUmYJRwZXay/p2rBpT1LaXOCPRFHryL9cs7xFQGXYGiYEntL/txqpVlFeO06psHTItY2AS0LUyDI0AOgyRfhFOF8AA1EwMQERELq44t6rbzBSMbl6s/xiZXBxkHTaoMvREitPyHTFGRxDERSn/2Cl2l1361XLBT5U30GW4GIi6jaha34ksMAA1EwMQEVELVHpTHLRsXqX9d0DbrirstLvDecbglBWIywT8UdldVpxj+XpIP6DjUMDDT5xlptECGh/xq9qn6rnK27kWUjUaAX2JOHtOrqj7ZtVNxADUTAxARETkNIxGMbCd/UlsIcpIs+JgmWUgsghIdYQmjVYMVYA4RklfKoYWXWVwMe3TVXvNFGpu3Wc+pvJ59XXNIqYAj7xny++UVX+/Hbj6FREREVlNLhdbp9rdAQxfCBRmA+d2iYuLlheIrUVl+ZWP86s2gw6AAJTni1u+1BdyC0MttwNyIAYgIiIiV+IdBPR/ouFy+rJqoagAKMu75Xn+LcHpliAFAEoPcUq/ylP8qvQQN5WH5XOLfZ61H1N9n5u75F1zDEBEREQtkVIjbl5tpa6JU3KikVFEREREjsEARERERK0OAxARERG1Ok4RgNauXYvw8HBoNBpERUXh4MGDdZY9efIkxo8fj/DwcMhkMqxZs6ZGGdNrt26zZ8+241UQERGRq5A8AG3atAmxsbGIi4tDWloaIiIiEBMTg5ycnFrLl5SUoHPnzlixYgWCg4NrLXPo0CFkZmaat127dgEAHnvsMbtdBxEREbkOyRdCjIqKwqBBg5CQkAAAMBqNCAsLw9y5c7Fw4cJ6jw0PD8e8efMwb968esvNmzcP27dvx9mzZyFrxJLmXAiRiIjI9Vjz91vSFiCdTofDhw8jOjravE8ulyM6Ohqpqak2e4/PP/8cTz31VJ3hp7y8HAUFBRYbERERtVySBqDc3FwYDAYEBVne1C0oKAhZWVk2eY9t27YhLy8PM2bMqLPM8uXLodVqzVtYWJhN3puIiIick+RjgOzt448/xqhRoxAaGlpnmUWLFiE/P9+8Xb582YE1JCIiIkeTdCXowMBAKBQKZGdnW+zPzs6uc4CzNS5duoSkpCRs2bKl3nJqtRpqtbrZ70dERESuQdIWIJVKhQEDBiA5Odm8z2g0Ijk5GYMHD272+devX4+2bdvioYceava5iIiIqOWQ/F5gsbGxmD59OgYOHIjIyEisWbMGxcXFmDlzJgBg2rRpaNeuHZYvXw5AHNR86tQp8+OrV6/iyJEj8PLyQteuXc3nNRqNWL9+PaZPnw43N8kvk4iIiJyI5Mlg0qRJuHbtGpYsWYKsrCz069cPO3bsMA+MTk9Ph7zaHWMzMjLQv39/8/P4+HjEx8fjnnvuQUpKinl/UlIS0tPT8dRTTznsWoiIiMg1SL4OkDPiOkBERESux5q/35K3ADkjUybkekBERESuw/R3uzFtOwxAtSgsLAQArgdERETkggoLC6HVaustwy6wWhiNRmRkZMDb27tRt86wRkFBAcLCwnD58uUW373Ga225WtP18lpbrtZ0va3lWgVBQGFhIUJDQy3GD9eGLUC1kMvlaN++vV3fw8fHp0X/EFbHa225WtP18lpbrtZ0va3hWhtq+TFp8StBExEREd2KAYiIiIhaHQYgB1Or1YiLi2sVt97gtbZcrel6ea0tV2u63tZ0rY3FQdBERETU6rAFiIiIiFodBiAiIiJqdRiAiIiIqNVhACIiIqJWhwHIDtauXYvw8HBoNBpERUXh4MGD9ZbfvHkzevToAY1Ggz59+uCHH35wUE2bbvny5Rg0aBC8vb3Rtm1bjBs3DmfOnKn3mA0bNkAmk1lsGo3GQTVuuqVLl9aod48ePeo9xhU/U5Pw8PAa1yuTyTB79uxay7vS5/rf//4Xo0ePRmhoKGQyGbZt22bxuiAIWLJkCUJCQuDu7o7o6GicPXu2wfNa+zvvKPVdr16vx4IFC9CnTx94enoiNDQU06ZNQ0ZGRr3nbMrvgyM09NnOmDGjRr1HjhzZ4Hmd8bNt6Fpr+/2VyWR444036jyns36u9sQAZGObNm1CbGws4uLikJaWhoiICMTExCAnJ6fW8r/++iumTJmCp59+Gr/99hvGjRuHcePG4cSJEw6uuXX27NmD2bNnY//+/di1axf0ej1GjBiB4uLieo/z8fFBZmamebt06ZKDatw8vXv3tqj3L7/8UmdZV/1MTQ4dOmRxrbt27QIAPPbYY3Ue4yqfa3FxMSIiIrB27dpaX1+1ahXefvttvPfeezhw4AA8PT0RExODsrKyOs9p7e+8I9V3vSUlJUhLS8PixYuRlpaGLVu24MyZMxgzZkyD57Xm98FRGvpsAWDkyJEW9f7qq6/qPaezfrYNXWv1a8zMzMS6desgk8kwfvz4es/rjJ+rXQlkU5GRkcLs2bPNzw0GgxAaGiosX7681vITJ04UHnroIYt9UVFRwl/+8he71tPWcnJyBADCnj176iyzfv16QavVOq5SNhIXFydEREQ0unxL+UxN/va3vwldunQRjEZjra+76ucKQNi6dav5udFoFIKDg4U33njDvC8vL09Qq9XCV199Ved5rP2dl8qt11ubgwcPCgCES5cu1VnG2t8HKdR2rdOnTxfGjh1r1Xlc4bNtzOc6duxY4b777qu3jCt8rrbGFiAb0ul0OHz4MKKjo8375HI5oqOjkZqaWusxqampFuUBICYmps7yzio/Px8A4O/vX2+5oqIidOzYEWFhYRg7dixOnjzpiOo129mzZxEaGorOnTtj6tSpSE9Pr7NsS/lMAfFn+vPPP8dTTz1V742BXfVzre7ChQvIysqy+Oy0Wi2ioqLq/Oya8jvvzPLz8yGTyeDr61tvOWt+H5xJSkoK2rZti+7du+O5557D9evX6yzbUj7b7OxsfP/993j66acbLOuqn2tTMQDZUG5uLgwGA4KCgiz2BwUFISsrq9ZjsrKyrCrvjIxGI+bNm4ehQ4fi9ttvr7Nc9+7dsW7dOvz73//G559/DqPRiCFDhuDKlSsOrK31oqKisGHDBuzYsQOJiYm4cOEChg0bhsLCwlrLt4TP1GTbtm3Iy8vDjBkz6izjqp/rrUyfjzWfXVN+551VWVkZFixYgClTptR7s0xrfx+cxciRI/Hpp58iOTkZK1euxJ49ezBq1CgYDIZay7eUz/aTTz6Bt7c3Hn300XrLuern2hy8Gzw12+zZs3HixIkG+4sHDx6MwYMHm58PGTIEPXv2xPvvv49ly5bZu5pNNmrUKPPjvn37IioqCh07dsTXX3/dqP9VubKPP/4Yo0aNQmhoaJ1lXPVzpSp6vR4TJ06EIAhITEyst6yr/j5MnjzZ/LhPnz7o27cvunTpgpSUFNx///0S1sy+1q1bh6lTpzY4McFVP9fmYAuQDQUGBkKhUCA7O9tif3Z2NoKDg2s9Jjg42KryzmbOnDnYvn07du/ejfbt21t1rFKpRP/+/XHu3Dk71c4+fH19cdttt9VZb1f/TE0uXbqEpKQkPPPMM1Yd56qfq+nzseaza8rvvLMxhZ9Lly5h165d9bb+1Kah3wdn1blzZwQGBtZZ75bw2e7duxdnzpyx+ncYcN3P1RoMQDakUqkwYMAAJCcnm/cZjUYkJydb/A+5usGDB1uUB4Bdu3bVWd5ZCIKAOXPmYOvWrfj555/RqVMnq89hMBhw/PhxhISE2KGG9lNUVITz58/XWW9X/UxvtX79erRt2xYPPfSQVce56ufaqVMnBAcHW3x2BQUFOHDgQJ2fXVN+552JKfycPXsWSUlJCAgIsPocDf0+OKsrV67g+vXrddbb1T9bQGzBHTBgACIiIqw+1lU/V6tIPQq7pdm4caOgVquFDRs2CKdOnRKeffZZwdfXV8jKyhIEQRCefPJJYeHCheby+/btE9zc3IT4+Hjh9OnTQlxcnKBUKoXjx49LdQmN8txzzwlarVZISUkRMjMzzVtJSYm5zK3X+uqrrwo7d+4Uzp8/Lxw+fFiYPHmyoNFohJMnT0pxCY324osvCikpKcKFCxeEffv2CdHR0UJgYKCQk5MjCELL+UyrMxgMQocOHYQFCxbUeM2VP9fCwkLht99+E3777TcBgLB69Wrht99+M896WrFiheDr6yv8+9//Fo4dOyaMHTtW6NSpk1BaWmo+x3333Se888475ucN/c5Lqb7r1el0wpgxY4T27dsLR44csfg9Li8vN5/j1utt6PdBKvVda2FhoTB//nwhNTVVuHDhgpCUlCTccccdQrdu3YSysjLzOVzls23o51gQBCE/P1/w8PAQEhMTaz2Hq3yu9sQAZAfvvPOO0KFDB0GlUgmRkZHC/v37za/dc889wvTp0y3Kf/3118Jtt90mqFQqoXfv3sL333/v4BpbD0Ct2/r1681lbr3WefPmmb8vQUFBwoMPPiikpaU5vvJWmjRpkhASEiKoVCqhXbt2wqRJk4Rz586ZX28pn2l1O3fuFAAIZ86cqfGaK3+uu3fvrvXn1nQ9RqNRWLx4sRAUFCSo1Wrh/vvvr/E96NixoxAXF2exr77feSnVd70XLlyo8/d49+7d5nPcer0N/T5Ipb5rLSkpEUaMGCG0adNGUCqVQseOHYVZs2bVCDKu8tk29HMsCILw/vvvC+7u7kJeXl6t53CVz9WeZIIgCHZtYiIiIiJyMhwDRERERK0OAxARERG1OgxARERE1OowABEREVGrwwBERERErQ4DEBEREbU6DEBERETU6jAAERE1gkwmw7Zt26SuBhHZCAMQETm9GTNmQCaT1dhGjhwpddWIyEW5SV0BIqLGGDlyJNavX2+xT61WS1QbInJ1bAEiIpegVqsRHBxssfn5+QEQu6cSExMxatQouLu7o3Pnzvjmm28sjj9+/Djuu+8+uLu7IyAgAM8++yyKioosyqxbtw69e/eGWq1GSEgI5syZY/F6bm4uHnnkEXh4eKBbt2747rvv7HvRRGQ3DEBE1CIsXrwY48ePx9GjRzF16lRMnjwZp0+fBgAUFxcjJiYGfn5+OHToEDZv3oykpCSLgJOYmIjZs2fj2WefxfHjx/Hdd9+ha9euFu/x6quvYuLEiTh27BgefPBBTJ06FTdu3HDodRKRjUh9N1YiooZMnz5dUCgUgqenp8X2+uuvC4IgCACEv/71rxbHREVFCc8995wgCILwwQcfCH5+fkJRUZH59e+//16Qy+XmO4KHhoYKL7/8cp11ACC88sor5udFRUUCAOHHH3+02XUSkeNwDBARuYR7770XiYmJFvv8/f3NjwcPHmzx2uDBg3HkyBEAwOnTpxEREQFPT0/z60OHDoXRaMSZM2cgk8mQkZGB+++/v9469O3b1/zY09MTPj4+yMnJaeolEZGEGICIyCV4enrW6JKyFXd390aVUyqVFs9lMhmMRqM9qkREdsYxQETUIuzfv7/G8549ewIAevbsiaNHj6K4uNj8+r59+yCXy9G9e3d4e3sjPDwcycnJDq0zEUmHLUBE5BLKy8uRlZVlsc/NzQ2BgYEAgM2bN2PgwIG466678MUXX+DgwYP4+OOPAQBTp05FXFwcpk+fjqVLl+LatWuYO3cunnzySQQFBQEAli5dir/+9a9o27YtRo0ahcLCQuzbtw9z58517IUSkUMwABGRS9ixYwdCQkIs9nXv3h2///47AHGG1saNG/H8888jJCQEX331FXr16gUA8PDwwM6dO/G3v/0NgwYNgoeHB8aPH4/Vq1ebzzV9+nSUlZXhzTffxPz58xEYGIgJEyY47gKJyKFkgiAIUleCiKg5ZDIZtm7dinHjxkldFSJyERwDRERERK0OAxARERG1OhwDREQujz35RGQttgARERFRq8MARERERK0OAxARERG1OgxARERE1OowABEREVGrwwBERERErQ4DEBEREbU6DEBERETU6jAAERERUavz/wG0DKpLhhIm5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(myhistory.history['loss'])\n",
    "plt.plot(myhistory.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['training loss', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "49f7630e-2bf1-45dd-b7c8-9d75277d1cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 645us/step\n"
     ]
    }
   ],
   "source": [
    "preds_100 = model.predict(X_val_100,batch_size=1000)\n",
    "fpr_100, tpr_100, _ = roc_curve(Y_val_100, preds_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "408a0cfc-8966-4c2d-a69d-9e8a346e1d72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(1-tpr_100, 1-fpr_100)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "81d22988-934c-4262-b84b-30ed9dcd8ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model: 93.07%\n"
     ]
    }
   ],
   "source": [
    "def pred_accuracy(y_test, predictions):\n",
    "\n",
    "    predictions_list = []\n",
    "    for pred in predictions:\n",
    "        #arbitrary cutoff of 0.5\n",
    "        if float(pred) > 0.5:\n",
    "            predictions_list.append(int(1))\n",
    "        elif float(pred) < 0.5:\n",
    "            predictions_list.append(int(0))\n",
    "            \n",
    "    accuracy = np.mean(predictions_list == y_test)\n",
    "    return accuracy\n",
    "\n",
    "accuracy_model = pred_accuracy(Y_val_100, list(preds_100))\n",
    "print(\"Accuracy of Model: {:.2%}\".format(accuracy_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c06f2567-c949-47bd-a97f-a99468632c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (False):\n",
    "    x_vals_all = []\n",
    "    y_vals_all = []\n",
    "    for m1 in mass_range[1:]:\n",
    "        for m2 in mass_range[1:]:\n",
    "            print(m1,m2)\n",
    "            x_aug_0 = np.append(np.append(x[0,0],m1*np.reshape(np.ones(len(x[0,0])),[len(x[0,0]),1]),1),m2*np.reshape(np.ones(len(x[0,0])),[len(x[0,0]),1]),1)\n",
    "            x_aug_m = np.append(np.append(x[m1,m2],m1*np.reshape(np.ones(len(x[m1,m2])),[len(x[m1,m2]),1]),1),m2*np.reshape(np.ones(len(x[m1,m2])),[len(x[m1,m2]),1]),1)\n",
    "            if (m1==0.5 and m2==0.5):\n",
    "                x_vals_all = np.concatenate([x_aug_0,x_aug_m])\n",
    "                y_vals_all = np.concatenate([np.ones(len(x_aug_0)),np.zeros(len(x_aug_m))])\n",
    "            else:\n",
    "                x_vals_all = np.concatenate([x_vals_all,x_aug_0,x_aug_m])\n",
    "                y_vals_all = np.concatenate([y_vals_all,np.ones(len(x_aug_0)),np.zeros(len(x_aug_m))])\n",
    "\n",
    "    np.save(\"x_vals_all\",x_vals_all)\n",
    "    np.save(\"y_vals_all\",y_vals_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a28cf353-6531-436c-9179-1a934125e35b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.72413866,  1.69355063,  1.11205286, -1.87386705,  6.        ,\n",
       "         6.        ],\n",
       "       [ 0.80799657,  0.66064736, -0.59943671, -2.09319001,  6.        ,\n",
       "         6.        ],\n",
       "       [ 2.17499885, -1.1884174 , -1.60538663, -1.95211824,  6.        ,\n",
       "         6.        ],\n",
       "       ...,\n",
       "       [ 2.25225265, -1.04538567, -1.74062478, -0.42062581,  6.        ,\n",
       "         6.        ],\n",
       "       [ 1.9191695 , -0.87384445, -1.59395235, -2.25172332,  6.        ,\n",
       "         6.        ],\n",
       "       [ 0.04826932,  1.34560735, -0.34342313, -1.79483175,  6.        ,\n",
       "         6.        ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_aug_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff957fc-43eb-4f59-8b86-21b916e9a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewrite cell above to understand\n",
    "x_valls_all = []\n",
    "y_valls_all = []\n",
    "\n",
    "for m1 in mass_range[1:]:\n",
    "    for m2 in mass_range[1:]:\n",
    "        x_aug_0 = np.append(np.append())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f41f4fd9-d932-4bc2-8ead-63d744ccbe76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " ...\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n"
     ]
    }
   ],
   "source": [
    "test = np.append([[1, 2],[3, 4]], [[5, 6]], 0)\n",
    "m1 = 0.5\n",
    "m2 = 0.5\n",
    "m1 = m1 * np.append(x[0,0],m1*np.reshape(np.ones(len(x[0,0])),[len(x[0,0]),1]),1)\n",
    "m2 = m2 * np.reshape(np.ones(len(x[0,0])),[len(x[0,0]),1])\n",
    "print(np.reshape(np.ones(len(x[0,0])),[len(x[0,0]), 1]))\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "281ce20a-e2a0-485f-a59b-3e0e5a9403ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_vals_all = np.load(\"x_vals_all.npy\")\n",
    "y_vals_all = np.load(\"y_vals_all.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c317d279-42ad-4f05-b8ef-914a86a1c20e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27188652, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_vals_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "246a1398-1118-40e5-af3b-1710bb57320c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.08511704, -0.13951411,  0.29623825, -1.38625319,  0.5       ,\n",
       "         0.5       ],\n",
       "       [-0.99621376, -0.3906208 ,  1.87209617, -1.20087092,  0.5       ,\n",
       "         0.5       ],\n",
       "       [-1.10503705,  1.30397829,  1.37879233, -0.51460752,  0.5       ,\n",
       "         0.5       ],\n",
       "       ...,\n",
       "       [ 2.25225265, -1.04538567, -1.74062478, -0.42062581,  6.        ,\n",
       "         6.        ],\n",
       "       [ 1.9191695 , -0.87384445, -1.59395235, -2.25172332,  6.        ,\n",
       "         6.        ],\n",
       "       [ 0.04826932,  1.34560735, -0.34342313, -1.79483175,  6.        ,\n",
       "         6.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad55635-851c-46cc-bbfd-1182f16da2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_all, X_val_all, Y_train_all, Y_val_all = train_test_split(x_vals_all, y_vals_all, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "5b5d5d3f-0523-4911-a7d3-d5abaaaa0f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13594326"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "601d4b1a-2897-465d-9c38-724e3873aaca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gup-singh/Anomaly/runs/210bp1r4\" target=\"_blank\">scarlet-pyramid-42</a></strong> to <a href=\"https://wandb.ai/gup-singh/Anomaly\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not wandb.run:\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"Anomaly\",\n",
    "        group=\"Parametrized\",\n",
    "        entity='gup-singh',\n",
    "\n",
    "        config={\n",
    "            \"layer_1\": 256,\n",
    "            \"activation_1\": \"relu\",\n",
    "            \"layer_2\": 256,\n",
    "            \"activation_2\": \"relu\",\n",
    "            \"layer_3\": 256,\n",
    "            \"activation_3\": \"relu\",\n",
    "            \"output_layer\": 1,\n",
    "            \"output_activation\": \"sigmoid\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"metric\": \"accuracy\",\n",
    "            \"epoch\": 20,\n",
    "            \"batch_size\": 1024\n",
    "        }\n",
    "    )\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f68541d3-0734-4e4a-ab49-3ad591f31744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             multiple                  1792      \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  65792     \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  65792     \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,633\n",
      "Trainable params: 133,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all = MyModel()\n",
    "model_all.build(input_shape=(None, X_train_all.shape[1]))\n",
    "model_all.compile(loss=config.loss, optimizer=config.optimizer, metrics=[\"accuracy\"])\n",
    "model_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d310961a-6cea-4058-9e5b-3cc3e472a4cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/5311 [..............................] - ETA: 1:36:38 - loss: 0.6707 - accuracy: 0.5793WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.\n",
      "5288/5311 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9327"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 12s 2ms/step - loss: 0.1716 - accuracy: 0.9327 - val_loss: 0.1634 - val_accuracy: 0.9358\n",
      "Epoch 2/20\n",
      "5286/5311 [============================>.] - ETA: 0s - loss: 0.1625 - accuracy: 0.9363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1624 - accuracy: 0.9363 - val_loss: 0.1621 - val_accuracy: 0.9364\n",
      "Epoch 3/20\n",
      "5308/5311 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1617 - accuracy: 0.9365 - val_loss: 0.1609 - val_accuracy: 0.9368\n",
      "Epoch 4/20\n",
      "5284/5311 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 0.9367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1613 - accuracy: 0.9367 - val_loss: 0.1609 - val_accuracy: 0.9369\n",
      "Epoch 5/20\n",
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1610 - accuracy: 0.9368 - val_loss: 0.1613 - val_accuracy: 0.9367\n",
      "Epoch 6/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1609 - accuracy: 0.9369 - val_loss: 0.1612 - val_accuracy: 0.9366\n",
      "Epoch 7/20\n",
      "5303/5311 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1607 - accuracy: 0.9369 - val_loss: 0.1602 - val_accuracy: 0.9372\n",
      "Epoch 8/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1606 - accuracy: 0.9370 - val_loss: 0.1602 - val_accuracy: 0.9371\n",
      "Epoch 9/20\n",
      "5292/5311 [============================>.] - ETA: 0s - loss: 0.1604 - accuracy: 0.9370"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1604 - accuracy: 0.9370 - val_loss: 0.1599 - val_accuracy: 0.9373\n",
      "Epoch 10/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1603 - accuracy: 0.9371 - val_loss: 0.1600 - val_accuracy: 0.9372\n",
      "Epoch 11/20\n",
      "5295/5311 [============================>.] - ETA: 0s - loss: 0.1602 - accuracy: 0.9371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1602 - accuracy: 0.9371 - val_loss: 0.1597 - val_accuracy: 0.9373\n",
      "Epoch 12/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1602 - accuracy: 0.9371 - val_loss: 0.1599 - val_accuracy: 0.9372\n",
      "Epoch 13/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1601 - accuracy: 0.9372 - val_loss: 0.1599 - val_accuracy: 0.9372\n",
      "Epoch 14/20\n",
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1600 - accuracy: 0.9372 - val_loss: 0.1602 - val_accuracy: 0.9371\n",
      "Epoch 15/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1599 - accuracy: 0.9372 - val_loss: 0.1599 - val_accuracy: 0.9372\n",
      "Epoch 16/20\n",
      "5301/5311 [============================>.] - ETA: 0s - loss: 0.1599 - accuracy: 0.9372"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1599 - accuracy: 0.9372 - val_loss: 0.1596 - val_accuracy: 0.9374\n",
      "Epoch 17/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1598 - accuracy: 0.9373 - val_loss: 0.1599 - val_accuracy: 0.9372\n",
      "Epoch 18/20\n",
      "5290/5311 [============================>.] - ETA: 0s - loss: 0.1597 - accuracy: 0.9373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1597 - accuracy: 0.9373 - val_loss: 0.1595 - val_accuracy: 0.9374\n",
      "Epoch 19/20\n",
      "5304/5311 [============================>.] - ETA: 0s - loss: 0.1597 - accuracy: 0.9373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230925_124501-210bp1r4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1597 - accuracy: 0.9373 - val_loss: 0.1591 - val_accuracy: 0.9376\n",
      "Epoch 20/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1596 - accuracy: 0.9373 - val_loss: 0.1596 - val_accuracy: 0.9373\n"
     ]
    }
   ],
   "source": [
    "myhistory_all = model_all.fit(x_vals_all, y_vals_all, epochs=config.epoch,validation_data=(X_val_all, Y_val_all),batch_size=config.batch_size*5, callbacks = [WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1c0821b-afa5-4e8c-8836-9af5710f2e24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇▇▇▇███████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▅▅▄▆▆▇▇▇▇▇▆▇▇▆▇█▇</td></tr><tr><td>val_loss</td><td>█▆▄▄▅▄▃▃▂▂▂▂▂▃▂▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.93734</td></tr><tr><td>best_epoch</td><td>18</td></tr><tr><td>best_val_loss</td><td>0.15907</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.1596</td></tr><tr><td>val_accuracy</td><td>0.93729</td></tr><tr><td>val_loss</td><td>0.15963</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">scarlet-pyramid-42</strong>: <a href=\"https://wandb.ai/gup-singh/Anomaly/runs/210bp1r4\" target=\"_blank\">https://wandb.ai/gup-singh/Anomaly/runs/210bp1r4</a><br/>Synced 5 W&B file(s), 1 media file(s), 31 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230925_124501-210bp1r4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e3d75fda-1aa3-4175-bf5e-8ea4af80a0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(myhistory_all.history['loss'])\n",
    "plt.plot(myhistory_all.history['val_loss'])\n",
    "plt.title('Model Loss All')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['loss', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "18f227d8-c1bf-40ad-9bc2-93dadc7e9421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 878us/step\n"
     ]
    }
   ],
   "source": [
    "preds_all = model_all.predict(X_val_all[np.product(X_val_all[:,4:6]==[1.,1.],axis=1)==1],batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "669e8b25-00b9-4ed0-9cf1-edc4d2fa55a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr_all, tpr_all, _ = roc_curve(Y_val_all[np.product(X_val_all[:,4:6]==[1.,1.],axis=1)==1], preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1cb0aa1-9961-4d08-b350-e90d446c85b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1951855/2571013946.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  plt.plot(tpr_100,1./fpr_100,label=\"dedicated_100\")\n",
      "/tmp/ipykernel_1951855/2571013946.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  plt.plot(tpr_all,1./fpr_all,label=\"parameterized\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '$(m_B,m_C) = (100,100)$ GeV Dedicated vs Parametrized')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tpr_100,1./fpr_100,label=\"dedicated_100\")\n",
    "plt.plot(tpr_all,1./fpr_all,label=\"parameterized\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel(\"TPR\")\n",
    "plt.ylabel(\"1/FPR\")\n",
    "plt.title(\"$(m_B,m_C) = (100,100)$ GeV Dedicated vs Parametrized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01828ec5-ae2a-4328-97cc-d001a15b89c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#written by Nachman\n",
    "\n",
    "# for l in model_all.layers:\n",
    "#     l.trainable=False\n",
    "\n",
    "# inputs_hold = tf.keras.Input(shape=(1,))\n",
    "# simple_model = Dense(1,use_bias = False,activation='relu',kernel_initializer=tf.keras.initializers.Constant(2.))(inputs_hold)\n",
    "# model3 = Model(inputs = inputs_hold, outputs = simple_model)\n",
    "\n",
    "# inputs_hold2 = tf.keras.Input(shape=(1,))\n",
    "# simple_model2 = Dense(1,use_bias = False,activation='relu',kernel_initializer=tf.keras.initializers.Constant(3.))(inputs_hold2)\n",
    "# model32 = Model(inputs = inputs_hold2, outputs = simple_model2)\n",
    "\n",
    "# inputs = tf.keras.Input(shape=(4,))\n",
    "# inputs2 = tf.keras.layers.concatenate([inputs,model3(tf.ones_like(inputs)[:,0]),model32(tf.ones_like(inputs)[:,0])])\n",
    "# hidden_layer_1 = model_all(inputs2)\n",
    "# model_all2 = Model(inputs = inputs, outputs = hidden_layer_1)\n",
    "# model_all2.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "733d1d90-3f0c-4fcd-8e65-7f4e760fc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewrite cell above to understand/improve\n",
    "\n",
    "#freezes the layers of the model (i.e all trainable params)\n",
    "for l in model_all.layers:\n",
    "    l.trainable=False\n",
    "\n",
    "#creates models with single node and arbitrary weight\n",
    "def createSimpleModel(weight):\n",
    "    input_layer = tf.keras.Input(shape=(1,))\n",
    "    simple_model = Dense(1,use_bias = False,activation='relu',kernel_initializer=tf.keras.initializers.Constant(weight))(input_layer)\n",
    "    model = Model(inputs=input_layer, outputs=simple_model)\n",
    "    return model\n",
    "\n",
    "model3 = createSimpleModel(2.)\n",
    "model32 = createSimpleModel(3.)\n",
    "\n",
    "#create final model with everything combined\n",
    "inputs = tf.keras.Input(shape=(4,))\n",
    "concatenated_inputs = tf.keras.layers.concatenate([inputs, model3(tf.ones_like(inputs)[:,0]), model32(tf.ones_like(inputs)[:,0])])\n",
    "hidden_layer_1 = model_all(concatenated_inputs)\n",
    "model_all2 = Model(inputs = inputs, outputs = hidden_layer_1)\n",
    "model_all2.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf95eba7-4755-4824-bb4b-334ce7dc6bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.ones_like (TFOpLambda)      (None, 4)            0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.ones_like_1 (TFOpLambda)    (None, 4)            0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None,)             0           ['tf.ones_like[0][0]']           \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None,)             0           ['tf.ones_like_1[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 1)            1           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 1)            1           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6)            0           ['input_3[0][0]',                \n",
      "                                                                  'model[0][0]',                  \n",
      "                                                                  'model_1[0][0]']                \n",
      "                                                                                                  \n",
      " my_model_1 (MyModel)           (None, 1)            133633      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 133,635\n",
      "Trainable params: 2\n",
      "Non-trainable params: 133,633\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50cbf1ec-4e5d-4d3f-a6ac-a76f1610d700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_8/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[2.]], dtype=float32)>,\n",
       " <tf.Variable 'dense_9/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[3.]], dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all2.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8977578-3a67-4201-bcb8-b2711f0c5727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 2.9198 - val_loss: 2.2686\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.2027 - val_loss: 2.1457\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.1269 - val_loss: 2.1030\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.0928 - val_loss: 2.0766\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.0679 - val_loss: 2.0528\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.0439 - val_loss: 2.0273\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.0183 - val_loss: 2.0014\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.9936 - val_loss: 1.9785\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.9734 - val_loss: 1.9606\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.9591 - val_loss: 1.9493\n"
     ]
    }
   ],
   "source": [
    "myhistory_all2 = model_all2.fit(x_vals_100[:,0:4], y_vals_100, epochs=10,validation_data=(X_val_100[:,0:4], Y_val_100),batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b237e289-dbc5-44dd-b930-225d88689107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SingleWeightLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, initial_value=1, **kwargs):\n",
    "        super(SingleWeightLayer, self).__init__(**kwargs)\n",
    "        self.initial_value = initial_value\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.weight = self.add_weight(shape=(1,), initializer=tf.keras.initializers.Constant(self.initial_value), trainable=True)\n",
    "    \n",
    "    def call(self, inputs):            \n",
    "        output = inputs * self.weight\n",
    "        return tf.nn.relu(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9461ad60-fe52-4dfd-bf18-586a8e5a8c36",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 1.9636 - val_loss: 0.7950\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.7421 - val_loss: 0.7060\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.6813 - val_loss: 0.6601\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.6411 - val_loss: 0.6263\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.6062\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5993 - val_loss: 0.5947\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5899 - val_loss: 0.5871\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5836 - val_loss: 0.5821\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5793 - val_loss: 0.5789\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5765 - val_loss: 0.5764\n",
      "0.5 0.5 0.49042767 9.830067\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 1.5131 - val_loss: 0.8873\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.8456 - val_loss: 0.8111\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.8005 - val_loss: 0.7800\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7693 - val_loss: 0.7498\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7443 - val_loss: 0.7310\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7307 - val_loss: 0.7216\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7240 - val_loss: 0.7170\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7208 - val_loss: 0.7148\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7194 - val_loss: 0.7140\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7187 - val_loss: 0.7132\n",
      "0.5 1 0.88938004 9.238634\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 1.1090 - val_loss: 0.8350\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7883 - val_loss: 0.7554\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7454 - val_loss: 0.7286\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7202 - val_loss: 0.7056\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6998 - val_loss: 0.6891\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6868 - val_loss: 0.6791\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6790 - val_loss: 0.6731\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6743 - val_loss: 0.6697\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6718 - val_loss: 0.6679\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6705 - val_loss: 0.6672\n",
      "0.5 1.5 1.4304806 9.517697\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.9500 - val_loss: 0.8020\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7461 - val_loss: 0.7138\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6997 - val_loss: 0.6882\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6766 - val_loss: 0.6665\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6571 - val_loss: 0.6493\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6433 - val_loss: 0.6388\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6351 - val_loss: 0.6326\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.6289\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6278 - val_loss: 0.6269\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6262 - val_loss: 0.6260\n",
      "0.5 2 1.9689283 9.606061\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 1.0694 - val_loss: 1.0420\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.0412 - val_loss: 1.0420\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.0412 - val_loss: 1.0419\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.0412 - val_loss: 1.0423\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.0413 - val_loss: 1.0420\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.0413 - val_loss: 1.0422\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.0414 - val_loss: 1.0419\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.0413 - val_loss: 1.0419\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.0412 - val_loss: 1.0420\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 1.0413 - val_loss: 1.0429\n",
      "0.5 2.5 2.4731803 2.60734\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 0.9847 - val_loss: 0.9061\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.9059\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.9059\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.9059\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.9059\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.9060\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.9041 - val_loss: 0.9060\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.9061\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.9061\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.9060\n",
      "0.5 3 2.9433212 3.1263187\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.9931 - val_loss: 0.7826\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7845 - val_loss: 0.7826\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7845 - val_loss: 0.7827\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7845 - val_loss: 0.7827\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7845 - val_loss: 0.7826\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7845 - val_loss: 0.7826\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7846 - val_loss: 0.7826\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7845 - val_loss: 0.7826\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7845 - val_loss: 0.7826\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7846 - val_loss: 0.7826\n",
      "0.5 3.5 3.4188526 3.6357832\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 1.1289 - val_loss: 0.7019\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6955 - val_loss: 0.7017\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6954 - val_loss: 0.7017\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6955 - val_loss: 0.7017\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6955 - val_loss: 0.7017\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6955 - val_loss: 0.7017\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6955 - val_loss: 0.7017\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6955 - val_loss: 0.7017\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6955 - val_loss: 0.7017\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6956 - val_loss: 0.7017\n",
      "0.5 4 3.8713343 4.1940656\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 1.3296 - val_loss: 0.6870\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6290 - val_loss: 0.6295\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.6294\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.6294\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.6294\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.6294\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6240 - val_loss: 0.6294\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6240 - val_loss: 0.6294\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.6295\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6240 - val_loss: 0.6294\n",
      "0.5 4.5 4.3091354 4.700434\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.5398 - val_loss: 0.7324\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.5813\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.5812\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.5812\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.5812\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.5812\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.5812\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.5812\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.5812\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.5812\n",
      "0.5 5 4.765122 5.1791496\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 2ms/step - loss: 1.7290 - val_loss: 0.9082\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.5428\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.5422\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.5422\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.5422\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.5422\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.5422\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.5422\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.5422\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.5422\n",
      "0.5 5.5 5.222106 5.6245484\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 1s 2ms/step - loss: 1.7863 - val_loss: 1.1588\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.6895 - val_loss: 0.5304\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5170 - val_loss: 0.5168\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5168\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5168\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5168\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5168\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5168\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5168\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5168\n",
      "0.5 6 5.6688843 6.0374393\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 1.5154 - val_loss: 0.8959\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.8486 - val_loss: 0.8189\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.8042 - val_loss: 0.7885\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7739 - val_loss: 0.7588\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7488 - val_loss: 0.7392\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7342 - val_loss: 0.7292\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7268 - val_loss: 0.7244\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7232 - val_loss: 0.7221\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7214 - val_loss: 0.7207\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7205 - val_loss: 0.7201\n",
      "1 0.5 0.87079334 9.246256\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 1.0515 - val_loss: 0.5034\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.4476\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.4267\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4168 - val_loss: 0.4094\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4036 - val_loss: 0.4002\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3971 - val_loss: 0.3961\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.3938\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3922 - val_loss: 0.3927\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.3919\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3909 - val_loss: 0.3916\n",
      "1 1 0.9875063 9.034551\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.8189 - val_loss: 0.5998\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5659 - val_loss: 0.5455\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5345 - val_loss: 0.5196\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4903 - val_loss: 0.4690\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.4539\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.4460\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4446 - val_loss: 0.4419\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.4396\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4397 - val_loss: 0.4385\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 0.4377\n",
      "1 1.5 1.0557623 10.506565\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.7432 - val_loss: 0.6454\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5974 - val_loss: 0.5797\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5646 - val_loss: 0.5594\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5486 - val_loss: 0.5469\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.5406\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5353 - val_loss: 0.5374\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5331 - val_loss: 0.5358\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5320 - val_loss: 0.5353\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 0.5349\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5315 - val_loss: 0.5348\n",
      "1 2 1.9337032 9.006684\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.7665 - val_loss: 0.7446\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7467 - val_loss: 0.7446\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7467 - val_loss: 0.7446\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7467 - val_loss: 0.7447\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7468 - val_loss: 0.7448\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7467 - val_loss: 0.7446\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7468 - val_loss: 0.7446\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7467 - val_loss: 0.7446\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7468 - val_loss: 0.7446\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7468 - val_loss: 0.7447\n",
      "1 2.5 2.4186785 2.554087\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.3236 - val_loss: 0.1848\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1848\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1848\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1849\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1848\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1850\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1849\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1849\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1849\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1848\n",
      "1 3 0.99883246 3.0278702\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 0.3652 - val_loss: 0.1839\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1857 - val_loss: 0.1839\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1857 - val_loss: 0.1839\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1857 - val_loss: 0.1839\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1857 - val_loss: 0.1839\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1857 - val_loss: 0.1839\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1857 - val_loss: 0.1840\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1858 - val_loss: 0.1840\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1857 - val_loss: 0.1840\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1857 - val_loss: 0.1840\n",
      "1 3.5 0.989777 3.51841\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.4689 - val_loss: 0.1858\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1862 - val_loss: 0.1848\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.1848\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.1849\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.1848\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.1848\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.1849\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.1848\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.1848\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.1848\n",
      "1 4 0.99720615 4.0226173\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.5763 - val_loss: 0.1991\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1894 - val_loss: 0.1902\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.1902\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.1902\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.1902\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.1902\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.1902\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.1902\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.1903\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.1902\n",
      "1 4.5 1.002153 4.5228796\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.6905 - val_loss: 0.2487\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2036 - val_loss: 0.1951\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.1951\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.1952\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.1952\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.1951\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.1951\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.1952\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.1951\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.1952\n",
      "1 5 0.9876942 5.009871\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.7715 - val_loss: 0.3270\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2351 - val_loss: 0.1953\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1952 - val_loss: 0.1941\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.1941\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.1941\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.1941\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.1941\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.1941\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.1943\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.1941\n",
      "1 5.5 0.9864196 5.518501\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.8225 - val_loss: 0.3886\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.2802 - val_loss: 0.2044\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1985 - val_loss: 0.1970\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1969 - val_loss: 0.1970\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1969 - val_loss: 0.1970\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1969 - val_loss: 0.1970\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1969 - val_loss: 0.1970\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1969 - val_loss: 0.1970\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1969 - val_loss: 0.1970\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1969 - val_loss: 0.1970\n",
      "1 6 0.9805792 6.013573\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 1.0810 - val_loss: 0.8251\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.7710 - val_loss: 0.7446\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.7280 - val_loss: 0.7187\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.7041 - val_loss: 0.6963\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6836 - val_loss: 0.6792\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6701 - val_loss: 0.6688\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6625\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6570 - val_loss: 0.6587\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6541 - val_loss: 0.6565\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6524 - val_loss: 0.6554\n",
      "1.5 0.5 1.4414834 9.489062\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.8191 - val_loss: 0.6058\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5682 - val_loss: 0.5480\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5341 - val_loss: 0.5115\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.4614\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.4470\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.4396\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.4358\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4349 - val_loss: 0.4338\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.4327\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.4321\n",
      "1.5 1 1.0541543 10.506485\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.3225 - val_loss: 0.1264\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.1264\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.1263\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.1263\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.1264\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.1264\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.1263\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.1263\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.1264\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.1264\n",
      "1.5 1.5 1.4711738 1.5460074\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.2198 - val_loss: 0.1438\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1438\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1438\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1438\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1438\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1438\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1440\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1438\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1441\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1437 - val_loss: 0.1438\n",
      "1.5 2 1.4862487 2.0168087\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.1882 - val_loss: 0.1527\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1527\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1528\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1527\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1526\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1527\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1527\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1527\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1529\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1520 - val_loss: 0.1526\n",
      "1.5 2.5 1.4990414 2.523871\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.1739 - val_loss: 0.1542\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.1542\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1541\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.1542\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.1541\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1541\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1542\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.1543\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.1542\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.1542\n",
      "1.5 3 1.5035286 3.038936\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.1919 - val_loss: 0.1559\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1581 - val_loss: 0.1559\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1581 - val_loss: 0.1560\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1559\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1560\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1559\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1581 - val_loss: 0.1559\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1559\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1560\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1560\n",
      "1.5 3.5 1.507543 3.5360184\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.2379 - val_loss: 0.1586\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1585\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1585\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1585\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1585\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1585\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1585\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1585\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1585\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1585\n",
      "1.5 4 1.4972202 4.0328665\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.3034 - val_loss: 0.1654\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1634\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1634\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1634\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1634\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1634\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1634\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1634\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1634\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1634\n",
      "1.5 4.5 1.4875894 4.5241942\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.3732 - val_loss: 0.1921\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1702 - val_loss: 0.1666\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1666\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1666\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1666\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1666\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1666\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1666\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1666\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1667\n",
      "1.5 5 1.5049258 5.018764\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.4415 - val_loss: 0.2629\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1923 - val_loss: 0.1705\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1711 - val_loss: 0.1703\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1711 - val_loss: 0.1703\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1711 - val_loss: 0.1703\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1711 - val_loss: 0.1703\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1711 - val_loss: 0.1703\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1711 - val_loss: 0.1703\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1711 - val_loss: 0.1703\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1711 - val_loss: 0.1704\n",
      "1.5 5.5 1.5031456 5.508186\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.4915 - val_loss: 0.3248\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.2313 - val_loss: 0.1782\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1756 - val_loss: 0.1748\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1748\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1748\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1748\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1749\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1749\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1749\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1749\n",
      "1.5 6 1.4839475 6.0074267\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 0.9002 - val_loss: 0.7658\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.7101 - val_loss: 0.6776\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.6634 - val_loss: 0.6520\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.6414 - val_loss: 0.6320\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.6160\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.6089 - val_loss: 0.6046\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.5974\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5943 - val_loss: 0.5931\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5909 - val_loss: 0.5905\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5891 - val_loss: 0.5890\n",
      "2 0.5 1.9817356 9.547328\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.7383 - val_loss: 0.6352\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5928 - val_loss: 0.5717\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5602 - val_loss: 0.5516\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5444 - val_loss: 0.5396\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5354 - val_loss: 0.5332\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 0.5302\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5286 - val_loss: 0.5289\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 0.5282\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 0.5275\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 0.5279\n",
      "2 1 1.9218352 8.973688\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 0.2180 - val_loss: 0.1427\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.1427\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.1427\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.1428\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.1427\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1425 - val_loss: 0.1427\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1425 - val_loss: 0.1427\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1425 - val_loss: 0.1427\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1425 - val_loss: 0.1427\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1425 - val_loss: 0.1428\n",
      "2 1.5 1.4812353 2.0026138\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.1430 - val_loss: 0.1143\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1143\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1143\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.1143\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1143\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1144\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1143\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1143\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1144\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1143\n",
      "2 2 1.9611696 2.032676\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.1368 - val_loss: 0.1292\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1290\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1290\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1291\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1306 - val_loss: 0.1290\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1290\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1291\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1291\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1292\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1292\n",
      "2 2.5 1.9788939 2.5292587\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.1389 - val_loss: 0.1394\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.1393\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1390 - val_loss: 0.1393\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.1394\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1390 - val_loss: 0.1393\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.1394\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.1394\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1390 - val_loss: 0.1393\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.1394\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.1393\n",
      "2 3 2.0028071 3.0156934\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 0.1505 - val_loss: 0.1440\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1446 - val_loss: 0.1439\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1447 - val_loss: 0.1441\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1447 - val_loss: 0.1440\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1446 - val_loss: 0.1440\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1447 - val_loss: 0.1440\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1446 - val_loss: 0.1439\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1447 - val_loss: 0.1440\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1447 - val_loss: 0.1441\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1446 - val_loss: 0.1440\n",
      "2 3.5 1.995718 3.5027125\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.1826 - val_loss: 0.1524\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1523\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1524\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1524\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1523\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1523\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1525\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1523\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1523\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1523\n",
      "2 4 1.9908515 4.035007\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.2294 - val_loss: 0.1539\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1538\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1537\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1537\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1537\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.1537\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1537\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1539\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.1538\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1537\n",
      "2 4.5 1.9886546 4.53545\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.2896 - val_loss: 0.1677\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1574\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1574\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1577\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1574\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1575\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1575 - val_loss: 0.1576\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1575 - val_loss: 0.1575\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1575 - val_loss: 0.1575\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1575 - val_loss: 0.1576\n",
      "2 5 1.9785358 5.0239515\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 2ms/step - loss: 0.3533 - val_loss: 0.2245\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1630\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1638 - val_loss: 0.1629\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1638 - val_loss: 0.1629\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1638 - val_loss: 0.1630\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1638 - val_loss: 0.1630\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1638 - val_loss: 0.1629\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1638 - val_loss: 0.1629\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1630\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1638 - val_loss: 0.1630\n",
      "2 5.5 1.9838927 5.528451\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.3935 - val_loss: 0.2758\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.2005 - val_loss: 0.1658\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1644 - val_loss: 0.1647\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1642 - val_loss: 0.1648\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1641 - val_loss: 0.1647\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1642 - val_loss: 0.1647\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1642 - val_loss: 0.1647\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1642 - val_loss: 0.1647\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1642 - val_loss: 0.1649\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1642 - val_loss: 0.1647\n",
      "2 6 1.9946772 6.0250087\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.9582 - val_loss: 0.9343\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9343\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9344\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9343\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9344\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9346\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9344\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9343\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9321 - val_loss: 0.9344\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9343\n",
      "2.5 0.5 2.4618433 2.6016176\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.7517 - val_loss: 0.7317\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7317 - val_loss: 0.7317\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7317 - val_loss: 0.7317\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7318 - val_loss: 0.7318\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7317 - val_loss: 0.7317\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7317 - val_loss: 0.7317\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7317 - val_loss: 0.7317\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7318 - val_loss: 0.7318\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7318 - val_loss: 0.7317\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7318 - val_loss: 0.7319\n",
      "2.5 1 2.4148767 2.5469017\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.1887 - val_loss: 0.1511\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1511\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1512\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1511\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1511\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1512\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1511\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1514\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1518 - val_loss: 0.1512\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1518 - val_loss: 0.1511\n",
      "2.5 1.5 1.4957068 2.5137317\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.1365 - val_loss: 0.1313\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1300 - val_loss: 0.1313\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.1313\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.1313\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.1313\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1300 - val_loss: 0.1313\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.1313\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1300 - val_loss: 0.1313\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.1314\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.1313\n",
      "2.5 2 1.9906733 2.5188606\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 0.1156 - val_loss: 0.1094\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1085 - val_loss: 0.1095\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1094\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1085 - val_loss: 0.1095\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1095\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1095\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1095\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1095\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1095\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1094\n",
      "2.5 2.5 2.4531248 2.5512555\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 0.1276 - val_loss: 0.1206\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1205\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1205\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1205\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1219 - val_loss: 0.1205\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1219 - val_loss: 0.1207\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1219 - val_loss: 0.1211\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1205\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1205\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1212\n",
      "2.5 3 2.450097 3.048805\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.1493 - val_loss: 0.1334\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 0.1334\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 0.1333\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 0.1334\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 0.1334\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 0.1335\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1351 - val_loss: 0.1334\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 0.1335\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 0.1334\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1351 - val_loss: 0.1334\n",
      "2.5 3.5 2.4881632 3.5325353\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.1824 - val_loss: 0.1417\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1417\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1417\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1417\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1417\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1417\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1417\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1418\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1419\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1415 - val_loss: 0.1418\n",
      "2.5 4 2.501822 4.0066757\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.2439 - val_loss: 0.1459\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1458\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1458\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1459\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1458\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1459\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1458\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1459\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1458\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.1458\n",
      "2.5 4.5 2.4862957 4.5411024\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.1925\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1560 - val_loss: 0.1527\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1527\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1526\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1527\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1527\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1526\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1526\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1526\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1527\n",
      "2.5 5 2.4802544 5.0473547\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.4355 - val_loss: 0.2993\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1967 - val_loss: 0.1565\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1561\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1561\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1562\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1561\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1561\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1562\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1562\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1561\n",
      "2.5 5.5 2.4924817 5.5164332\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.4856 - val_loss: 0.3772\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2562 - val_loss: 0.1697\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1601 - val_loss: 0.1598\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1599\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1585 - val_loss: 0.1598\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1598\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1599\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1598\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1598\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1598\n",
      "2.5 6 2.4919803 6.019496\n",
      "Epoch 1/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.8431 - val_loss: 0.7704\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.7667 - val_loss: 0.7705\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.7667 - val_loss: 0.7704\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.7668 - val_loss: 0.7704\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.7667 - val_loss: 0.7705\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.7667 - val_loss: 0.7705\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.7668 - val_loss: 0.7705\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.7668 - val_loss: 0.7708\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.7667 - val_loss: 0.7707\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.7668 - val_loss: 0.7704\n",
      "3 0.5 2.9418948 3.1273167\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3189 - val_loss: 0.1764\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1763\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1764\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1768\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1787 - val_loss: 0.1766\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1764\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1764\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1764\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1764\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1764\n",
      "3 1 0.9958146 3.0340867\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.1728 - val_loss: 0.1529\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1528\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1529\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1528\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1528\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1529\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1536 - val_loss: 0.1528\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.1531\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1536 - val_loss: 0.1529\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1536 - val_loss: 0.1529\n",
      "3 1.5 1.4937689 3.031302\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.1381 - val_loss: 0.1390\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1390\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1388\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1390\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1391\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1389\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1395\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1390\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1391\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1390\n",
      "3 2 2.0096166 3.0067217\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.1288 - val_loss: 0.1245\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.1245\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.1243\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.1244\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1233 - val_loss: 0.1245\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.1243\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1233 - val_loss: 0.1244\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.1243\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1233 - val_loss: 0.1243\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 0.1244\n",
      "3 2.5 2.4847486 3.0022345\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.1244 - val_loss: 0.1080\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1080\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1080\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1080\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1081\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1080\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1077 - val_loss: 0.1080\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1080\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1080\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1081\n",
      "3 3 2.9279726 3.0502694\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.1531 - val_loss: 0.1225\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 3ms/step - loss: 0.1209 - val_loss: 0.1226\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1208 - val_loss: 0.1225\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1225\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1225\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1227\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1226\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1226\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1226\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1226\n",
      "3 3.5 3.0091012 3.5188482\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 6ms/step - loss: 0.2039 - val_loss: 0.1358\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1335 - val_loss: 0.1358\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1335 - val_loss: 0.1358\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1358\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1358\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1335 - val_loss: 0.1358\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1361\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1358\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1358\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1358\n",
      "3 4 2.9941998 4.0436625\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.2645 - val_loss: 0.1395\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1389\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1389\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1389\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1389\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1389\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1389\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1389\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1393 - val_loss: 0.1390\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1391\n",
      "3 4.5 2.9657063 4.5549893\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.1723\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1484 - val_loss: 0.1456\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1455\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1455\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1459 - val_loss: 0.1456\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1455\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1456\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1459 - val_loss: 0.1455\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1459 - val_loss: 0.1455\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1456\n",
      "3 5 2.9820466 5.053615\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.3969 - val_loss: 0.2453\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1690 - val_loss: 0.1530\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1530\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1530\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1530\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1530\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1530\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1530\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1531\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1530\n",
      "3 5.5 2.974298 5.5551457\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.4350 - val_loss: 0.2981\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2004 - val_loss: 0.1551\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1547 - val_loss: 0.1546\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1546\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1546\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1546\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1546\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1546\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1547\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1546\n",
      "3 6 2.9807773 6.02407\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.8138 - val_loss: 0.6260\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.6260\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.6260\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.6260\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.6260\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.6260\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.6260\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.6260\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.6260\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.6261\n",
      "3.5 0.5 3.4066985 3.632552\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.1792\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1788 - val_loss: 0.1792\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1788 - val_loss: 0.1793\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1792\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1788 - val_loss: 0.1792\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1792\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1793\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1788 - val_loss: 0.1792\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1793\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1788 - val_loss: 0.1794\n",
      "3.5 1 0.984263 3.5033648\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1893 - val_loss: 0.1563\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1557 - val_loss: 0.1563\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1557 - val_loss: 0.1563\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1557 - val_loss: 0.1563\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1557 - val_loss: 0.1563\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1557 - val_loss: 0.1564\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1558 - val_loss: 0.1563\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1558 - val_loss: 0.1563\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1558 - val_loss: 0.1563\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1559 - val_loss: 0.1563\n",
      "3.5 1.5 1.4979563 3.5219731\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.1506 - val_loss: 0.1461\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1462\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1461\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1461\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1463\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1462\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1461\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1461\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1461\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1449 - val_loss: 0.1461\n",
      "3.5 2 1.9846549 3.5338793\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.1483 - val_loss: 0.1329\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1330\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1330\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1329\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1330\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1329\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1330\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1329\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1329\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1329\n",
      "3.5 2.5 2.4904723 3.5245671\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.1501 - val_loss: 0.1191\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1191\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1191\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1191\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1191\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1191\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1191\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1193 - val_loss: 0.1191\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1192\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1193 - val_loss: 0.1191\n",
      "3.5 3 2.9825935 3.5218196\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.1877 - val_loss: 0.1138\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1099 - val_loss: 0.1085\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1085\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1085\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1085\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1085\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1085\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1085\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1085\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1085\n",
      "3.5 3.5 3.4136543 3.5762048\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.2552 - val_loss: 0.1332\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1242 - val_loss: 0.1225\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1224\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1224\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1224\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1224\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1224\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1224\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1224\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1224\n",
      "3.5 4 3.4795387 4.0346913\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.3354 - val_loss: 0.1765\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1386\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.1340\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1351 - val_loss: 0.1339\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1351 - val_loss: 0.1339\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1351 - val_loss: 0.1339\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1351 - val_loss: 0.1339\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1351 - val_loss: 0.1340\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1351 - val_loss: 0.1339\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1351 - val_loss: 0.1339\n",
      "3.5 4.5 3.4806347 4.5364356\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4059 - val_loss: 0.2297\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2131 - val_loss: 0.1863\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1591 - val_loss: 0.1440\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1426 - val_loss: 0.1426\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.1427\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.1427\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.1426\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.1426\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.1429\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.1427\n",
      "3.5 5 3.4636996 5.037525\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.4586 - val_loss: 0.2761\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2652 - val_loss: 0.2501\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2177 - val_loss: 0.1757\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1573 - val_loss: 0.1488\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1491 - val_loss: 0.1481\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1481\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1481\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1481\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1481\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1481\n",
      "3.5 5.5 3.474638 5.526655\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.4865 - val_loss: 0.3073\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2989 - val_loss: 0.2917\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2691 - val_loss: 0.2399\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1987 - val_loss: 0.1662\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.1521\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1517\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1516\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1516\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1516\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1516\n",
      "3.5 6 3.4769187 6.031376\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.8898 - val_loss: 0.5277\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 0.5205\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5206\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5206\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5205\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5206\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5205\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5206\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5206\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5205\n",
      "4 0.5 3.8819275 4.1506495\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.4516 - val_loss: 0.1801\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1789\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1789\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1789\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1789\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1789\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1789\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1790\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1791\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1789\n",
      "4 1 0.99801075 4.0260496\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2349 - val_loss: 0.1561\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1561\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1561\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1561\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1561\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1561\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1561\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1561\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1561\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1561\n",
      "4 1.5 1.4936771 4.0177536\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1800 - val_loss: 0.1512\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1512\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1512\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.1513\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1512\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1514\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1512\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1514\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1513\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1512\n",
      "4 2 1.9989278 4.028368\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.1808 - val_loss: 0.1406\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.1405\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.1405\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.1405\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.1407\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.1406\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.1405\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.1405\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.1405\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.1406\n",
      "4 2.5 2.5054343 4.0126653\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.2022 - val_loss: 0.1325\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1324\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1325\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1325\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1325\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1325\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1326\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1325\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1325\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1327 - val_loss: 0.1325\n",
      "4 3 2.9861097 4.0184717\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.2524 - val_loss: 0.1335\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1228 - val_loss: 0.1223\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1221\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1221\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1221\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1221\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1221\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1221\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1221\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1221\n",
      "4 3.5 3.469976 4.0229278\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.3270 - val_loss: 0.1565\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1302 - val_loss: 0.1132\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1124 - val_loss: 0.1120\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1119\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1120\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1119\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1119\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1119\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1119\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1119\n",
      "4 4 3.9243522 4.0849676\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.4230 - val_loss: 0.1808\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1434 - val_loss: 0.1262\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1244 - val_loss: 0.1252\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.1252\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.1252\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.1252\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.1252\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.1252\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.1252\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.1252\n",
      "4 4.5 3.9787028 4.536387\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.5177 - val_loss: 0.2333\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1771 - val_loss: 0.1512\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1430 - val_loss: 0.1371\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1366 - val_loss: 0.1356\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1355\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1355\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1355\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1355\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1355\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1356\n",
      "4 5 3.987902 5.0367126\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 0.5766 - val_loss: 0.2762\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2206 - val_loss: 0.2024\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1847 - val_loss: 0.1665\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1470\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1442 - val_loss: 0.1454\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1437 - val_loss: 0.1454\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1437 - val_loss: 0.1453\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1437 - val_loss: 0.1454\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1437 - val_loss: 0.1453\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1437 - val_loss: 0.1454\n",
      "4 5.5 3.9796848 5.5261946\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 1s 2ms/step - loss: 0.6179 - val_loss: 0.3123\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2559 - val_loss: 0.2384\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2292 - val_loss: 0.2146\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.1698\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1492\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1473 - val_loss: 0.1472\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1467 - val_loss: 0.1472\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1466 - val_loss: 0.1472\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1467 - val_loss: 0.1472\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1467 - val_loss: 0.1472\n",
      "4 6 3.9579418 6.0410585\n",
      "Epoch 1/10\n",
      "156/156 [==============================] - 1s 3ms/step - loss: 0.9812 - val_loss: 0.5351\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.4349\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4349\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4349\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4349\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4349\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4349\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4349\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4349\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4351\n",
      "4.5 0.5 4.355761 4.6727653\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5491 - val_loss: 0.1912\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1821 - val_loss: 0.1810\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1802 - val_loss: 0.1810\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1802 - val_loss: 0.1810\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1802 - val_loss: 0.1810\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1802 - val_loss: 0.1811\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1802 - val_loss: 0.1811\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1802 - val_loss: 0.1811\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1802 - val_loss: 0.1810\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1803 - val_loss: 0.1810\n",
      "4.5 1 0.9963216 4.525608\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.2901 - val_loss: 0.1609\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1584 - val_loss: 0.1588\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1588\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1588\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1588\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1588\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1588\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1589\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1589\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1589\n",
      "4.5 1.5 1.500343 4.531093\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2211 - val_loss: 0.1536\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.1529\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.1528\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.1529\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.1530\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.1531\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1514 - val_loss: 0.1530\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.1529\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.1528\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.1529\n",
      "4.5 2 1.996612 4.5247464\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.2345 - val_loss: 0.1468\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1468\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1467\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1468\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1468\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1468\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1467\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1470\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1467\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1469\n",
      "4.5 2.5 2.5008526 4.563155\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.2682 - val_loss: 0.1417\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1405\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1405\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1405\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1405\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1405\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1405\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1405\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1405\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1405\n",
      "4.5 3 2.9966054 4.5363507\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.3290 - val_loss: 0.1741\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1542 - val_loss: 0.1383\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1353 - val_loss: 0.1338\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.1337\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.1337\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.1337\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.1338\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.1338\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.1337\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.1338\n",
      "4.5 3.5 3.4963346 4.550709\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4222 - val_loss: 0.1823\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1429 - val_loss: 0.1252\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1239 - val_loss: 0.1241\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1236 - val_loss: 0.1240\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1235 - val_loss: 0.1240\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 3ms/step - loss: 0.1235 - val_loss: 0.1240\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1235 - val_loss: 0.1240\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1235 - val_loss: 0.1240\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1235 - val_loss: 0.1240\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1235 - val_loss: 0.1240\n",
      "4.5 4 3.9648728 4.538997\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.5169 - val_loss: 0.1788\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1552 - val_loss: 0.1313\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1205 - val_loss: 0.1140\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.1137\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1136\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1136\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1136\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1136\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1136\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1136\n",
      "4.5 4.5 4.41913 4.5898046\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.6309 - val_loss: 0.2152\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1714 - val_loss: 0.1383\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.1252\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1250\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1251\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1250\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1251\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1250\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1251\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1250\n",
      "4.5 5 4.465998 5.0215206\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.7197 - val_loss: 0.2782\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.2069 - val_loss: 0.1607\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 0.1431\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1384\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1371 - val_loss: 0.1377\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.1376\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.1376\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.1376\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.1376\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.1377\n",
      "4.5 5.5 4.4756827 5.548529\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.7604 - val_loss: 0.3100\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.2392 - val_loss: 0.1903\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1827 - val_loss: 0.1717\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1605 - val_loss: 0.1489\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1442 - val_loss: 0.1404\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1404 - val_loss: 0.1393\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1392\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1392\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1392\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1392\n",
      "4.5 6 4.452882 6.0446663\n",
      "Epoch 1/10\n",
      "151/151 [==============================] - 1s 3ms/step - loss: 1.0410 - val_loss: 0.5621\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.4282 - val_loss: 0.3670\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.3663\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3663\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3663\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3663\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.3664\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.3664\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3664\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3675 - val_loss: 0.3663\n",
      "5 0.5 4.789882 5.1517525\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.6479 - val_loss: 0.2465\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1958 - val_loss: 0.1821\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1815 - val_loss: 0.1819\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1815 - val_loss: 0.1819\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1815 - val_loss: 0.1819\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1815 - val_loss: 0.1819\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1814 - val_loss: 0.1819\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1815 - val_loss: 0.1819\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1815 - val_loss: 0.1821\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1815 - val_loss: 0.1819\n",
      "5 1 0.98899585 5.0374217\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.1939\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1684 - val_loss: 0.1658\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1657\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1658\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1658\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1658\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1658\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1644 - val_loss: 0.1657\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1644 - val_loss: 0.1658\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1644 - val_loss: 0.1658\n",
      "5 1.5 1.4922136 5.025995\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.2849 - val_loss: 0.1666\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1578 - val_loss: 0.1548\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1548\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1548\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1548\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1550\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1548\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1564 - val_loss: 0.1548\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1548\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1549\n",
      "5 2 1.9734519 5.0164237\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 2ms/step - loss: 0.3549 - val_loss: 0.1943\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.1492\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 0.1492\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 0.1492\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 0.1492\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 0.1493\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 0.1492\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 0.1493\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.1492\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.1492\n",
      "5 2.5 2.4824774 5.0353327\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.3381 - val_loss: 0.1775\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1460\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1459\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1459\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1459\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1457 - val_loss: 0.1459\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1459\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1459\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1459\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1460\n",
      "5 3 2.9724264 5.026722\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.2272\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2117 - val_loss: 0.1849\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1590 - val_loss: 0.1415\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1425 - val_loss: 0.1399\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.1399\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.1399\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.1399\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 3ms/step - loss: 0.1421 - val_loss: 0.1399\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.1399\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.1399\n",
      "5 3.5 3.4627924 5.0226493\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.2308\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1741 - val_loss: 0.1509\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1412 - val_loss: 0.1366\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1343 - val_loss: 0.1346\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1337 - val_loss: 0.1345\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1345\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1346\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1346\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1345\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1337 - val_loss: 0.1346\n",
      "5 4 3.98126 5.0368567\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.6290 - val_loss: 0.2147\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1397\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1288 - val_loss: 0.1270\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.1268\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1268\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1268\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1268\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1267\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1268\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1267\n",
      "5 4.5 4.468297 5.017813\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 0.7570 - val_loss: 0.2197\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1716 - val_loss: 0.1515\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1343 - val_loss: 0.1231\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1183 - val_loss: 0.1185\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.1184\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1168 - val_loss: 0.1183\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1183\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1183\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1183\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1183\n",
      "5 5 4.912859 5.071005\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.8770 - val_loss: 0.2973\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1991 - val_loss: 0.1603\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1402 - val_loss: 0.1291\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1259 - val_loss: 0.1261\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1260\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1260\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1260\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1260\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1260\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1260\n",
      "5 5.5 4.9489937 5.525452\n",
      "Epoch 1/10\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.9335 - val_loss: 0.3487\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2375 - val_loss: 0.1795\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1545 - val_loss: 0.1404\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1370 - val_loss: 0.1337\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1317\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1320 - val_loss: 0.1312\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1312\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1312\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1312\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1312\n",
      "5 6 4.958949 6.0333285\n",
      "Epoch 1/10\n",
      "146/146 [==============================] - 1s 3ms/step - loss: 1.0338 - val_loss: 0.7469\n",
      "Epoch 2/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.3488\n",
      "Epoch 3/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.3255\n",
      "Epoch 4/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3255\n",
      "Epoch 5/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3255\n",
      "Epoch 6/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3255\n",
      "Epoch 7/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3255\n",
      "Epoch 8/10\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 0.3232 - val_loss: 0.3255\n",
      "Epoch 9/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3255\n",
      "Epoch 10/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3255\n",
      "5.5 0.5 5.2717957 5.6144223\n",
      "Epoch 1/10\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 0.7026 - val_loss: 0.3143\n",
      "Epoch 2/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2305 - val_loss: 0.1880\n",
      "Epoch 3/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1840 - val_loss: 0.1840\n",
      "Epoch 4/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1833 - val_loss: 0.1839\n",
      "Epoch 5/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1833 - val_loss: 0.1840\n",
      "Epoch 6/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1833 - val_loss: 0.1839\n",
      "Epoch 7/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1833 - val_loss: 0.1839\n",
      "Epoch 8/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1833 - val_loss: 0.1839\n",
      "Epoch 9/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1833 - val_loss: 0.1840\n",
      "Epoch 10/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1833 - val_loss: 0.1839\n",
      "5.5 1 0.99551654 5.5238\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4191 - val_loss: 0.2587\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1893 - val_loss: 0.1645\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1649 - val_loss: 0.1642\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1648 - val_loss: 0.1642\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1648 - val_loss: 0.1642\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1648 - val_loss: 0.1642\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1648 - val_loss: 0.1642\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1648 - val_loss: 0.1642\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1648 - val_loss: 0.1642\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1648 - val_loss: 0.1642\n",
      "5.5 1.5 1.4947346 5.5102158\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.3403 - val_loss: 0.2207\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1709 - val_loss: 0.1577\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1576\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1576\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1576\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1577\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1577\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1577\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1588 - val_loss: 0.1576\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1577\n",
      "5.5 2 1.9725134 5.5057354\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 0.4282 - val_loss: 0.3024\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1989 - val_loss: 0.1543\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1538 - val_loss: 0.1539\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.1538\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.1538\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.1540\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.1538\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.1540\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.1539\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.1539\n",
      "5.5 2.5 2.4942348 5.5027924\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 1s 2ms/step - loss: 0.3928 - val_loss: 0.2402\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1671 - val_loss: 0.1491\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1490\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1500 - val_loss: 0.1490\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1490\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1500 - val_loss: 0.1491\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1500 - val_loss: 0.1491\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1491\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1490\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1491\n",
      "5.5 3 2.9856548 5.5165706\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.4532 - val_loss: 0.2735\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2621 - val_loss: 0.2473\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2171 - val_loss: 0.1763\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1560 - val_loss: 0.1485\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.1480\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1475 - val_loss: 0.1480\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1475 - val_loss: 0.1480\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1475 - val_loss: 0.1480\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1475 - val_loss: 0.1480\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1475 - val_loss: 0.1480\n",
      "5.5 3.5 3.470554 5.5278215\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 0.5763 - val_loss: 0.2736\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2201 - val_loss: 0.2006\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1636\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 0.1449\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1438 - val_loss: 0.1432\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 0.1431\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 0.1431\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 0.1431\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 0.1431\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 0.1432\n",
      "5.5 4 3.949429 5.5261436\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 2ms/step - loss: 0.7132 - val_loss: 0.2699\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.2050 - val_loss: 0.1582\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1483 - val_loss: 0.1409\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.1367\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.1360\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.1359\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.1359\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.1359\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.1360\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.1359\n",
      "5.5 4.5 4.465669 5.542932\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.8751 - val_loss: 0.2942\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1995 - val_loss: 0.1595\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.1286\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1256\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1256\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1256\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1256\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1256\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1256\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1256\n",
      "5.5 5 4.9533644 5.524559\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 1.0163 - val_loss: 0.4626\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.2364 - val_loss: 0.1561\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1435 - val_loss: 0.1307\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1247 - val_loss: 0.1178\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.1159\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.1157\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.1157\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.1157\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.1157\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.1157\n",
      "5.5 5.5 5.39205 5.6040053\n",
      "Epoch 1/10\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 1.0771 - val_loss: 0.5490\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.2849 - val_loss: 0.1674\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1466 - val_loss: 0.1307\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1245 - val_loss: 0.1199\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1188\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 0.1187\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1187\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1187\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1187\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1187\n",
      "5.5 6 5.450101 6.0167365\n",
      "Epoch 1/10\n",
      "141/141 [==============================] - 1s 3ms/step - loss: 0.9595 - val_loss: 0.7419\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.5103 - val_loss: 0.3274\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.3034 - val_loss: 0.2868\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.2870 - val_loss: 0.2848\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.2848\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.2848\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.2848\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.2866 - val_loss: 0.2848\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.2866 - val_loss: 0.2847\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.2865 - val_loss: 0.2847\n",
      "6 0.5 5.778035 5.9819303\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 0.7329 - val_loss: 0.3531\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.2743 - val_loss: 0.2019\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1872 - val_loss: 0.1829\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1826 - val_loss: 0.1826\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1826 - val_loss: 0.1826\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1826 - val_loss: 0.1826\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1826 - val_loss: 0.1826\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1826 - val_loss: 0.1826\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1826 - val_loss: 0.1826\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1826 - val_loss: 0.1826\n",
      "6 1 0.98468804 6.0345325\n",
      "Epoch 1/10\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4576 - val_loss: 0.3023\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.2235 - val_loss: 0.1701\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1690 - val_loss: 0.1658\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.1658\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.1658\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.1658\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.1658\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.1658\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.1658\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.1658\n",
      "6 1.5 1.4838715 6.021467\n",
      "Epoch 1/10\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.3824 - val_loss: 0.2754\n",
      "Epoch 2/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.2008 - val_loss: 0.1623\n",
      "Epoch 3/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1614 - val_loss: 0.1605\n",
      "Epoch 4/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.1605\n",
      "Epoch 5/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.1604\n",
      "Epoch 6/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.1604\n",
      "Epoch 7/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.1605\n",
      "Epoch 8/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.1608\n",
      "Epoch 9/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.1605\n",
      "Epoch 10/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.1606\n",
      "6 2 2.0125995 6.0099087\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4787 - val_loss: 0.3814\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2633 - val_loss: 0.1698\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1585 - val_loss: 0.1560\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1559\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1560\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1559\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1560\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1559\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1559\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1560\n",
      "6 2.5 2.4875653 6.018594\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4278 - val_loss: 0.2998\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2025 - val_loss: 0.1532\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1528 - val_loss: 0.1521\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1527 - val_loss: 0.1520\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1527 - val_loss: 0.1521\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1527 - val_loss: 0.1521\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1527 - val_loss: 0.1521\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1527 - val_loss: 0.1520\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1527 - val_loss: 0.1520\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1527 - val_loss: 0.1521\n",
      "6 3 2.9762397 6.022503\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4824 - val_loss: 0.3025\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2963 - val_loss: 0.2874\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2687 - val_loss: 0.2393\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1999 - val_loss: 0.1669\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.1527\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1506 - val_loss: 0.1521\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.1521\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1521\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1521\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1521\n",
      "6 3.5 3.4694653 6.0297165\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6125 - val_loss: 0.3085\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2520 - val_loss: 0.2344\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2254 - val_loss: 0.2108\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1910 - val_loss: 0.1678\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1554 - val_loss: 0.1475\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1469 - val_loss: 0.1453\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.1451\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.1451\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.1451\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.1451\n",
      "6 4 3.9716141 6.037391\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.7587 - val_loss: 0.3116\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.1933\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1824 - val_loss: 0.1731\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1601 - val_loss: 0.1496\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1441 - val_loss: 0.1417\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1405 - val_loss: 0.1409\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1402 - val_loss: 0.1409\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1402 - val_loss: 0.1409\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1402 - val_loss: 0.1409\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1402 - val_loss: 0.1409\n",
      "6 4.5 4.474477 6.0429435\n",
      "Epoch 1/10\n",
      "176/176 [==============================] - 1s 2ms/step - loss: 0.9376 - val_loss: 0.3517\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2387 - val_loss: 0.1820\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1423\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1382 - val_loss: 0.1357\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.1336\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1332\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1328 - val_loss: 0.1331\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1328 - val_loss: 0.1331\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1328 - val_loss: 0.1331\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1328 - val_loss: 0.1331\n",
      "6 5 4.9382863 6.0316014\n",
      "Epoch 1/10\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 1.0841 - val_loss: 0.5602\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.2908 - val_loss: 0.1700\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 0.1325\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1255 - val_loss: 0.1204\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1200 - val_loss: 0.1191\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1190\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1190\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1190\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1190\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1190\n",
      "6 5.5 5.4356236 6.037902\n",
      "Epoch 1/10\n",
      "170/170 [==============================] - 1s 3ms/step - loss: 1.1622 - val_loss: 0.6424\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.1857\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.1309\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1171\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.1117\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.1110\n",
      "Epoch 7/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1110\n",
      "Epoch 8/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.1109\n",
      "Epoch 9/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.1109\n",
      "Epoch 10/10\n",
      "170/170 [==============================] - 0s 3ms/step - loss: 0.1107 - val_loss: 0.1109\n",
      "6 6 5.879463 6.125778\n"
     ]
    }
   ],
   "source": [
    "xx = []\n",
    "mm = []\n",
    "for m1 in mass_range[1:]:\n",
    "        for m2 in mass_range[1:]:\n",
    "\n",
    "            #freeze layers\n",
    "            for l in model_all.layers:\n",
    "                l.trainable=False\n",
    "\n",
    "            #create simple models\n",
    "            model3 = createSimpleModel(2.)\n",
    "            model32 = createSimpleModel(3.)\n",
    "\n",
    "            #combine everything\n",
    "            inputs = tf.keras.Input(shape=(4,))\n",
    "            inputs2 = tf.keras.layers.concatenate([inputs,model3(tf.ones_like(inputs)[:,0]),model32(tf.ones_like(inputs)[:,0])])\n",
    "            hidden_layer_1 = model_all(inputs2)\n",
    "            model_all2 = Model(inputs = inputs, outputs = hidden_layer_1)\n",
    "            model_all2.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01))\n",
    "\n",
    "            x_vals_ = np.concatenate([x[0,0],x[m1,m2]])\n",
    "            y_vals_ = np.concatenate([np.ones(len(x[0,0])),np.zeros(len(x[m1,m2]))])\n",
    "            X_train_, X_val_, Y_train_, Y_val_ = train_test_split(x_vals_, y_vals_, test_size=0.5)\n",
    "            myhistory_hack_ = model_all2.fit(x_vals_[:,0:4], y_vals_, epochs=10,validation_data=(X_val_[:,0:4], Y_val_),batch_size=1024)\n",
    "            print(m1,m2,np.array(model_all2.trainable_weights).flatten()[0],np.array(model_all2.trainable_weights).flatten()[1])\n",
    "            xx += [[np.array(model_all2.trainable_weights).flatten()[0],np.array(model_all2.trainable_weights).flatten()[1]]]\n",
    "            mm += [[m1,m2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43403e1a-5362-4f51-bafb-6c950afa689a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5] [0.49042767 9.830067  ]\n",
      "[0.5 1. ] [0.88938004 9.238634  ]\n",
      "[0.5 1.5] [1.4304806 9.517697 ]\n",
      "[0.5 2. ] [1.9689283 9.606061 ]\n",
      "[0.5 2.5] [2.4731803 2.60734  ]\n",
      "[0.5 3. ] [2.9433212 3.1263187]\n",
      "[0.5 3.5] [3.4188526 3.6357832]\n",
      "[0.5 4. ] [3.8713343 4.1940656]\n",
      "[0.5 4.5] [4.3091354 4.700434 ]\n",
      "[0.5 5. ] [4.765122  5.1791496]\n",
      "[0.5 5.5] [5.222106  5.6245484]\n",
      "[0.5 6. ] [5.6688843 6.0374393]\n",
      "[1.  0.5] [0.87079334 9.246256  ]\n",
      "[1. 1.] [0.9875063 9.034551 ]\n",
      "[1.  1.5] [ 1.0557623 10.506565 ]\n",
      "[1. 2.] [1.9337032 9.006684 ]\n",
      "[1.  2.5] [2.4186785 2.554087 ]\n",
      "[1.5 0.5] [1.4414834 9.489062 ]\n",
      "[1.5 1. ] [ 1.0541543 10.506485 ]\n",
      "[2.  0.5] [1.9817356 9.547328 ]\n",
      "[2. 1.] [1.9218352 8.973688 ]\n",
      "[2.5 0.5] [2.4618433 2.6016176]\n",
      "[2.5 1. ] [2.4148767 2.5469017]\n",
      "[3.  0.5] [2.9418948 3.1273167]\n",
      "[3.5 0.5] [3.4066985 3.632552 ]\n",
      "[4.  0.5] [3.8819275 4.1506495]\n",
      "[4.5 0.5] [4.355761  4.6727653]\n",
      "[5.  0.5] [4.789882  5.1517525]\n",
      "[5.5 0.5] [5.2717957 5.6144223]\n",
      "[6.  0.5] [5.778035  5.9819303]\n",
      "found both: 0.7916666666666666\n",
      "found one: 0.20833333333333334\n",
      "found none: 0.0\n"
     ]
    }
   ],
   "source": [
    "xx = np.array(xx)\n",
    "mm = np.array(mm)\n",
    "\n",
    "found_both = 0.\n",
    "found_one = 0.\n",
    "found_none = 0.\n",
    "for i in range(len(mm)):\n",
    "    diff1 = abs(mm[i][0]-xx[i][0])\n",
    "    diff2 = abs(mm[i][1]-xx[i][0])\n",
    "    diff3 = abs(mm[i][0]-xx[i][1])\n",
    "    diff4 = abs(mm[i][1]-xx[i][1])\n",
    "    diffs = [diff1,diff2,diff3,diff4]\n",
    "    if (diff1 < 0.2 and diff4 < 0.2) or (diff2 < 0.2 and diff3 < 0.2):\n",
    "        #print(mm[i],xx[i])\n",
    "        found_both+=1\n",
    "    elif (min(diffs) < 0.2):\n",
    "        print(mm[i],xx[i])\n",
    "        found_one+=1\n",
    "        pass\n",
    "    else:\n",
    "        print(mm[i],xx[i])\n",
    "        found_none+=1\n",
    "        pass\n",
    "print(\"found both:\",found_both/(found_both+found_one+found_none))\n",
    "print(\"found one:\",found_one/(found_both+found_one+found_none))\n",
    "print(\"found none:\",found_none/(found_both+found_one+found_none))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "c698dae5-6e4d-4adc-9ebc-86ae14aba853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    epsilon = tf.constant(0.00001)\n",
    "    \n",
    "    nudged_pred = y_pred + epsilon\n",
    "    loss = tf.multiply(y_true, tf.math.log(nudged_pred)) - tf.multiply((1-y_true),tf.math.log(1-nudged_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b7d1c-a711-457d-9308-5af9de6c3d21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 7ms/step - loss: 1.8907 - val_loss: 1.8720\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.8766 - val_loss: 1.8582\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.8625 - val_loss: 1.8441\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.8484 - val_loss: 1.8303\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.8344 - val_loss: 1.8166\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 1.8205 - val_loss: 1.8026\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.8063 - val_loss: 1.7883\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.7921 - val_loss: 1.7736\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.7774 - val_loss: 1.7584\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.7622 - val_loss: 1.7430\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.7467 - val_loss: 1.7270\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.7309 - val_loss: 1.7105\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.7143 - val_loss: 1.6931\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.6968 - val_loss: 1.6751\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.6785 - val_loss: 1.6558\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.6588 - val_loss: 1.6355\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.6376 - val_loss: 1.6141\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.6157 - val_loss: 1.5924\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.5936 - val_loss: 1.5702\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.5707 - val_loss: 1.5474\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.5475 - val_loss: 1.5242\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.5244 - val_loss: 1.5013\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.5016 - val_loss: 1.4788\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.4796 - val_loss: 1.4571\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.4588 - val_loss: 1.4370\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.4394 - val_loss: 1.4176\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.4208 - val_loss: 1.3993\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.4028 - val_loss: 1.3803\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.3840 - val_loss: 1.3603\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.3643 - val_loss: 1.3395\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.3451 - val_loss: 1.3215\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.3280 - val_loss: 1.3051\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.3124 - val_loss: 1.2898\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2981 - val_loss: 1.2764\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2857 - val_loss: 1.2650\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2755 - val_loss: 1.2560\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2673 - val_loss: 1.2484\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2604 - val_loss: 1.2422\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2548 - val_loss: 1.2375\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2503 - val_loss: 1.2338\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2469 - val_loss: 1.2308\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2441 - val_loss: 1.2287\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2420 - val_loss: 1.2272\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.2403 - val_loss: 1.2258\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 1.2389 - val_loss: 1.2249\n",
      "Epoch 46/100\n",
      " 1/34 [..............................] - ETA: 0s - loss: 1.2509"
     ]
    }
   ],
   "source": [
    "sig_list = []\n",
    "weight_list1 = []\n",
    "weight_list2 = []\n",
    "weight_list3 = []\n",
    "\n",
    "epsilon = tf.constant(1e-6)\n",
    "#sigfrac = 0.1\n",
    "print(sigfrac)\n",
    "#sigfrac = 0.05\n",
    "# if (sigfrac > 0.5):\n",
    "#     continue\n",
    "\n",
    "for l in model_all.layers:\n",
    "    l.trainable=False\n",
    "\n",
    "model3 = createSimpleModel(2)\n",
    "model32 = createSimpleModel(3)\n",
    "\n",
    "inputs_hold3 = tf.keras.Input(shape=(1,))\n",
    "simple_model3 = tf.exp(Dense(1,use_bias = False,activation='linear',kernel_initializer=tf.keras.initializers.Constant(-1))(inputs_hold3))\n",
    "model33 = Model(inputs = inputs_hold3, outputs = simple_model3)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(4,))\n",
    "inputs2 = tf.keras.layers.concatenate([inputs,model3(tf.ones_like(inputs)[:,0]),model32(tf.ones_like(inputs)[:,0])])\n",
    "hidden_layer_1 = model_all(inputs2)\n",
    "LLR = (hidden_layer_1)/ (1.- hidden_layer_1 + epsilon)\n",
    "\n",
    "#LLR_xs = 1.+sigfrac*LLR\n",
    "#mu = model33(tf.ones_like(inputs)[:,0])\n",
    "\n",
    "mu = 0.1\n",
    "LLR_xs = 1. + mu*LLR - mu\n",
    "ws = (LLR_xs)/ (1.+ LLR_xs)\n",
    "model_all2 = Model(inputs = inputs, outputs = ws)\n",
    "model_all2.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001))\n",
    "\n",
    "#create ws data set\n",
    "m1 = 2\n",
    "m2 = 3\n",
    "\n",
    "#background\n",
    "test_background = int(1/2 *len(x[0,0]))\n",
    "train_background = int(1/4 * len(x[0,0]))\n",
    "train_reference = int(1/4 * len(x[0,0]))\n",
    "#signal\n",
    "test_signal_length = int(1/2*len(x[m1,m2]))\n",
    "N = int(1/4 * (len(x[0,0])))\n",
    "signal = x[m1, m2][test_signal_length:test_signal_length + int(.1*len(x[m1, m2]))]\n",
    "\n",
    "#had to switch labels\n",
    "#[reference (1), data_background (0), signal(0)]\n",
    "x_vals_ = np.concatenate([x[0,0][test_background:], signal])\n",
    "y_vals_ = np.concatenate([np.ones(train_reference), np.zeros(train_background + 1), np.zeros(len(signal))])\n",
    "\n",
    "X_train_, X_val_, Y_train_, Y_val_ = train_test_split(x_vals_, y_vals_, test_size=0.5)\n",
    "myhistory_hack_ = model_all2.fit(X_train_[:,0:4], Y_train_, epochs=100,validation_data=(X_val_[:,0:4], Y_val_),batch_size=1024)\n",
    "\n",
    "trainble_weight1 = model_all2.trainable_weights[0].numpy()[0][0]\n",
    "trainble_weight2 = model_all2.trainable_weights[1].numpy()[0][0]\n",
    "#trainble_weight3 = model_all2.trainable_weights[2].numpy()[0][0]\n",
    "\n",
    "print(m1,m2,trainble_weight1,trainble_weight2)\n",
    "\n",
    "sig_list+=[sigfrac]\n",
    "weight_list1+=[trainble_weight1]\n",
    "weight_list2+=[trainble_weight2]\n",
    "#weight_list3+=[trainble_weight3]\n",
    "scores = model_all2.predict(np.concatenate([x[0,0][:test_background],x[m1,m2][:test_signal_length]]), batch_size=1024)\n",
    "y = np.concatenate([np.zeros(test_background),np.ones(test_signal_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "ce1c2c88-da24-4d97-a454-8939ab3da1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x_vals_).any(), np.isnan(y_vals_).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "e5bf4865-a01a-477f-bdca-a2a795509492",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.72158126 -0.28277024  0.5733606   0.26217565]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in x_vals_:\n",
    "    if count == 1:\n",
    "        break\n",
    "    print(i)\n",
    "    for j in i:\n",
    "        if np.round(j,1) == 0:\n",
    "            print(\"found 0\")\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "bb6ef2fc-9135-4f83-9050-fe516418aa99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12069927, -1.28673229,  1.98006976,  1.40189193]])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals_[410:411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "99ae2314-31dd-494f-92be-71f6b6d940ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: -0.6466\n"
     ]
    }
   ],
   "source": [
    "model_all2.evaluate(x_vals_[906:907], y_vals_[906:907])\n",
    "trainble_weight1 = model_all2.trainable_weights[0].numpy()[0][0]\n",
    "trainble_weight2 = model_all2.trainable_weights[1].numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "a6463a2e-aa37-46f4-a730-4ede191dc179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.72158126, -0.28277024,  0.5733606 ,  0.26217565],\n",
       "       [-0.92658964, -0.00396325,  0.71195008, -0.42272083],\n",
       "       [-0.3137427 , -0.42851287,  0.78051413,  1.54771669],\n",
       "       ...,\n",
       "       [ 0.84752121, -0.92088776,  0.31389488, -2.50860844],\n",
       "       [ 0.90978493, -1.07758066, -0.51314168, -2.01723036],\n",
       "       [ 0.4949179 , -0.57406076, -1.61046056, -1.09104063]])"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals_del = x_vals_\n",
    "np.delete(x_vals_del, 411)\n",
    "x_vals_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "62e6247c-ac25-40fa-8008-39fdc33b003a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12069927, -1.28673229,  1.98006976,  1.40189193]])"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals_[410:411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "ed94be34-2ebe-40b4-ba66-4cb5c20ac178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all2.evaluate(x_vals_[409:410], y_vals_[409:410])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "cb0a5337-69c0-4664-bb1e-5e1988a2441c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.12944229,  0.54687401,  1.72460089, -0.0766593 ],\n",
       "        [-1.12069927, -1.28673229,  1.98006976,  1.40189193]]),\n",
       " array([1., 1.]))"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals_[409:411], y_vals_[409:411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "2737e7df-a4c9-480c-9ab4-d78ac7d6bed8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9998394],\n",
       "       [      nan]], dtype=float32)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all2.predict(x_vals_[409:411])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "861e9440-ea1a-496e-9705-1daaac221d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_background +1 - (len(x[0,0]) - int(1/2*len(x[0,0])) - int(1/4*len(x[0,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "fde779fc-0ca3-4103-9f69-53fabd6d914e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.96784543, -0.57360299,  2.25100986,  0.46229079]]), array([1.]))"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals_[906:907], y_vals_[906:907]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "93b36231-4ba7-4115-848b-e8cd518f828b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67818, 4)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_vals_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "14f6c400-696e-4b42-b836-bb4288ec2c53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49877053],\n",
       "       [0.5219461 ],\n",
       "       [0.5015893 ],\n",
       "       ...,\n",
       "       [0.48307368],\n",
       "       [0.49922457],\n",
       "       [0.48880598]], dtype=float32)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "1ab63f8c-461d-4e69-939b-331330be3165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_475/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.7941915]], dtype=float32)>,\n",
       " <tf.Variable 'dense_476/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[3.1973953]], dtype=float32)>,\n",
       " <tf.Variable 'dense_477/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[-1.1996981]], dtype=float32)>]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all2.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e5902e59-cf4f-4604-a813-149bccef5f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(y, scores)\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve Semi Weakly')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "654485f4-6175-45d4-9994-5619690dc3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 600.0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sig_list,np.array(weight_list1)*100)\n",
    "plt.plot(sig_list,np.array(weight_list2)*100)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"S/B\")\n",
    "plt.ylabel(\"Fitted masses [GeV]\")\n",
    "plt.axhline(450,ls=\":\",color='orange')\n",
    "plt.axhline(200,ls=\":\",color='blue')\n",
    "plt.title(\"Trainable Weights\")\n",
    "plt.ylim([0,600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c16e01cb-4044-4546-9733-f1c5e771898b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.1915026]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ceeae064-5f7f-4c1f-a131-7e1ec34d344f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Fitted S/B')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sig_list,np.array(weight_list3))\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(sig_list,sig_list,ls=\":\",color=\"black\")\n",
    "plt.xlabel(\"S/B\")\n",
    "plt.ylabel(\"Fitted S/B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5398d19-71e3-471b-ab94-aea9d46ed5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
