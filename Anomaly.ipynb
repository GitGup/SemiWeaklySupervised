{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a51ad95-8898-4ff8-b34c-32b10200f15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa34132-ce9d-4c73-b9b8-9c0eb9d473e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# Check if tensorflow is using GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1639fc-28b1-4530-ab19-4114c2f0db3c",
   "metadata": {},
   "source": [
    "Referencing: https://arxiv.org/pdf/2212.11285.pdf\n",
    "\n",
    "We start off by loading in 1,000,000 background dijet events and 100,000 signal dijet events. The signal comes from the process Z$\\rightarrow$ X($\\rightarrow$ $q\\bar{q}$) Y$\\rightarrow$($q\\bar{q}$) where Z is 3.5 TeV. X is 500 GeV and Y is 100 GeV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf36cb3-02cc-487b-85a7-4fbf5ee16d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_QCD = pd.read_hdf(\"/global/cfs/projectdirs/m3246/AnomalyDetection/LHCO/events_anomalydetection_DelphesPythia8_v2_qcd_features.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9cf47ae-311d-4c6e-b8c8-7208364ed33d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pxj1</th>\n",
       "      <th>pyj1</th>\n",
       "      <th>pzj1</th>\n",
       "      <th>mj1</th>\n",
       "      <th>tau1j1</th>\n",
       "      <th>tau2j1</th>\n",
       "      <th>tau3j1</th>\n",
       "      <th>pxj2</th>\n",
       "      <th>pyj2</th>\n",
       "      <th>pzj2</th>\n",
       "      <th>mj2</th>\n",
       "      <th>tau1j2</th>\n",
       "      <th>tau2j2</th>\n",
       "      <th>tau3j2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1467.239990</td>\n",
       "      <td>611.502014</td>\n",
       "      <td>511.101990</td>\n",
       "      <td>38.896000</td>\n",
       "      <td>8.290650</td>\n",
       "      <td>4.836080</td>\n",
       "      <td>4.260190</td>\n",
       "      <td>1403.579956</td>\n",
       "      <td>-674.551025</td>\n",
       "      <td>-451.670990</td>\n",
       "      <td>237.893997</td>\n",
       "      <td>79.815102</td>\n",
       "      <td>21.010300</td>\n",
       "      <td>16.757601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1211.239990</td>\n",
       "      <td>347.315002</td>\n",
       "      <td>547.963013</td>\n",
       "      <td>389.532013</td>\n",
       "      <td>191.804001</td>\n",
       "      <td>99.562798</td>\n",
       "      <td>70.872200</td>\n",
       "      <td>619.341003</td>\n",
       "      <td>-62.177299</td>\n",
       "      <td>-1944.040039</td>\n",
       "      <td>22.999201</td>\n",
       "      <td>8.042180</td>\n",
       "      <td>6.335090</td>\n",
       "      <td>5.525370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1229.619995</td>\n",
       "      <td>649.857971</td>\n",
       "      <td>8.089170</td>\n",
       "      <td>72.155502</td>\n",
       "      <td>47.168098</td>\n",
       "      <td>37.243198</td>\n",
       "      <td>33.658199</td>\n",
       "      <td>1196.250000</td>\n",
       "      <td>-647.896973</td>\n",
       "      <td>-1283.109985</td>\n",
       "      <td>78.230698</td>\n",
       "      <td>15.292900</td>\n",
       "      <td>13.944200</td>\n",
       "      <td>10.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-693.304016</td>\n",
       "      <td>-1046.729980</td>\n",
       "      <td>1716.910034</td>\n",
       "      <td>55.797798</td>\n",
       "      <td>24.788500</td>\n",
       "      <td>6.890140</td>\n",
       "      <td>5.813400</td>\n",
       "      <td>747.961975</td>\n",
       "      <td>994.250000</td>\n",
       "      <td>-412.966003</td>\n",
       "      <td>359.113007</td>\n",
       "      <td>175.209000</td>\n",
       "      <td>103.500999</td>\n",
       "      <td>84.447098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1488.199951</td>\n",
       "      <td>-25.370100</td>\n",
       "      <td>-30.989700</td>\n",
       "      <td>84.891502</td>\n",
       "      <td>26.878799</td>\n",
       "      <td>15.517200</td>\n",
       "      <td>13.260400</td>\n",
       "      <td>1415.640015</td>\n",
       "      <td>20.905100</td>\n",
       "      <td>223.630997</td>\n",
       "      <td>77.506500</td>\n",
       "      <td>57.986000</td>\n",
       "      <td>34.147400</td>\n",
       "      <td>26.660601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999994</th>\n",
       "      <td>-646.442017</td>\n",
       "      <td>-1295.150024</td>\n",
       "      <td>1331.800049</td>\n",
       "      <td>37.011299</td>\n",
       "      <td>21.006800</td>\n",
       "      <td>12.873700</td>\n",
       "      <td>8.898860</td>\n",
       "      <td>274.566986</td>\n",
       "      <td>1019.390015</td>\n",
       "      <td>-504.290985</td>\n",
       "      <td>90.375000</td>\n",
       "      <td>61.218800</td>\n",
       "      <td>20.514500</td>\n",
       "      <td>15.854600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>-286.550995</td>\n",
       "      <td>-1310.829956</td>\n",
       "      <td>-1510.910034</td>\n",
       "      <td>147.516998</td>\n",
       "      <td>60.997799</td>\n",
       "      <td>41.356201</td>\n",
       "      <td>28.225700</td>\n",
       "      <td>252.884995</td>\n",
       "      <td>1085.420044</td>\n",
       "      <td>759.314026</td>\n",
       "      <td>58.769901</td>\n",
       "      <td>42.276402</td>\n",
       "      <td>8.637120</td>\n",
       "      <td>7.852020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>918.562988</td>\n",
       "      <td>951.195984</td>\n",
       "      <td>-1622.569946</td>\n",
       "      <td>32.242199</td>\n",
       "      <td>5.894110</td>\n",
       "      <td>5.004100</td>\n",
       "      <td>3.992740</td>\n",
       "      <td>-266.285004</td>\n",
       "      <td>-1284.189941</td>\n",
       "      <td>185.007996</td>\n",
       "      <td>136.389008</td>\n",
       "      <td>70.623901</td>\n",
       "      <td>49.508499</td>\n",
       "      <td>40.708599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>1447.219971</td>\n",
       "      <td>-547.710999</td>\n",
       "      <td>827.945007</td>\n",
       "      <td>396.112000</td>\n",
       "      <td>181.406998</td>\n",
       "      <td>152.207993</td>\n",
       "      <td>86.676804</td>\n",
       "      <td>-932.369995</td>\n",
       "      <td>165.005005</td>\n",
       "      <td>-2806.959961</td>\n",
       "      <td>56.471600</td>\n",
       "      <td>14.446400</td>\n",
       "      <td>10.258900</td>\n",
       "      <td>8.874700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>200.035995</td>\n",
       "      <td>-1252.869995</td>\n",
       "      <td>27.924900</td>\n",
       "      <td>363.790985</td>\n",
       "      <td>139.281998</td>\n",
       "      <td>31.751499</td>\n",
       "      <td>22.884300</td>\n",
       "      <td>-583.494995</td>\n",
       "      <td>1096.890015</td>\n",
       "      <td>-1194.410034</td>\n",
       "      <td>105.186996</td>\n",
       "      <td>36.687000</td>\n",
       "      <td>23.652201</td>\n",
       "      <td>19.462601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999999 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pxj1         pyj1         pzj1         mj1      tau1j1  \\\n",
       "0      -1467.239990   611.502014   511.101990   38.896000    8.290650   \n",
       "1      -1211.239990   347.315002   547.963013  389.532013  191.804001   \n",
       "2      -1229.619995   649.857971     8.089170   72.155502   47.168098   \n",
       "3       -693.304016 -1046.729980  1716.910034   55.797798   24.788500   \n",
       "4      -1488.199951   -25.370100   -30.989700   84.891502   26.878799   \n",
       "...             ...          ...          ...         ...         ...   \n",
       "999994  -646.442017 -1295.150024  1331.800049   37.011299   21.006800   \n",
       "999995  -286.550995 -1310.829956 -1510.910034  147.516998   60.997799   \n",
       "999996   918.562988   951.195984 -1622.569946   32.242199    5.894110   \n",
       "999997  1447.219971  -547.710999   827.945007  396.112000  181.406998   \n",
       "999998   200.035995 -1252.869995    27.924900  363.790985  139.281998   \n",
       "\n",
       "            tau2j1     tau3j1         pxj2         pyj2         pzj2  \\\n",
       "0         4.836080   4.260190  1403.579956  -674.551025  -451.670990   \n",
       "1        99.562798  70.872200   619.341003   -62.177299 -1944.040039   \n",
       "2        37.243198  33.658199  1196.250000  -647.896973 -1283.109985   \n",
       "3         6.890140   5.813400   747.961975   994.250000  -412.966003   \n",
       "4        15.517200  13.260400  1415.640015    20.905100   223.630997   \n",
       "...            ...        ...          ...          ...          ...   \n",
       "999994   12.873700   8.898860   274.566986  1019.390015  -504.290985   \n",
       "999995   41.356201  28.225700   252.884995  1085.420044   759.314026   \n",
       "999996    5.004100   3.992740  -266.285004 -1284.189941   185.007996   \n",
       "999997  152.207993  86.676804  -932.369995   165.005005 -2806.959961   \n",
       "999998   31.751499  22.884300  -583.494995  1096.890015 -1194.410034   \n",
       "\n",
       "               mj2      tau1j2      tau2j2     tau3j2  \n",
       "0       237.893997   79.815102   21.010300  16.757601  \n",
       "1        22.999201    8.042180    6.335090   5.525370  \n",
       "2        78.230698   15.292900   13.944200  10.013500  \n",
       "3       359.113007  175.209000  103.500999  84.447098  \n",
       "4        77.506500   57.986000   34.147400  26.660601  \n",
       "...            ...         ...         ...        ...  \n",
       "999994   90.375000   61.218800   20.514500  15.854600  \n",
       "999995   58.769901   42.276402    8.637120   7.852020  \n",
       "999996  136.389008   70.623901   49.508499  40.708599  \n",
       "999997   56.471600   14.446400   10.258900   8.874700  \n",
       "999998  105.186996   36.687000   23.652201  19.462601  \n",
       "\n",
       "[999999 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_QCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c26fcc-24e2-401e-8f60-c71c168529d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"/global/cfs/projectdirs/m3246/AnomalyDetection/LHCO/events_anomalydetection_DelphesPythia8_v2_Wprime_features.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "874a6f00-dd55-49a1-a8b0-f80267d5ff3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pxj1</th>\n",
       "      <th>pyj1</th>\n",
       "      <th>pzj1</th>\n",
       "      <th>mj1</th>\n",
       "      <th>tau1j1</th>\n",
       "      <th>tau2j1</th>\n",
       "      <th>tau3j1</th>\n",
       "      <th>pxj2</th>\n",
       "      <th>pyj2</th>\n",
       "      <th>pzj2</th>\n",
       "      <th>mj2</th>\n",
       "      <th>tau1j2</th>\n",
       "      <th>tau2j2</th>\n",
       "      <th>tau3j2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1698.670044</td>\n",
       "      <td>-884.039978</td>\n",
       "      <td>723.843018</td>\n",
       "      <td>105.035004</td>\n",
       "      <td>83.721703</td>\n",
       "      <td>46.282101</td>\n",
       "      <td>13.635700</td>\n",
       "      <td>1539.439941</td>\n",
       "      <td>372.238007</td>\n",
       "      <td>-295.865997</td>\n",
       "      <td>461.574005</td>\n",
       "      <td>431.343994</td>\n",
       "      <td>52.344799</td>\n",
       "      <td>37.284901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1246.660034</td>\n",
       "      <td>-1133.010010</td>\n",
       "      <td>-921.987000</td>\n",
       "      <td>159.865997</td>\n",
       "      <td>133.781998</td>\n",
       "      <td>58.968601</td>\n",
       "      <td>30.377399</td>\n",
       "      <td>-1218.489990</td>\n",
       "      <td>1108.380005</td>\n",
       "      <td>182.147003</td>\n",
       "      <td>514.883972</td>\n",
       "      <td>462.654999</td>\n",
       "      <td>138.789001</td>\n",
       "      <td>67.805801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420.975006</td>\n",
       "      <td>-1739.790039</td>\n",
       "      <td>281.553986</td>\n",
       "      <td>93.665901</td>\n",
       "      <td>77.925797</td>\n",
       "      <td>10.605900</td>\n",
       "      <td>6.916520</td>\n",
       "      <td>-510.779999</td>\n",
       "      <td>1484.069946</td>\n",
       "      <td>227.175995</td>\n",
       "      <td>475.316986</td>\n",
       "      <td>217.113998</td>\n",
       "      <td>29.424000</td>\n",
       "      <td>21.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161.048996</td>\n",
       "      <td>-1664.859985</td>\n",
       "      <td>-2005.099976</td>\n",
       "      <td>116.327003</td>\n",
       "      <td>61.819698</td>\n",
       "      <td>38.143600</td>\n",
       "      <td>18.414400</td>\n",
       "      <td>-188.942993</td>\n",
       "      <td>1556.900024</td>\n",
       "      <td>-561.664001</td>\n",
       "      <td>561.236023</td>\n",
       "      <td>348.181000</td>\n",
       "      <td>102.625000</td>\n",
       "      <td>53.422699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-564.754028</td>\n",
       "      <td>-1315.599976</td>\n",
       "      <td>-1087.410034</td>\n",
       "      <td>513.015991</td>\n",
       "      <td>276.446991</td>\n",
       "      <td>50.629799</td>\n",
       "      <td>35.460999</td>\n",
       "      <td>326.164001</td>\n",
       "      <td>1050.239990</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>108.752998</td>\n",
       "      <td>89.666603</td>\n",
       "      <td>40.928699</td>\n",
       "      <td>17.055799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>-206.662003</td>\n",
       "      <td>-1729.280029</td>\n",
       "      <td>357.635010</td>\n",
       "      <td>96.165001</td>\n",
       "      <td>58.014500</td>\n",
       "      <td>11.731300</td>\n",
       "      <td>6.174070</td>\n",
       "      <td>218.800003</td>\n",
       "      <td>1714.890015</td>\n",
       "      <td>-210.578995</td>\n",
       "      <td>472.475006</td>\n",
       "      <td>259.884003</td>\n",
       "      <td>40.806999</td>\n",
       "      <td>31.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1069.660034</td>\n",
       "      <td>659.874023</td>\n",
       "      <td>218.751007</td>\n",
       "      <td>126.183998</td>\n",
       "      <td>122.486000</td>\n",
       "      <td>27.608700</td>\n",
       "      <td>17.924801</td>\n",
       "      <td>-956.169006</td>\n",
       "      <td>-297.311005</td>\n",
       "      <td>-2204.350098</td>\n",
       "      <td>108.890999</td>\n",
       "      <td>21.177200</td>\n",
       "      <td>10.582400</td>\n",
       "      <td>9.138590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>-1286.619995</td>\n",
       "      <td>-86.162598</td>\n",
       "      <td>-1366.270020</td>\n",
       "      <td>115.719002</td>\n",
       "      <td>109.853996</td>\n",
       "      <td>29.830200</td>\n",
       "      <td>22.489201</td>\n",
       "      <td>1145.729980</td>\n",
       "      <td>136.792007</td>\n",
       "      <td>1216.780029</td>\n",
       "      <td>489.053009</td>\n",
       "      <td>416.747009</td>\n",
       "      <td>84.599998</td>\n",
       "      <td>66.767502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>-149.330002</td>\n",
       "      <td>1781.459961</td>\n",
       "      <td>-58.690899</td>\n",
       "      <td>508.045013</td>\n",
       "      <td>495.290985</td>\n",
       "      <td>82.283600</td>\n",
       "      <td>43.567902</td>\n",
       "      <td>84.726601</td>\n",
       "      <td>-1378.569946</td>\n",
       "      <td>-1485.469971</td>\n",
       "      <td>91.104897</td>\n",
       "      <td>79.120102</td>\n",
       "      <td>46.537300</td>\n",
       "      <td>23.227301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1584.699951</td>\n",
       "      <td>-731.156982</td>\n",
       "      <td>-196.348007</td>\n",
       "      <td>114.938004</td>\n",
       "      <td>83.769897</td>\n",
       "      <td>12.898200</td>\n",
       "      <td>9.031230</td>\n",
       "      <td>-1515.079956</td>\n",
       "      <td>783.245972</td>\n",
       "      <td>498.704010</td>\n",
       "      <td>553.737000</td>\n",
       "      <td>366.188995</td>\n",
       "      <td>192.139008</td>\n",
       "      <td>81.398201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99999 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pxj1         pyj1         pzj1         mj1      tau1j1  \\\n",
       "0     -1698.670044  -884.039978   723.843018  105.035004   83.721703   \n",
       "1      1246.660034 -1133.010010  -921.987000  159.865997  133.781998   \n",
       "2       420.975006 -1739.790039   281.553986   93.665901   77.925797   \n",
       "3       161.048996 -1664.859985 -2005.099976  116.327003   61.819698   \n",
       "4      -564.754028 -1315.599976 -1087.410034  513.015991  276.446991   \n",
       "...            ...          ...          ...         ...         ...   \n",
       "99994  -206.662003 -1729.280029   357.635010   96.165001   58.014500   \n",
       "99995  1069.660034   659.874023   218.751007  126.183998  122.486000   \n",
       "99996 -1286.619995   -86.162598 -1366.270020  115.719002  109.853996   \n",
       "99997  -149.330002  1781.459961   -58.690899  508.045013  495.290985   \n",
       "99998  1584.699951  -731.156982  -196.348007  114.938004   83.769897   \n",
       "\n",
       "          tau2j1     tau3j1         pxj2         pyj2         pzj2  \\\n",
       "0      46.282101  13.635700  1539.439941   372.238007  -295.865997   \n",
       "1      58.968601  30.377399 -1218.489990  1108.380005   182.147003   \n",
       "2      10.605900   6.916520  -510.779999  1484.069946   227.175995   \n",
       "3      38.143600  18.414400  -188.942993  1556.900024  -561.664001   \n",
       "4      50.629799  35.460999   326.164001  1050.239990  1201.000000   \n",
       "...          ...        ...          ...          ...          ...   \n",
       "99994  11.731300   6.174070   218.800003  1714.890015  -210.578995   \n",
       "99995  27.608700  17.924801  -956.169006  -297.311005 -2204.350098   \n",
       "99996  29.830200  22.489201  1145.729980   136.792007  1216.780029   \n",
       "99997  82.283600  43.567902    84.726601 -1378.569946 -1485.469971   \n",
       "99998  12.898200   9.031230 -1515.079956   783.245972   498.704010   \n",
       "\n",
       "              mj2      tau1j2      tau2j2     tau3j2  \n",
       "0      461.574005  431.343994   52.344799  37.284901  \n",
       "1      514.883972  462.654999  138.789001  67.805801  \n",
       "2      475.316986  217.113998   29.424000  21.020300  \n",
       "3      561.236023  348.181000  102.625000  53.422699  \n",
       "4      108.752998   89.666603   40.928699  17.055799  \n",
       "...           ...         ...         ...        ...  \n",
       "99994  472.475006  259.884003   40.806999  31.226000  \n",
       "99995  108.890999   21.177200   10.582400   9.138590  \n",
       "99996  489.053009  416.747009   84.599998  66.767502  \n",
       "99997   91.104897   79.120102   46.537300  23.227301  \n",
       "99998  553.737000  366.188995  192.139008  81.398201  \n",
       "\n",
       "[99999 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3adbce-25f0-4389-a115-e694802d94cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Jet Mass Distributions')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['mj1'],bins=np.linspace(0,600,20))\n",
    "plt.xlabel(\"Mass [GeV]\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Jet Mass Distributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "472adaa6-938f-4e12-ae2e-cdbe211d0815",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 J 1788.55 -0.300279 -2.51608 130.279 0 0.0289343 0.0153102 0.0126833 0.010346 0.00825964  P 4.64413 -0.377384 3.00207  P 2.47947 -0.425799 3.02334  P 2.68613 -0.39458 -2.608  P 5.84707 -0.404504 -2.54133  P 24.9416 -0.408844 -2.52053  P 6.58412 -0.387347 -2.54543  P 13.1517 -0.350432 -2.59254  P 13.7381 -0.300859 -2.52212  P 4.55674 -0.286343 -2.52545  P 517.142 -0.286492 -2.50205 \n",
      "\n",
      "0 1 J 1643.32 -0.173344 0.717105 95.8961 0 0.0424313 0.0221081 0.0140335 0.0108518 0.00877299  P 1.75001 -0.530883 0.585762  P 2.74298 -0.297844 0.694373  P 5.4756 -0.195946 0.630677  P 7.35714 -0.200437 0.647468  P 9.16487 -0.119969 0.704896  P 5.77878 -0.125155 0.709119  P 6.37682 -0.141306 0.773328  P 8.23397 -0.155549 0.732862  P 29.6409 -0.186092 0.763671  P 2.24246 -0.170876 0.729569  P 245.519 -0.180535 0.735561 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"/global/cfs/projectdirs/m3246/AnomalyDetection/ILC/Delphes-3.5.0/LHCO_RnD_qq/LHCO_RnD_qq.txt\")\n",
    "\n",
    "jets = []\n",
    "count = 0\n",
    "for line in file:\n",
    "    if count == 2:\n",
    "        break\n",
    "    print(line)\n",
    "    jets += [line.split(\"J\")[1].split(\"P\")[0].split()]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d84ddc16-9bdb-4964-882d-f8db41e4f5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1788.55',\n",
       "  '-0.300279',\n",
       "  '-2.51608',\n",
       "  '130.279',\n",
       "  '0',\n",
       "  '0.0289343',\n",
       "  '0.0153102',\n",
       "  '0.0126833',\n",
       "  '0.010346',\n",
       "  '0.00825964'],\n",
       " ['1643.32',\n",
       "  '-0.173344',\n",
       "  '0.717105',\n",
       "  '95.8961',\n",
       "  '0',\n",
       "  '0.0424313',\n",
       "  '0.0221081',\n",
       "  '0.0140335',\n",
       "  '0.0108518',\n",
       "  '0.00877299']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74e751ad-3731-4908-a40e-3d53afa0d19a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ljet = [jets[2*n] for n in range(int(len(jets)/2))]\n",
    "sjet = [jets[2*n+1] for n in range(int(len(jets)/2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec57e185-b108-4d49-8a6e-9d602a0b1a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1788.55',\n",
       "  '-0.300279',\n",
       "  '-2.51608',\n",
       "  '130.279',\n",
       "  '0',\n",
       "  '0.0289343',\n",
       "  '0.0153102',\n",
       "  '0.0126833',\n",
       "  '0.010346',\n",
       "  '0.00825964']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ljet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a256173c-6db9-488e-917a-f5e89ae59167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computemjj_pd(event):\n",
    "    px1 = event[[\"pxj1\"]].to_numpy()\n",
    "    py1 = event[[\"pyj1\"]].to_numpy()\n",
    "    pz1 = event[[\"pzj1\"]].to_numpy()\n",
    "    pE1 = np.sqrt(px1**2+py1**2+pz1**2+event[[\"mj1\"]].to_numpy()**2)\n",
    "    \n",
    "    px2 = event[[\"pxj2\"]].to_numpy()\n",
    "    py2 = event[[\"pyj2\"]].to_numpy()\n",
    "    pz2 = event[[\"pzj2\"]].to_numpy()\n",
    "    pE2 = np.sqrt(px1**2+py1**2+pz1**2+event[[\"mj2\"]].to_numpy()**2)\n",
    "    \n",
    "    m2 = (pE1+pE2)**2-(px1+px2)**2-(py1+py2)**2-(pz1+pz2)**2\n",
    "    return np.array(np.sqrt(m2)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd77cfaa-083f-472c-b291-3050fb718da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computemjj_txt(event):\n",
    "    pT1 = np.array([float(event[2*i][0]) for i in range(int(len(event)/2))])\n",
    "    eta1 = np.array([float(event[2*i][1]) for i in range(int(len(event)/2))])\n",
    "    phi1 = np.array([float(event[2*i][2]) for i in range(int(len(event)/2))])\n",
    "    m1 = np.array([float(event[2*i][3]) for i in range(int(len(event)/2))])\n",
    "    px1 = pT1*np.cos(phi1)\n",
    "    py1 = pT1*np.sin(phi1)\n",
    "    pz1 = pT1*np.sinh(eta1)\n",
    "    pE1 = np.sqrt(px1**2+py1**2+pz1**2+m1**2)\n",
    "    \n",
    "    pT2 = np.array([float(event[2*i+1][0]) for i in range(int(len(event)/2))])\n",
    "    eta2 = np.array([float(event[2*i+1][1]) for i in range(int(len(event)/2))])\n",
    "    phi2 = np.array([float(event[2*i+1][2]) for i in range(int(len(event)/2))])\n",
    "    m2 = np.array([float(event[2*i+1][3]) for i in range(int(len(event)/2))])\n",
    "    px2 = pT2*np.cos(phi2)\n",
    "    py2 = pT2*np.sin(phi2)\n",
    "    pz2 = pT2*np.sinh(eta2)\n",
    "    pE2 = np.sqrt(px2**2+py2**2+pz2**2+m2**2)\n",
    "    \n",
    "    m2 = (pE1+pE2)**2-(px1+px2)**2-(py1+py2)**2-(pz1+pz2)**2\n",
    "    return np.array(np.sqrt(m2)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6ae4f16-8096-43cf-8e19-9983f63bc64f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3674.182176987098"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 100\n",
    "file = open(\"/global/cfs/projectdirs/m3246/AnomalyDetection/ILC/Delphes-3.5.0/LHCO_RnD_qq/LHCO_RnD_qq_\"+str(m)+\"_\"+str(m)+\".txt\")\n",
    "jets_m_m = []\n",
    "for line in file:\n",
    "    jets_m_m+=[line.split(\"J\")[1].split(\"P\")[0].split()]\n",
    "    pass\n",
    "computemjj_txt(jets_m_m)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b973cdf7-fd7f-453a-a3e8-d5c93560f393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180286"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jets_m_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67c5dc45-f8c3-4ac7-afab-dfea17f527bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mass_range = [0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6]\n",
    "if (False):\n",
    "    lmass_vec = {}\n",
    "    x = {}\n",
    "    mjjs = {}\n",
    "\n",
    "    mu_m = 0.\n",
    "    mu_t = 0.\n",
    "    sd_m = 0.\n",
    "    sd_t = 0.\n",
    "\n",
    "    for m1 in mass_range:\n",
    "        for m2 in mass_range:\n",
    "\n",
    "            print(\"on ...\",m1,m2)\n",
    "\n",
    "            ltau1_m_m = []\n",
    "            ltau2_m_m = []\n",
    "            stau1_m_m = []\n",
    "            stau2_m_m = []\n",
    "            if (m1>0 and m2>0):\n",
    "                myfile = open(\"/global/cfs/projectdirs/m3246/AnomalyDetection/ILC/Delphes-3.5.0/LHCO_RnD_qq/LHCO_RnD_qq_\"+str(int(m1*100))+\"_\"+str(int(100*m2))+\".txt\")\n",
    "                jets_m_m = []\n",
    "                for line in myfile:\n",
    "                    jets_m_m+=[line.split(\"J\")[1].split(\"P\")[0].split()]\n",
    "                    pass\n",
    "                ljet_m_m = [jets_m_m[2*n] for n in range(int(len(jets_m_m)/2))]\n",
    "                sjet_m_m = [jets_m_m[2*n+1] for n in range(int(len(jets_m_m)/2))]\n",
    "\n",
    "                lmass_m_m = np.array([float(ljet_m_m[i][3]) for i in range(len(ljet_m_m))])/1000.\n",
    "                smass_m_m = np.array([float(sjet_m_m[i][3]) for i in range(len(sjet_m_m))])/1000.\n",
    "\n",
    "                ltau1_m_m = np.array([float(ljet_m_m[i][5]) for i in range(len(ljet_m_m))])\n",
    "                ltau2_m_m = np.array([float(ljet_m_m[i][6]) for i in range(len(ljet_m_m))])\n",
    "\n",
    "                stau1_m_m = np.array([float(sjet_m_m[i][5]) for i in range(len(ljet_m_m))])\n",
    "                stau2_m_m = np.array([float(sjet_m_m[i][6]) for i in range(len(ljet_m_m))])\n",
    "\n",
    "                mjj = computemjj_txt(jets_m_m)/1000.\n",
    "                mjjs[m1,m2] = mjj\n",
    "                passcut = (mjj > 3.3) * (mjj < 3.7)\n",
    "                lmass_m_m = lmass_m_m[passcut]\n",
    "                smass_m_m = smass_m_m[passcut]\n",
    "                ltau1_m_m = ltau1_m_m[passcut]\n",
    "                ltau2_m_m = ltau2_m_m[passcut]\n",
    "                stau1_m_m = stau1_m_m[passcut]\n",
    "                stau2_m_m = stau2_m_m[passcut]\n",
    "                pass\n",
    "            elif m1==0 and m2==0:\n",
    "                df_QCD = pd.read_hdf(\"/global/cfs/projectdirs/m3246/AnomalyDetection/LHCO/events_anomalydetection_DelphesPythia8_v2_qcd_features.h5\")\n",
    "                lmass_m_m = np.array(df_QCD[[\"mj1\"]]).flatten()/1000.\n",
    "                smass_m_m = np.array(df_QCD[[\"mj2\"]]).flatten()/1000.\n",
    "                ltau1_m_m = np.array(df_QCD[[\"tau1j1\"]]).flatten()\n",
    "                ltau2_m_m = np.array(df_QCD[[\"tau2j1\"]]).flatten()\n",
    "                stau1_m_m = np.array(df_QCD[[\"tau1j2\"]]).flatten()\n",
    "                stau2_m_m = np.array(df_QCD[[\"tau2j2\"]]).flatten()\n",
    "                mjj = computemjj_pd(df_QCD)/1000.\n",
    "                mjjs[m1,m2] = mjj\n",
    "                passcut = (mjj > 3.3) * (mjj < 3.7)\n",
    "                lmass_m_m = lmass_m_m[passcut]\n",
    "                smass_m_m = smass_m_m[passcut]\n",
    "                ltau1_m_m = ltau1_m_m[passcut]\n",
    "                ltau2_m_m = ltau2_m_m[passcut]\n",
    "                stau1_m_m = stau1_m_m[passcut]\n",
    "                stau2_m_m = stau2_m_m[passcut]\n",
    "\n",
    "                mu_m = np.mean(lmass_m_m)\n",
    "                mu_t = np.mean(ltau2_m_m/(ltau1_m_m+0.0001))\n",
    "                sd_m = np.std(lmass_m_m)\n",
    "                sd_t = np.std(ltau2_m_m/(ltau1_m_m+0.0001))\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            ms = np.stack([lmass_m_m,smass_m_m],axis=1)\n",
    "            ts = np.stack([ltau2_m_m/(ltau1_m_m+0.0001),stau2_m_m/(stau1_m_m+0.001)],axis=1)\n",
    "            order1 = [np.argmax(ms[i]) for i in range(len(ms))]\n",
    "            order2 = [np.argmin(ms[i]) for i in range(len(ms))]\n",
    "            mJ1 = np.array([ms[i][order1[i]] for i in range(len(ms))])\n",
    "            mJ2 = np.array([ms[i][order2[i]] for i in range(len(ms))])\n",
    "            x[m1,m2] = np.stack([(mJ2 - mu_m)/sd_m,\n",
    "                                    ((mJ1 - mJ2) - mu_m)/sd_m,\n",
    "                                    ([ts[i][order2[i]] for i in range(len(ts))] - mu_t)/sd_t,\n",
    "                                    ([ts[i][order1[i]] for i in range(len(ts))] - mu_t)/sd_t],axis=1)\n",
    "            lmass_vec[m1,m2]=lmass_m_m\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "    x_array = []\n",
    "    for m1 in mass_range:\n",
    "        for m2 in mass_range:\n",
    "            if (m1==0 and m2>0 or m2==0 and m1>0):\n",
    "                continue\n",
    "            x_array+=[x[m1,m2]]\n",
    "    np.save(\"x_array\", x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e4d3043-90b8-492d-8c1a-1b45ec3a8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads in data \n",
    "x = {}\n",
    "x_array_read = np.load(\"x_array.npy\",allow_pickle=True)\n",
    "mycounter = -1\n",
    "for m1 in mass_range:\n",
    "    for m2 in mass_range:\n",
    "        if (m1==0 and m2>0 or m2==0 and m1>0):\n",
    "            continue\n",
    "        mycounter+=1\n",
    "        x[m1,m2] = x_array_read[mycounter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e982c79c-ebc9-4330-ba3f-020a3d9c4a48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.72332359, -0.98361217, -1.47351623,  0.1065722 ],\n",
       "       [-0.76381805, -1.17060296, -0.32160171, -1.15966026],\n",
       "       [-0.53039583, -0.75444364, -0.83465484,  0.14455233],\n",
       "       ...,\n",
       "       [-0.72849452, -1.20127827, -1.46586875, -0.17525045],\n",
       "       [-0.71564546, -1.27923195, -1.13014702,  0.1427768 ],\n",
       "       [-0.69956274, -1.30933612, -0.96529716, -0.55303517]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8695136e-87e9-46ff-8c38-24504ca2a192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_vals_100 = np.concatenate([x[1,1],x[0,0]])\n",
    "y_vals_100 = np.concatenate([np.ones(len(x[1,1])),np.zeros(len(x[0,0]))])\n",
    "X_train_100, X_val_100, Y_train_100, Y_val_100 = train_test_split(x_vals_100, y_vals_100, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dd69b8d-2704-4bcd-a3f4-4cac42859ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.72332359, -0.98361217, -1.47351623,  0.1065722 ],\n",
       "       [-0.76381805, -1.17060296, -0.32160171, -1.15966026],\n",
       "       [-0.53039583, -0.75444364, -0.83465484,  0.14455233],\n",
       "       ...,\n",
       "       [-0.8137767 , -0.68498134, -0.48486568, -1.80944097],\n",
       "       [-0.60554108, -0.3927861 ,  1.66516101, -0.46855806],\n",
       "       [-1.03992653,  0.32502271,  1.51100575, -1.56040698]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d37fda62-a40a-4b64-a02f-8668a9bddeac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgup-singh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gup-singh/Anomaly/runs/1sgjrd0o\" target=\"_blank\">lively-forest-29</a></strong> to <a href=\"https://wandb.ai/gup-singh/Anomaly\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initializies wandb config\n",
    "if not wandb.run:\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"Anomaly\",\n",
    "        group=\"Dedicated\",\n",
    "        entity='gup-singh',\n",
    "\n",
    "        config={\n",
    "            \"layer_1\": 256,\n",
    "            \"activation_1\": \"relu\",\n",
    "            \"layer_2\": 256,\n",
    "            \"activation_2\": \"relu\",\n",
    "            \"layer_3\": 256,\n",
    "            \"activation_3\": \"relu\",\n",
    "            \"output_layer\": 1,\n",
    "            \"output_activation\": \"sigmoid\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"metric\": \"accuracy\",\n",
    "            \"epoch\": 20,\n",
    "            \"batch_size\": 1024\n",
    "        }\n",
    "    )\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e648787-8408-4c0f-be9a-31f0d1b2181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        config = wandb.config\n",
    "        self.dense1 = Dense(config.layer_1, activation=config.activation_1)\n",
    "        \n",
    "        self.dense2 = Dense(config.layer_2, activation=config.activation_2)\n",
    "        \n",
    "        self.dense3 = Dense(config.layer_3, activation=config.activation_3)\n",
    "        \n",
    "        self.dense4 = Dense(config.output_layer, activation=config.output_activation)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        x = self.dense4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38640130-1c28-4ed7-9862-77aaa2f58a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  1280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,121\n",
      "Trainable params: 133,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 14:24:13.887283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 14:24:14.735999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6565 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:c3:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.build(input_shape=(None, X_train_100.shape[1]))\n",
    "model.compile(loss=config.loss, optimizer=config.optimizer, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865c4829-8a9b-4ecd-b563-7380a0240867",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 64/193 [========>.....................] - ETA: 0s - loss: 0.3127 - accuracy: 0.8725"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 14:24:16.024060: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/193 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.8992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 2s 6ms/step - loss: 0.2475 - accuracy: 0.8993 - val_loss: 0.1904 - val_accuracy: 0.9249\n",
      "Epoch 2/20\n",
      "166/193 [========================>.....] - ETA: 0s - loss: 0.1834 - accuracy: 0.9266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1824 - accuracy: 0.9270 - val_loss: 0.1820 - val_accuracy: 0.9271\n",
      "Epoch 3/20\n",
      "180/193 [==========================>...] - ETA: 0s - loss: 0.1794 - accuracy: 0.9278"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1794 - accuracy: 0.9277 - val_loss: 0.1781 - val_accuracy: 0.9282\n",
      "Epoch 4/20\n",
      "177/193 [==========================>...] - ETA: 0s - loss: 0.1793 - accuracy: 0.9281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 6ms/step - loss: 0.1790 - accuracy: 0.9282 - val_loss: 0.1768 - val_accuracy: 0.9283\n",
      "Epoch 5/20\n",
      "181/193 [===========================>..] - ETA: 0s - loss: 0.1769 - accuracy: 0.9286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1773 - accuracy: 0.9285 - val_loss: 0.1764 - val_accuracy: 0.9288\n",
      "Epoch 6/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9286 - val_loss: 0.1765 - val_accuracy: 0.9288\n",
      "Epoch 7/20\n",
      "181/193 [===========================>..] - ETA: 0s - loss: 0.1772 - accuracy: 0.9285"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1771 - accuracy: 0.9286 - val_loss: 0.1760 - val_accuracy: 0.9290\n",
      "Epoch 8/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9288 - val_loss: 0.1770 - val_accuracy: 0.9285\n",
      "Epoch 9/20\n",
      "180/193 [==========================>...] - ETA: 0s - loss: 0.1758 - accuracy: 0.9293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1757 - accuracy: 0.9293 - val_loss: 0.1756 - val_accuracy: 0.9290\n",
      "Epoch 10/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9290 - val_loss: 0.1757 - val_accuracy: 0.9292\n",
      "Epoch 11/20\n",
      "178/193 [==========================>...] - ETA: 0s - loss: 0.1763 - accuracy: 0.9288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1765 - accuracy: 0.9288 - val_loss: 0.1754 - val_accuracy: 0.9290\n",
      "Epoch 12/20\n",
      "180/193 [==========================>...] - ETA: 0s - loss: 0.1754 - accuracy: 0.9294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1755 - accuracy: 0.9293 - val_loss: 0.1752 - val_accuracy: 0.9289\n",
      "Epoch 13/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9289 - val_loss: 0.1754 - val_accuracy: 0.9295\n",
      "Epoch 14/20\n",
      "181/193 [===========================>..] - ETA: 0s - loss: 0.1749 - accuracy: 0.9293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1750 - accuracy: 0.9291 - val_loss: 0.1745 - val_accuracy: 0.9298\n",
      "Epoch 15/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9290 - val_loss: 0.1759 - val_accuracy: 0.9289\n",
      "Epoch 16/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9295 - val_loss: 0.1779 - val_accuracy: 0.9280\n",
      "Epoch 17/20\n",
      "181/193 [===========================>..] - ETA: 0s - loss: 0.1747 - accuracy: 0.9291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1748 - accuracy: 0.9291 - val_loss: 0.1742 - val_accuracy: 0.9294\n",
      "Epoch 18/20\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9297 - val_loss: 0.1764 - val_accuracy: 0.9289\n",
      "Epoch 19/20\n",
      "181/193 [===========================>..] - ETA: 0s - loss: 0.1742 - accuracy: 0.9295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1740 - accuracy: 0.9296 - val_loss: 0.1740 - val_accuracy: 0.9301\n",
      "Epoch 20/20\n",
      "181/193 [===========================>..] - ETA: 0s - loss: 0.1739 - accuracy: 0.9294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142413-1sgjrd0o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 5ms/step - loss: 0.1740 - accuracy: 0.9294 - val_loss: 0.1737 - val_accuracy: 0.9300\n"
     ]
    }
   ],
   "source": [
    "myhistory = model.fit(x_vals_100, y_vals_100, epochs=config.epoch, validation_data=(X_val_100, Y_val_100),batch_size=config.batch_size, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6aa950c-4790-466d-8f3f-867da3a0a19d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇██████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▆▆▇▆▇▇▆▆▇█▆▅▇▆██</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▁▂▃▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.92941</td></tr><tr><td>best_epoch</td><td>19</td></tr><tr><td>best_val_loss</td><td>0.17367</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.17404</td></tr><tr><td>val_accuracy</td><td>0.93001</td></tr><tr><td>val_loss</td><td>0.17367</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lively-forest-29</strong>: <a href=\"https://wandb.ai/gup-singh/Anomaly/runs/1sgjrd0o\" target=\"_blank\">https://wandb.ai/gup-singh/Anomaly/runs/1sgjrd0o</a><br/>Synced 5 W&B file(s), 1 media file(s), 40 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230914_142413-1sgjrd0o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303cf48d-50d6-4203-bff5-dfd452387b24",
   "metadata": {},
   "source": [
    "Analysis of Models begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40b790d6-6abd-49d2-b7e3-0bcc38935d69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(myhistory.history['loss'])\n",
    "plt.plot(myhistory.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['training loss', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49f7630e-2bf1-45dd-b7c8-9d75277d1cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 649us/step\n"
     ]
    }
   ],
   "source": [
    "preds_100 = model.predict(X_val_100,batch_size=1000)\n",
    "fpr_100, tpr_100, _ = roc_curve(Y_val_100, preds_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "408a0cfc-8966-4c2d-a69d-9e8a346e1d72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLuElEQVR4nO3deXhTVf4G8DdJm6T7YulKsOyL7CD8CiKDVIoLyrhQhZFSFTdAhoqyU5CljAjiCIqiUEGUAoPKCMJIFWVTtKUsAkVoy9oWKtB0T5Oc3x9tA6ELTU1ym/T9PE8ekptzb765ovf15NxzZEIIASIiIiInIZe6ACIiIiJrYrghIiIip8JwQ0RERE6F4YaIiIicCsMNERERORWGGyIiInIqDDdERETkVBhuiIiIyKkw3BAREZFTYbghIiIip8JwQ0R1SkxMhEwmMz1cXFwQFhaGMWPG4OLFizXuI4TAunXrcO+998LX1xfu7u7o0qUL3nzzTRQVFdX6WV9++SUeeOABBAQEQKlUIjQ0FCNGjMD3339fr1pLS0vxzjvvoG/fvvDx8YFarUa7du0wfvx4nDp1qkHfn4gcj4xrSxFRXRITExEbG4s333wTLVu2RGlpKX7++WckJiYiPDwcx44dg1qtNrU3GAwYOXIkNm7ciAEDBuCxxx6Du7s79uzZg88//xydOnXCrl27EBQUZNpHCIFnn30WiYmJ6NGjB5544gkEBwcjOzsbX375JVJSUrBv3z7069ev1jrz8vIwdOhQpKSk4OGHH0ZkZCQ8PT2Rnp6ODRs2ICcnBzqdzqbniogaCUFEVIc1a9YIAOLXX3812z5lyhQBQCQlJZltX7hwoQAgJk+eXO1YW7duFXK5XAwdOtRs++LFiwUA8c9//lMYjcZq+61du1b88ssvddb50EMPCblcLjZv3lztvdLSUvHaa6/VuX99lZeXi7KyMqsci4hsg+GGiOpUW7j55ptvBACxcOFC07bi4mLh5+cn2rVrJ8rLy2s8XmxsrAAgDhw4YNrH399fdOjQQej1+gbV+PPPPwsAYuzYsfVqP3DgQDFw4MBq22NiYsSdd95pep2ZmSkAiMWLF4t33nlHtGrVSsjlcvHzzz8LhUIh5syZU+0YJ0+eFADEe++9Z9p27do1MXHiRNG8eXOhVCpF69atxaJFi4TBYLD4uxLR7XHMDRE1SFZWFgDAz8/PtG3v3r24du0aRo4cCRcXlxr3Gz16NADgm2++Me1z9epVjBw5EgqFokG1bN26FQDwzDPPNGj/21mzZg3ee+89vPDCC1iyZAlCQkIwcOBAbNy4sVrbpKQkKBQKPPnkkwCA4uJiDBw4EJ999hlGjx6Nf//73+jfvz+mTZuGuLg4m9RL1NTV/F8fIqJb5OfnIy8vD6Wlpfjll18wd+5cqFQqPPzww6Y2x48fBwB069at1uNUvXfixAmzP7t06dLg2qxxjLpcuHABp0+fRrNmzUzboqOj8eKLL+LYsWPo3LmzaXtSUhIGDhxoGlO0dOlSnDlzBocOHULbtm0BAC+++CJCQ0OxePFivPbaa9BoNDapm6ipYs8NEdVLZGQkmjVrBo1GgyeeeAIeHh7YunUrmjdvbmpTUFAAAPDy8qr1OFXvabVasz/r2ud2rHGMujz++ONmwQYAHnvsMbi4uCApKcm07dixYzh+/Diio6NN2zZt2oQBAwbAz88PeXl5pkdkZCQMBgN++uknm9RM1JSx54aI6mXFihVo164d8vPzsXr1avz0009QqVRmbarCRVXIqcmtAcjb2/u2+9zOzcfw9fVt8HFq07Jly2rbAgICMHjwYGzcuBHz5s0DUNFr4+Ligscee8zU7o8//sCRI0eqhaMqly9ftnq9RE0dww0R1UufPn3Qu3dvAMDw4cNxzz33YOTIkUhPT4enpycAoGPHjgCAI0eOYPjw4TUe58iRIwCATp06AQA6dOgAADh69Git+9zOzccYMGDAbdvLZDKIGmbBMBgMNbZ3c3OrcftTTz2F2NhYpKWloXv37ti4cSMGDx6MgIAAUxuj0Yj7778fb7zxRo3HaNeu3W3rJSLL8GcpIrKYQqFAQkICLl26hOXLl5u233PPPfD19cXnn39ea1BYu3YtAJjG6txzzz3w8/PDF198Ues+tzNs2DAAwGeffVav9n5+frh+/Xq17WfPnrXoc4cPHw6lUomkpCSkpaXh1KlTeOqpp8zatG7dGoWFhYiMjKzx0aJFC4s+k4huj+GGiBrkb3/7G/r06YNly5ahtLQUAODu7o7JkycjPT0dM2bMqLbPtm3bkJiYiKioKPzf//2faZ8pU6bgxIkTmDJlSo09Kp999hkOHjxYay0REREYOnQoPv74Y3z11VfV3tfpdJg8ebLpdevWrXHy5ElcuXLFtO3w4cPYt29fvb8/APj6+iIqKgobN27Ehg0boFQqq/U+jRgxAgcOHMDOnTur7X/9+nXo9XqLPpOIbo8zFBNRnapmKP71119NP0tV2bx5M5588kl88MEHeOmllwBU/LQTHR2N//znP7j33nvx+OOPw83NDXv37sVnn32Gjh07Ijk52WyGYqPRiDFjxmDdunXo2bOnaYbinJwcfPXVVzh48CD279+PiIiIWuu8cuUKhgwZgsOHD2PYsGEYPHgwPDw88Mcff2DDhg3Izs5GWVkZgIq7qzp37oxu3brhueeew+XLl7Fy5UoEBQVBq9WabnPPyspCy5YtsXjxYrNwdLP169fjH//4B7y8vPC3v/3NdFt6leLiYgwYMABHjhzBmDFj0KtXLxQVFeHo0aPYvHkzsrKyzH7GIiIrkHaaHSJq7GqbxE8IIQwGg2jdurVo3bq12QR8BoNBrFmzRvTv3194e3sLtVot7rrrLjF37lxRWFhY62dt3rxZDBkyRPj7+wsXFxcREhIioqOjxe7du+tVa3FxsXj77bfF3XffLTw9PYVSqRRt27YVEyZMEKdPnzZr+9lnn4lWrVoJpVIpunfvLnbu3FnnJH610Wq1ws3NTQAQn332WY1tCgoKxLRp00SbNm2EUqkUAQEBol+/fuLtt98WOp2uXt+NiOqPPTdERETkVDjmhoiIiJwKww0RERE5FYYbIiIicioMN0RERORUGG6IiIjIqTDcEBERkVNpcmtLGY1GXLp0CV5eXpDJZFKXQ0RERPUghEBBQQFCQ0Mhl9fdN9Pkws2lS5eg0WikLoOIiIga4Pz582jevHmdbZpcuPHy8gJQcXK8vb0lroaIiIjqQ6vVQqPRmK7jdWly4abqpyhvb2+GGyIiIgdTnyElHFBMREREToXhhoiIiJwKww0RERE5FYYbIiIicioMN0RERORUGG6IiIjIqTDcEBERkVNhuCEiIiKnwnBDREREToXhhoiIiJyKpOHmp59+wrBhwxAaGgqZTIavvvrqtvvs3r0bPXv2hEqlQps2bZCYmGjzOomIiMhxSBpuioqK0K1bN6xYsaJe7TMzM/HQQw9h0KBBSEtLwz//+U88//zz2Llzp40rJSIiIkch6cKZDzzwAB544IF6t1+5ciVatmyJJUuWAAA6duyIvXv34p133kFUVJStyiQiokZKCHHT88o/ARhr2F7x3k0vbnmv+rFveY2aj1n1mbXWVddx6/iMW9s2+DNuPW4dtVvrOytd5Aj0UkMqDrUq+IEDBxAZGWm2LSoqCv/85z9r3aesrAxlZWWm11qt1lblETVJQggYjAL6yofBIKA3GqE3Cuj0RggBGISAUYjKthUXHoNRmN4zGKuOYYTReKO9sXK7UQiUlhtRWKaHu1IBvbHyvco2eqNAucGIS9dLEeitqtwPpvdvPt6ZK0UI8VFDLpPBUFmTsbImo6j688bz3PxSCAD+HkoIUVGzUYjKCyjMt9303s3bjQJIO38dncO8K89Z5QM3LggVr4XZdgEAt7yuanfzcVDD+7naMigVcni7uQI1XKAEbuwH1HyBq+k91LK/+baq18LstdmxbmlTV201HZsat54tfLHllf6Sfb5DhZucnBwEBQWZbQsKCoJWq0VJSQnc3Nyq7ZOQkIC5c+faq0Qim9MbjCjTG1FSboBOX/G8oLS84gKvN0JnMOJKQRlULgqUlhtw7moxvNQuprBx+nIhmnmpoDdUtNXpBUr1BugNRhiMAuWGikChq/wcnd4Ind4AncGI0nIj9AYj9AaBcmPFa6q/Yxft+z9XOoMReYVlt29ITksmu+W12XuyGrffup/s1ndlNT4120/pIu39Sg4Vbhpi2rRpiIuLM73WarXQaDQSVkRNiU5vRH5JOYrK9MgvKYe2tByFpXoU6wwo0ulRojOgpNxQ8bpMj6MX8xHio0bK2Wto4e+O0nIjjmdrEeytRo62VOqvYxGFXAaXyodcJoNcLoNcBrPnCpkMMpkMCrnM1F5hal/xvlwuM/2pLSmHTm9EizvcTdtc5DfaGCp7WtoEepq2VR1PIb/x2eevFqNVgIfZsWVVtZn+rHwul6GozAAXuQxeahfIZTLgprZV+wEVf1a9lqHi4lHRpuJ1kU5f2ZMC0/sVf1ZcQCoPDdzyWia7+XlFg6qLSG3HAQC9UUDtKq9sd9OF7KZ9b36NOttUvxDeaFN9v2rHsXD/GkoytatPbfJqhVSvqYa3zI5V/b3qtdR2zNreq2u/6kGhnuGjrg9vohwq3AQHByM3N9dsW25uLry9vWvstQEAlUoFlUplj/LICRmNAoU6PfKLy1GsMyCvsAxFZXr8WaTD2T+LcfF6CdQuchSU6nEg40+E+KhRpNOjoFSPojI9yg2W96EfuZAPAMgr1Jm21RVsvFQuULnKkVeoQ6tmHlAq5FC5yHH6ciF6hftD5SLHuT+L0SnUG2pXOZQKOS5eL0WHYC+oXORQVj5cFfKKMKKQw1VREQqUCjnUrgpTG9VN7VwVcrhUtlMpFFAoboQZhVzG/+ASkWQcKtxERERg+/btZtu+++47RERESFQRORqDUeB6sQ6XC8qQqy3Fn4U65GhLceZyIVwUMlwuKMOfhTpcL9GhoLQipBiM9Q8o+SXlNW73UCrg7eYKb7UrvNQucFMq4K5UwENZ8dzNteK1ylWBEp0BrQM9UFZuRLCPGmpXBVwVMvi5K6FyVcBDqYDKpSJwKOQMEEREt5I03BQWFuL06dOm15mZmUhLS4O/vz9atGiBadOm4eLFi1i7di0A4KWXXsLy5cvxxhtv4Nlnn8X333+PjRs3Ytu2bVJ9BWokhBC4XlyO01cKcaWgDNeKdbh4rQQHMv6Er5srTuUW4lJ+CRQyGfQWhJVbeatd4KqQo5vGF808VXBTKiCEQOtAT/i6KyGXASE+aniqKkKMu1IBb7Ur5AwhRER2I2m4+e233zBo0CDT66qxMTExMUhMTER2djbOnTtner9ly5bYtm0bJk2ahHfffRfNmzfHxx9/zNvAm4iiMj2y/ixCrrYUGVeKkJ1fiovXSnDmSiEuXi9Bsc5w22PoK2+18HV3RbC3Gs28VPD3UMJT5QKjEOih8UOAlxI+pl4WV/i6u0LlIufPLEREDkImRNO6sU6r1cLHxwf5+fnw9vaWuhy6iRACVwrLcP5qMS5cK8G5P4tx9moxLlwrRsaVIlwuuP1dHx5KBYp0BnQJ80F3jS+CfdQQQqBDsDf8PFwR6KVGsI8argquPEJE5EgsuX471Jgbch5CCGTmFeG3rGtIPXcNp3IL8MflQhSU6uvcz0vtgoJSPSI7BqJVM08EeavRJtATYb5uaO7nBrWrwk7fgIiIGiuGG7KLKwVlOHYxH4cvXMexi/n4/ZIW2fnV7wCSy4BgbzU0/u4I83NDyzs80NzfDXfe4YHWzTzhU3kbLRERUW0YbsjqinV6pJ69jrTz13A8W4sT2QXIzCuq1k6pkKO7xhc9Wviic5gP2gR6omWAB3tfiIjoL2G4ob+stNyAg5lX8dOpK/jmSDbyCstqvCOpdTMPdAnzQTeNLzqGeKNLmA88VPwrSERE1sUrC1ms3GDE4fPXcTDrKg5mXsXeP/KqhZkQHzW6NvdBzxZ+aB/shS5hPrjDk5MpEhGR7THcUL1k55cg+cRl7Pw9B6lnr6Holtuug7xVGNC2GXq08EXflnegdTMP3jpNRESSYLihGgkhcCq3EMknc7Hz91wcPn/d7H0fN1f0bemPu8P90a/NHegU4s0wQ0REjQLDDZk5maPFt0dzsDnlAi5eLzFtl8mArmE+GHJXMAa1D0T7YC9O/U9ERI0Sww3BaBT47kQu1uzLxM8ZV03blQo5+rT0x6AOgXikWyiaeXHMDBERNX4MN03YlYIyrP/lLDb9dqOXRi4D/tY+EEPvCsaDXUPgybuZiIjIwfDK1cQIIfBzxlV8fvActh/NNq147aVywRO9myMmIhzhAR4SV0lERNRwDDdNyMHMq1iw/YTZ4ODOYd54tn9LDO0cDHcl/zoQEZHj49WsCbhcUIr535zA1sOXAFSMpXm8V3OM7NMCXZr7SFwdERGRdTHcODGDUSBxfxaWfXcKBWV6yGTAU3e3wKTItgj0VktdHhERkU0w3DipvX/k4c1vfsep3EIAQMcQb7z56F24O9xf4sqIiIhsi+HGyej0RiR8ewJr9mUBANyVCsTd3w4x/cLhqpBLWxwREZEdMNw4kR9PXcGCbcdNvTVP9mqO6Q92hJ+HUuLKiIiI7IfhxgnoDUYs3pmOD3/KAAB4KBVIeLwrHukWKnFlRERE9sdw4+AuXCvG5E2HTTMLR/fWIG5IOwRxwDARETVRDDcOLPlELl5enwqd3ghXhQwLhnfBiLs1UpdFREQkKYYbB7XnjysY//kh6PRGhN/hjvdH9UKnUG+pyyIiIpIcw40D2n86Dy+sTUFJuQH/18ofibF9oHZVSF0WERFRo8Bw42Bu/inq/1r5Y80YBhsiIqKbceITB5J67prpp6hB7ZthzZg+cFMy2BAREd2MPTcOYs8fVzB27W8oLa/osfnwmd5QujCbEhER3YpXRwdw/moxXlibgtJyI3rf6YeV/+jFYENERFQL9tw0cgajwPQvj6Kk3ICOId747Pm+HGNDRERUB/7vfyP31o6T2PNHHlwVMrwT3Y3BhoiI6DYYbhqxlLPX8PHeTADA/OGd0SGY89gQERHdDsNNI1VabsC0LUdgMAo83DUE0Xe3kLokIiIih8Bw00i9vTMdp3ILcYeHEjMf6iR1OURERA6D4aYR+iXjT9PPUQsf64JgHy6CSUREVF8MN42MtrQccRsPAwCG3hWMIZ2CJK6IiIjIsTDcNDIrd5/BxeslaOalwr8e7wqZTCZ1SURERA6F4aYRKdbpkbg/CwAw86GO8HF3lbYgIiIiB8Rw04hs/PU8inUGhPio8Ui3UKnLISIickgMN42E0Siwak/FIOJn+7fkz1FEREQNxHDTSOw9nYeL10ugVMjxdF/OaUNERNRQDDeNxIofTgMAnuzdHJ4qLvlFRETUUAw3jcD+M3n4JfMqXOQyvDSwtdTlEBEROTSGm0Zg/S/nAABP9GoOjb+7xNUQERE5NoYbif1ZWIbvfs8FAIy4WyNxNURERI6P4UZiH/6UAZ3BiA7BXuih8ZW6HCIiIofHcCOhgtJyrNqTAQD4Z2Rb3v5NRERkBQw3Evr+5GUIUfE8siPXkCIiIrIGhhsJ/fdwNgAgtn84XBT8R0FERGQNvKJKRFtaju9PVgwk/sf/3SlxNURERM6D4UYim367AKMAWgV4oHUzT6nLISIichoMNxLZfrTiJ6lhXCCTiIjIqhhuJKDTG3H0Qj4A4P5OHEhMRERkTQw3Evgt6yp0BiMCPJXoFOItdTlEREROheFGAv87XjGQ+P9a3QG5nHPbEBERWRPDjQR+OnUFAPBglxCJKyEiInI+DDd2lp1fgoy8IshlQP82AVKXQ0RE5HQYbuzs54w/AQDtg73h4+YqcTVERETOh+HGzr46dAkA0CfcT+JKiIiInJPk4WbFihUIDw+HWq1G3759cfDgwTrbL1u2DO3bt4ebmxs0Gg0mTZqE0tJSO1X71wgh8PulilvA7+NaUkRERDYhabhJSkpCXFwc4uPjkZqaim7duiEqKgqXL1+usf3nn3+OqVOnIj4+HidOnMAnn3yCpKQkTJ8+3c6VN8yZK0XIK9QBAPqE+0tcDRERkXOSNNwsXboUY8eORWxsLDp16oSVK1fC3d0dq1evrrH9/v370b9/f4wcORLh4eEYMmQInn766dv29jQWh85dAwB01/jCTamQuBoiIiLnJFm40el0SElJQWRk5I1i5HJERkbiwIEDNe7Tr18/pKSkmMJMRkYGtm/fjgcffLDWzykrK4NWqzV7SOXc1WIAQMcQL8lqICIicnYuUn1wXl4eDAYDgoLMx54EBQXh5MmTNe4zcuRI5OXl4Z577oEQAnq9Hi+99FKdP0slJCRg7ty5Vq29oc5cKQQAhN/hIXElREREzkvyAcWW2L17NxYuXIj3338fqamp2LJlC7Zt24Z58+bVus+0adOQn59vepw/f96OFZtLOVvxs1QHLrlARERkM5L13AQEBEChUCA3N9dse25uLoKDg2vcZ9asWXjmmWfw/PPPAwC6dOmCoqIivPDCC5gxYwbk8upZTaVSQaVSWf8LWCgrrwi52jIAQI8WvtIWQ0RE5MQk67lRKpXo1asXkpOTTduMRiOSk5MRERFR4z7FxcXVAoxCUTEwVwhhu2KtYN+ZPACAxt8N3mpO3kdERGQrkvXcAEBcXBxiYmLQu3dv9OnTB8uWLUNRURFiY2MBAKNHj0ZYWBgSEhIAAMOGDcPSpUvRo0cP9O3bF6dPn8asWbMwbNgwU8hprI5eqJjfJqLVHRJXQkRE5NwkDTfR0dG4cuUKZs+ejZycHHTv3h07duwwDTI+d+6cWU/NzJkzIZPJMHPmTFy8eBHNmjXDsGHDsGDBAqm+Qr2dyCkAAHTieBsiIiKbkonG/nuOlWm1Wvj4+CA/Px/e3vYJGqXlBnSYtQMA8P1rA9GqmaddPpeIiMhZWHL9dqi7pRzVoXPXTc95GzgREZFtMdzYwenK+W2UCjnkcpnE1RARETk3hhs7+E/KBQDAs/e0lLgSIiIi58dwYwfaknIAXHaBiIjIHhhubKy03IDMP4sAAHdzJXAiIiKbY7ixsQvXSiAE4OaqQIiPWupyiIiInB7DjY2dv1axEvidd7hDJuNgYiIiIltjuLGxzCsVP0k193OXuBIiIqKmgeHGxo5drFh2oVMoZyYmIiKyB4YbG/vpjysAgLaBnJWYiIjIHhhubEzlUrGg5x0eSokrISIiahoYbmzIYBS4eL0EABDq6yZxNURERE0Dw40N5WhLTc81/hxQTEREZA8MNzZ0/mqx6bmCa0oRERHZBcONDZ2tnJnYXamQuBIiIqKmg+HGhk5frlgNnONtiIiI7IfhxoYu5VeMuRncIVDiSoiIiJoOhhsbOnz+OgCgYwgn8CMiIrIXhhsbul5cDgDw4xw3REREdsNwY0OFZXoAnMCPiIjInhhubMRoFKhaBNyf4YaIiMhuGG5spEinhxAVz33dXaUthoiIqAlhuLGRC9dKTM/dXDnPDRERkb0w3NhIdv6NcCOTcXZiIiIie2G4sZFrRRV3SrUM8JC4EiIioqaF4cZGCkorwg0HExMREdkXw42NHLukBQB0be4jcSVERERNC8ONjZSUGwBw0UwiIiJ7Y7ixkdSz1wAAHYK59AIREZE9MdzYSLnBCADwVLtIXAkREVHTwnBjI2XlFeEmzNdN4kqIiIiaFoYbG9DpjSioXFcq0EslcTVERERNC8ONDfxZVGZ67q3m0gtERET29JfCTWlpqbXqcCpXi3Sm53I5ZycmIiKyJ4vDjdFoxLx58xAWFgZPT09kZGQAAGbNmoVPPvnE6gU6ooLSip+kWjfj7MRERET2ZnG4mT9/PhITE/HWW29Bqbwx+27nzp3x8ccfW7U4R1VaOceNmgtmEhER2Z3F4Wbt2rX46KOPMGrUKCgUNy7e3bp1w8mTJ61anKPKzq/4uU7lwiFNRERE9mbx1ffixYto06ZNte1GoxHl5eVWKcrRKRUVp/Xc1WKJKyEiImp6LA43nTp1wp49e6pt37x5M3r06GGVohzdpeslAIDed/pLXAkREVHTY/H0ubNnz0ZMTAwuXrwIo9GILVu2ID09HWvXrsU333xjixodTrlRAACKdHqJKyEiImp6LO65efTRR/Hf//4Xu3btgoeHB2bPno0TJ07gv//9L+6//35b1OhwdPqK2Yn93JW3aUlERETW1qCFjwYMGIDvvvvO2rU4jVxtxYBizk5MRERkfxb33LRq1Qp//vlnte3Xr19Hq1atrFKUo5NVztun4AR+REREdmdxuMnKyoLBYKi2vaysDBcvXrRKUY4uv7jirrEWd7hLXAkREVHTU++fpbZu3Wp6vnPnTvj4+JheGwwGJCcnIzw83KrFOSptaUW44ZgbIiIi+6t3uBk+fDgAQCaTISYmxuw9V1dXhIeHY8mSJVYtzlEVllX0bLkpOUMxERGRvdU73BiNFXcAtWzZEr/++isCAgJsVpSjK6jsufFSNWi8NhEREf0FFl99MzMzbVGHU7lwrWISP193V4krISIianoa1LVQVFSEH3/8EefOnYNOpzN779VXX7VKYY5KCAGZDBAC8GDPDRERkd1ZfPU9dOgQHnzwQRQXF6OoqAj+/v7Iy8uDu7s7AgMDm3y4KdMbISomKIaXmj03RERE9mbxreCTJk3CsGHDcO3aNbi5ueHnn3/G2bNn0atXL7z99tu2qNGhFJbdWHJBzVXBiYiI7M7iq29aWhpee+01yOVyKBQKlJWVQaPR4K233sL06dNtUaNDKdHdmAPIRcFwQ0REZG8WX31dXV0hl1fsFhgYiHPnzgEAfHx8cP78eetW54DK9BXhhoOJiYiIpGHxmJsePXrg119/Rdu2bTFw4EDMnj0beXl5WLduHTp37myLGh3K9crZiV3k7LUhIiKSgsVX4IULFyIkJAQAsGDBAvj5+eHll1/GlStX8OGHH1q9QEdTbqgYTZxXWCZxJURERE2TxT03vXv3Nj0PDAzEjh07rFqQoyuqHFDctbnPbVoSERGRLVjtt5PU1FQ8/PDDFu+3YsUKhIeHQ61Wo2/fvjh48GCd7a9fv45x48YhJCQEKpUK7dq1w/bt2xtattVVrSvlpeYcN0RERFKwKNzs3LkTkydPxvTp05GRkQEAOHnyJIYPH467777btERDfSUlJSEuLg7x8fFITU1Ft27dEBUVhcuXL9fYXqfT4f7770dWVhY2b96M9PR0rFq1CmFhYRZ9ri0VlFb03HgoGW6IiIikUO8r8CeffIKxY8fC398f165dw8cff4ylS5diwoQJiI6OxrFjx9CxY0eLPnzp0qUYO3YsYmNjAQArV67Etm3bsHr1akydOrVa+9WrV+Pq1avYv38/XF0r7kZqbCuRn79aDABQyGUSV0JERNQ01bvn5t1338W//vUv5OXlYePGjcjLy8P777+Po0ePYuXKlRYHG51Oh5SUFERGRt4oRi5HZGQkDhw4UOM+W7duRUREBMaNG4egoCB07twZCxcuhMFgqLE9AJSVlUGr1Zo9bKlqVuL8knKbfg4RERHVrN7h5syZM3jyyScBAI899hhcXFywePFiNG/evEEfnJeXB4PBgKCgILPtQUFByMnJqXGfjIwMbN68GQaDAdu3b8esWbOwZMkSzJ8/v9bPSUhIgI+Pj+mh0WgaVG99XbhW0XPTMcTbpp9DRERENat3uCkpKYG7uzsAQCaTQaVSmW4Jtxej0YjAwEB89NFH6NWrF6KjozFjxgysXLmy1n2mTZuG/Px808PWEw2W6ivGHekNlo0/IiIiIuuwaNTrxx9/DE9PTwCAXq9HYmIiAgICzNrUd+HMgIAAKBQK5Obmmm3Pzc1FcHBwjfuEhITA1dUVCoXCtK1jx47IycmBTqeDUqmsto9KpYJKpapXTdagqlxPSuWquE1LIiIisoV6h5sWLVpg1apVptfBwcFYt26dWRuZTFbvcKNUKtGrVy8kJydj+PDhACp6ZpKTkzF+/Pga9+nfvz8+//xzGI1G0xIQp06dQkhISI3BRgqHzl0DAIT6qCWuhIiIqGmqd7jJysqy+ofHxcUhJiYGvXv3Rp8+fbBs2TIUFRWZ7p4aPXo0wsLCkJCQAAB4+eWXsXz5ckycOBETJkzAH3/8gYULF9Y7UNmDxt8dZ64UmW4JJyIiIvuSdDKW6OhoXLlyBbNnz0ZOTg66d++OHTt2mAYZnzt3ztRDAwAajQY7d+7EpEmT0LVrV4SFhWHixImYMmWKVF+hGl3lmJsWd7hLXAkREVHTJBNCCKmLsCetVgsfHx/k5+fD29v6dzQ9/sF+pJy9hpX/6Imhne074JqIiMhZWXL95tLVVpZytmLMjauCp5aIiEgKvAJbWdvAirvJDMYm1SFGRETUaDDcWFl55fw2/h6N4+4tIiKipqZB4ebMmTOYOXMmnn76adMil99++y1+//13qxbniKoGFCtdmBuJiIikYPEV+Mcff0SXLl3wyy+/YMuWLSgsLAQAHD58GPHx8VYv0NFcyi8FwDE3REREUrH4Cjx16lTMnz8f3333ndnEeffddx9+/vlnqxbniNwqZyZmzw0REZE0LL4CHz16FH//+9+rbQ8MDEReXp5VinJURqNASXnFCuU+bq4SV0NERNQ0WRxufH19kZ2dXW37oUOHEBYWZpWiHJW2tNz03Est6fyIRERETZbF4eapp57ClClTkJOTA5lMBqPRiH379mHy5MkYPXq0LWp0GGWVg4nlMkDlwoUziYiIpGBxuFm4cCE6dOgAjUaDwsJCdOrUCffeey/69euHmTNn2qJGh1F1pxSDDRERkXQs/u1EqVRi1apVmDVrFo4dO4bCwkL06NEDbdu2tUV9DqVIV7FYJgcTExERScficLN3717cc889aNGiBVq0aGGLmhyW3lAxK3F+SfltWhIREZGtWNzFcN9996Fly5aYPn06jh8/bouaHJa+csmFEB+1xJUQERE1XRaHm0uXLuG1117Djz/+iM6dO6N79+5YvHgxLly4YIv6HIreUDXmhj9LERERScXiq3BAQADGjx+Pffv24cyZM3jyySfx6aefIjw8HPfdd58tanQY5ZU/S7lwdmIiIiLJ/KWrcMuWLTF16lQsWrQIXbp0wY8//mituhxS1aKZLnKZxJUQERE1XQ0ON/v27cMrr7yCkJAQjBw5Ep07d8a2bdusWZvDuVasAwDoKkMOERER2Z/Fd0tNmzYNGzZswKVLl3D//ffj3XffxaOPPgp3d3db1OdQqua3+bNQJ3ElRERETZfF4eann37C66+/jhEjRiAgIMAWNTksvbGix6ZDsJfElRARETVdFoebffv22aIOp1A1z40rBxQTERFJpl7hZuvWrXjggQfg6uqKrVu31tn2kUcesUphjsg0oFjBAcVERERSqVe4GT58OHJychAYGIjhw4fX2k4mk8FgMFirNodTNYkf75YiIiKSTr3CjdForPE5mSstrwh2XFuKiIhIOhZfhdeuXYuysrJq23U6HdauXWuVohxV1ZgbrgpOREQkHYvDTWxsLPLz86ttLygoQGxsrFWKclRVP0sp+LMUERGRZCwON0IIyGTVL94XLlyAj4+PVYpyVAYjZygmIiKSWr1vBe/RowdkMhlkMhkGDx4MF5cbuxoMBmRmZmLo0KE2KdJRsOeGiIhIevUON1V3SaWlpSEqKgqenp6m95RKJcLDw/H4449bvUBHUjXmhj03RERE0ql3uImPjwcAhIeHIzo6Gmq12mZFOapTuQUAAIWcd0sRERFJxeIZimNiYmxRh1PQ+Fesr3XuapHElRARETVd9Qo3/v7+OHXqFAICAuDn51fjgOIqV69etVpxjkZU/CqFtkFcW4qIiEgq9Qo377zzDry8vEzP6wo3TZmxMt1wyA0REZF06hVubv4pasyYMbaqxWnIwHRDREQkFYtHvqampuLo0aOm119//TWGDx+O6dOnQ6fTWbU4R8OeGyIiIulZHG5efPFFnDp1CgCQkZGB6OhouLu7Y9OmTXjjjTesXqAjqQo3/NmOiIhIOhaHm1OnTqF79+4AgE2bNmHgwIH4/PPPkZiYiP/85z/Wrs+hVA0oZrYhIiKSToOWX6haGXzXrl148MEHAQAajQZ5eXnWrc7BVE5QDDnTDRERkWQsDje9e/fG/PnzsW7dOvz444946KGHAACZmZkICgqyeoGOhWNuiIiIpGZxuFm2bBlSU1Mxfvx4zJgxA23atAEAbN68Gf369bN6gY6kskOLY26IiIgkZPEMxV27djW7W6rK4sWLoVAorFKUo7oxoFjiQoiIiJowi8NNlZSUFJw4cQIA0KlTJ/Ts2dNqRTmqyiE3HHNDREQkIYvDzeXLlxEdHY0ff/wRvr6+AIDr169j0KBB2LBhA5o1a2btGh2GqedG4jqIiIiaMovH3EyYMAGFhYX4/fffcfXqVVy9ehXHjh2DVqvFq6++aosaHQfvliIiIpKcxT03O3bswK5du9CxY0fTtk6dOmHFihUYMmSIVYtzNBxzQ0REJD2Le26MRiNcXV2rbXd1dTXNf9NU6Y2coZiIiEhqFoeb++67DxMnTsSlS5dM2y5evIhJkyZh8ODBVi3O0ZzMKQBQMdEhERERScPicLN8+XJotVqEh4ejdevWaN26NVq2bAmtVov33nvPFjU6jDbNPAEA14vLJa6EiIio6bJ4zI1Go0FqaiqSk5NNt4J37NgRkZGRVi/O0Rgqe2xCfd0kroSIiKjpsijcJCUlYevWrdDpdBg8eDAmTJhgq7ockrFyzI3C4v4wIiIispZ6h5sPPvgA48aNQ9u2beHm5oYtW7bgzJkzWLx4sS3rcyhVPTe8FZyIiEg69e5jWL58OeLj45Geno60tDR8+umneP/9921Zm8MxmHpuGG6IiIikUu9wk5GRgZiYGNPrkSNHQq/XIzs72yaFOSLBSfyIiIgkV+9wU1ZWBg8Pjxs7yuVQKpUoKSmxSWGOqKrnRs6eGyIiIslYNKB41qxZcHd3N73W6XRYsGABfHx8TNuWLl1qveocTNWYGwV7boiIiCRT73Bz7733Ij093Wxbv379kJGRYXrd1GfmTTt/HQDvliIiIpJSvcPN7t27bViGc+gQ7IUjF/JRWGaQuhQiIqImq1H0MaxYsQLh4eFQq9Xo27cvDh48WK/9NmzYAJlMhuHDh9u2wHqqWjjzDk+lxJUQERE1XZKHm6SkJMTFxSE+Ph6pqano1q0boqKicPny5Tr3y8rKwuTJkzFgwAA7VXp7hsp1QznmhoiISDqSh5ulS5di7NixiI2NRadOnbBy5Uq4u7tj9erVte5jMBgwatQozJ07F61atbJjtXWrWjCT89wQERFJR9Jwo9PpkJKSYrYulVwuR2RkJA4cOFDrfm+++SYCAwPx3HPP2aPMequ6FZwdN0RERNKxeOFMa8rLy4PBYEBQUJDZ9qCgIJw8ebLGffbu3YtPPvkEaWlp9fqMsrIylJWVmV5rtdoG13s7vBWciIhIeg3qudmzZw/+8Y9/ICIiAhcvXgQArFu3Dnv37rVqcbcqKCjAM888g1WrViEgIKBe+yQkJMDHx8f00Gg0NqvPyOUXiIiIJGdxuPnPf/6DqKgouLm54dChQ6Zekfz8fCxcuNCiYwUEBEChUCA3N9dse25uLoKDg6u1P3PmDLKysjBs2DC4uLjAxcUFa9euxdatW+Hi4oIzZ85U22fatGnIz883Pc6fP29RjZYwLZzJcENERCQZi8PN/PnzsXLlSqxatQqurq6m7f3790dqaqpFx1IqlejVqxeSk5NN24xGI5KTkxEREVGtfYcOHXD06FGkpaWZHo888ggGDRqEtLS0GntlVCoVvL29zR62cvFaxVIU/FmKiIhIOhaPuUlPT8e9995bbbuPjw+uX79ucQFxcXGIiYlB79690adPHyxbtgxFRUWIjY0FAIwePRphYWFISEiAWq1G586dzfb39fUFgGrbpVD5q5SpB4eIiIjsz+JwExwcjNOnTyM8PNxs+969ext0W3Z0dDSuXLmC2bNnIycnB927d8eOHTtMg4zPnTsHuVzyO9brJcBTibxCHdxcFVKXQkRE1GRZHG7Gjh2LiRMnYvXq1ZDJZLh06RIOHDiAyZMnY9asWQ0qYvz48Rg/fnyN791u2YfExMQGfaYtVPXccEAxERGRdCwON1OnToXRaMTgwYNRXFyMe++9FyqVCpMnT8aECRNsUaPDqFp+gdmGiIhIOhaHG5lMhhkzZuD111/H6dOnUVhYiE6dOsHT09MW9TmUqlvB5RxQTEREJJkGT+KnVCrRqVMna9bi8KrGETPcEBERScficDNo0CDI6rh4f//993+pIEd242cphhsiIiKpWBxuunfvbva6vLwcaWlpOHbsGGJiYqxVl0OqugWc2YaIiEg6Foebd955p8btc+bMQWFh4V8uyJFV3S3FGYqJiIikY7UJZP7xj39g9erV1jqcQxK8W4qIiEhyVgs3Bw4cgFqtttbhHJKRA4qJiIgkZ/HPUo899pjZayEEsrOz8dtvvzV4Ej9nYeSYGyIiIslZHG58fHzMXsvlcrRv3x5vvvkmhgwZYrXCHI0QgreCExERNQIWhRuDwYDY2Fh06dIFfn5+tqrJIemNNxbLZLghIiKSjkVjbhQKBYYMGdKg1b+dnfGmlcC5thQREZF0LB5Q3LlzZ2RkZNiiFod2U7bhmBsiIiIJWRxu5s+fj8mTJ+Obb75BdnY2tFqt2YMAZhsiIiLp1HvMzZtvvonXXnsNDz74IADgkUceMVuGQQgBmUwGg8Fg/SodgHnPDeMNERGRVOodbubOnYuXXnoJP/zwgy3rcVgCN9INow0REZF06h1uqmbfHThwoM2KcWQcc0NERNQ4WDTmhj+31O6mbAMZ+26IiIgkY9E8N+3atbttwLl69epfKshRiZu6bpgBiYiIpGNRuJk7d261GYqpgrh9EyIiIrIDi8LNU089hcDAQFvV4tA45oaIiKhxqPeYG463uY2bww3H3BAREUmm3uHm5jElVJ3ZreDMNkRERJKp989SRqPRlnU4PLOfpaQrg4iIqMmzePkFqtnNC2dyVXAiIiLpMNxYidk8N8w2REREkmG4sRKuLUVERNQ4MNxYieBMN0RERI0Cw421VGYbdtoQERFJi+HGSqr6bZhtiIiIpMVwYyXC1HPDeENERCQlhhsrqRpzw2hDREQkLYYbKxEcc0NERNQoMNxYyY0xN0w3REREUmK4sRLT2lvMNkRERJJiuLESZhsiIqLGgeHGSsoNFQuLlum5wCgREZGUGG6shItlEhERNQ4MN1bmqXKRugQiIqImjeGGiIiInArDjZVw2UwiIqLGgeHGyjjyhoiISFoMN0RERORUGG6IiIjIqTDcEBERkVNhuLES0/ILREREJCmGG2vjiGIiIiJJMdwQERGRU2G4ISIiIqfCcGMlHHFDRETUODDcWBmH3BAREUmL4YaIiIicCsMNERERORWGGyIiInIqDDdWUjWHn0zGUTdERERSYrghIiIip9Iows2KFSsQHh4OtVqNvn374uDBg7W2XbVqFQYMGAA/Pz/4+fkhMjKyzvZERETUtEgebpKSkhAXF4f4+HikpqaiW7duiIqKwuXLl2tsv3v3bjz99NP44YcfcODAAWg0GgwZMgQXL160c+VERETUGMmExCs+9u3bF3fffTeWL18OADAajdBoNJgwYQKmTp162/0NBgP8/PywfPlyjB49+rbttVotfHx8kJ+fD29v779cf5XTlwsQufQn+Lq7Im32EKsdl4iIiCy7fkvac6PT6ZCSkoLIyEjTNrlcjsjISBw4cKBexyguLkZ5eTn8/f1tVSYRERE5EBcpPzwvLw8GgwFBQUFm24OCgnDy5Ml6HWPKlCkIDQ01C0g3KysrQ1lZmem1VqtteMFERETU6Ek+5uavWLRoETZs2IAvv/wSarW6xjYJCQnw8fExPTQajZ2rJCIiInuSNNwEBARAoVAgNzfXbHtubi6Cg4Pr3Pftt9/GokWL8L///Q9du3attd20adOQn59vepw/f94qtd/KNM+NTY5ORERE9SVpuFEqlejVqxeSk5NN24xGI5KTkxEREVHrfm+99RbmzZuHHTt2oHfv3nV+hkqlgre3t9mDiIiInJekY24AIC4uDjExMejduzf69OmDZcuWoaioCLGxsQCA0aNHIywsDAkJCQCAf/3rX5g9ezY+//xzhIeHIycnBwDg6ekJT09Pyb4HERERNQ6Sh5vo6GhcuXIFs2fPRk5ODrp3744dO3aYBhmfO3cOcvmNDqYPPvgAOp0OTzzxhNlx4uPjMWfOHHuWTkRERI2Q5OEGAMaPH4/x48fX+N7u3bvNXmdlZdm+oL+Aa0sRERFJy6HvlmpMJJ0JkYiIiEwYboiIiMipMNwQERGRU2G4ISIiIqfCcGMlnMSPiIiocWC4ISIiIqfCcENEREROheGGiIiInArDjZVxDj8iIiJpMdxYieA0fkRERI0Cww0RERE5FYYbIiIicioMN1bHQTdERERSYrixEsEhN0RERI0Cww0RERE5FYYbIiIicioMN1bGeW6IiIikxXBjJRxzQ0RE1Dgw3BAREZFTYbghIiIip8JwY2UcckNERCQthhsiIiJyKgw3VsKFM4mIiBoHhhsiIiJyKgw3RERE5FQYbqyMk/gRERFJi+HGSjiJHxERUePAcENEREROheGGiIiInArDjZXJOI0fERGRpBhuiIiIyKkw3BAREZFTYbghIiIip8JwY2Wc54aIiEhaDDdERETkVBhurIST+BERETUODDdERETkVBhurIxDboiIiKTFcENEREROheHGSgQ46IaIiKgxYLghIiIip8JwY2UyTnRDREQkKYYbIiIicioMN0RERORUGG6shJP4ERERNQ4MN0RERORUGG6IiIjIqTDcEBERkVNhuLESDrkhIiJqHBhuiIiIyKkw3FgZ5/AjIiKSFsMNERERORWGGyIiInIqDDdWIjiLHxERUaPAcGNlHHNDREQkLYYbIiIicioMN0RERORUGkW4WbFiBcLDw6FWq9G3b18cPHiwzvabNm1Chw4doFar0aVLF2zfvt1OldaOI26IiIgaB8nDTVJSEuLi4hAfH4/U1FR069YNUVFRuHz5co3t9+/fj6effhrPPfccDh06hOHDh2P48OE4duyYnSuvmQwcdENERCQlycPN0qVLMXbsWMTGxqJTp05YuXIl3N3dsXr16hrbv/vuuxg6dChef/11dOzYEfPmzUPPnj2xfPlyO1dOREREjZGk4Uan0yElJQWRkZGmbXK5HJGRkThw4ECN+xw4cMCsPQBERUXV2r6srAxardbsQURERM5L0nCTl5cHg8GAoKAgs+1BQUHIycmpcZ+cnByL2ickJMDHx8f00Gg01in+FjIAKhc5lC6Sd4YRERE1aU5/JZ42bRry8/NNj/Pnz9vkc3q08EP6/AewK26gTY5PRERE9eMi5YcHBARAoVAgNzfXbHtubi6Cg4Nr3Cc4ONii9iqVCiqVyjoFExERUaMnac+NUqlEr169kJycbNpmNBqRnJyMiIiIGveJiIgwaw8A3333Xa3tiYiIqGmRtOcGAOLi4hATE4PevXujT58+WLZsGYqKihAbGwsAGD16NMLCwpCQkAAAmDhxIgYOHIglS5bgoYcewoYNG/Dbb7/ho48+kvJrEBERUSMhebiJjo7GlStXMHv2bOTk5KB79+7YsWOHadDwuXPnIJff6GDq168fPv/8c8ycORPTp09H27Zt8dVXX6Fz585SfQUiIiJqRGSiiS1nrdVq4ePjg/z8fHh7e0tdDhEREdWDJddvp79bioiIiJoWhhsiIiJyKgw3RERE5FQYboiIiMipMNwQERGRU2G4ISIiIqfCcENEREROheGGiIiInArDDRERETkVyZdfsLeqCZm1Wq3ElRAREVF9VV2367OwQpMLNwUFBQAAjUYjcSVERERkqYKCAvj4+NTZpsmtLWU0GnHp0iV4eXlBJpNZ9dharRYajQbnz5/nulU2xPNsHzzP9sHzbD881/Zhq/MshEBBQQFCQ0PNFtSuSZPruZHL5WjevLlNP8Pb25v/4tgBz7N98DzbB8+z/fBc24ctzvPtemyqcEAxERERORWGGyIiInIqDDdWpFKpEB8fD5VKJXUpTo3n2T54nu2D59l+eK7tozGc5yY3oJiIiIicG3tuiIiIyKkw3BAREZFTYbghIiIip8JwQ0RERE6F4cZCK1asQHh4ONRqNfr27YuDBw/W2X7Tpk3o0KED1Go1unTpgu3bt9upUsdmyXletWoVBgwYAD8/P/j5+SEyMvK2/1yogqV/n6ts2LABMpkMw4cPt22BTsLS83z9+nWMGzcOISEhUKlUaNeuHf/bUQ+Wnudly5ahffv2cHNzg0ajwaRJk1BaWmqnah3TTz/9hGHDhiE0NBQymQxfffXVbffZvXs3evbsCZVKhTZt2iAxMdHmdUJQvW3YsEEolUqxevVq8fvvv4uxY8cKX19fkZubW2P7ffv2CYVCId566y1x/PhxMXPmTOHq6iqOHj1q58odi6XneeTIkWLFihXi0KFD4sSJE2LMmDHCx8dHXLhwwc6VOxZLz3OVzMxMERYWJgYMGCAeffRR+xTrwCw9z2VlZaJ3797iwQcfFHv37hWZmZli9+7dIi0tzc6VOxZLz/P69euFSqUS69evF5mZmWLnzp0iJCRETJo0yc6VO5bt27eLGTNmiC1btggA4ssvv6yzfUZGhnB3dxdxcXHi+PHj4r333hMKhULs2LHDpnUy3FigT58+Yty4cabXBoNBhIaGioSEhBrbjxgxQjz00ENm2/r27StefPFFm9bp6Cw9z7fS6/XCy8tLfPrpp7Yq0Sk05Dzr9XrRr18/8fHHH4uYmBiGm3qw9Dx/8MEHolWrVkKn09mrRKdg6XkeN26cuO+++8y2xcXFif79+9u0TmdSn3DzxhtviLvuustsW3R0tIiKirJhZULwZ6l60ul0SElJQWRkpGmbXC5HZGQkDhw4UOM+Bw4cMGsPAFFRUbW2p4ad51sVFxejvLwc/v7+tirT4TX0PL/55psIDAzEc889Z48yHV5DzvPWrVsRERGBcePGISgoCJ07d8bChQthMBjsVbbDach57tevH1JSUkw/XWVkZGD79u148MEH7VJzUyHVdbDJLZzZUHl5eTAYDAgKCjLbHhQUhJMnT9a4T05OTo3tc3JybFano2vIeb7VlClTEBoaWu1fKLqhIed57969+OSTT5CWlmaHCp1DQ85zRkYGvv/+e4waNQrbt2/H6dOn8corr6C8vBzx8fH2KNvhNOQ8jxw5Enl5ebjnnnsghIBer8dLL72E6dOn26PkJqO266BWq0VJSQnc3Nxs8rnsuSGnsmjRImzYsAFffvkl1Gq11OU4jYKCAjzzzDNYtWoVAgICpC7HqRmNRgQGBuKjjz5Cr169EB0djRkzZmDlypVSl+ZUdu/ejYULF+L9999HamoqtmzZgm3btmHevHlSl0ZWwJ6begoICIBCoUBubq7Z9tzcXAQHB9e4T3BwsEXtqWHnucrbb7+NRYsWYdeuXejatasty3R4lp7nM2fOICsrC8OGDTNtMxqNAAAXFxekp6ejdevWti3aATXk73NISAhcXV2hUChM2zp27IicnBzodDoolUqb1uyIGnKeZ82ahWeeeQbPP/88AKBLly4oKirCCy+8gBkzZkAu5//7W0Nt10Fvb2+b9doA7LmpN6VSiV69eiE5Odm0zWg0Ijk5GRERETXuExERYdYeAL777rta21PDzjMAvPXWW5g3bx527NiB3r1726NUh2bpee7QoQOOHj2KtLQ00+ORRx7BoEGDkJaWBo1GY8/yHUZD/j73798fp0+fNoVHADh16hRCQkIYbGrRkPNcXFxcLcBUBUrBJRetRrLroE2HKzuZDRs2CJVKJRITE8Xx48fFCy+8IHx9fUVOTo4QQohnnnlGTJ061dR+3759wsXFRbz99tvixIkTIj4+nreC14Ol53nRokVCqVSKzZs3i+zsbNOjoKBAqq/gECw9z7fi3VL1Y+l5PnfunPDy8hLjx48X6enp4ptvvhGBgYFi/vz5Un0Fh2DpeY6PjxdeXl7iiy++EBkZGeJ///ufaN26tRgxYoRUX8EhFBQUiEOHDolDhw4JAGLp0qXi0KFD4uzZs0IIIaZOnSqeeeYZU/uqW8Fff/11ceLECbFixQreCt4Yvffee6JFixZCqVSKPn36iJ9//tn03sCBA0VMTIxZ+40bN4p27doJpVIp7rrrLrFt2zY7V+yYLDnPd955pwBQ7REfH2//wh2MpX+fb8ZwU3+Wnuf9+/eLvn37CpVKJVq1aiUWLFgg9Hq9nat2PJac5/LycjFnzhzRunVroVarhUajEa+88oq4du2a/Qt3ID/88EON/72tOrcxMTFi4MCB1fbp3r27UCqVolWrVmLNmjU2r1MmBPvfiIiIyHlwzA0RERE5FYYbIiIicioMN0RERORUGG6IiIjIqTDcEBERkVNhuCEiIiKnwnBDREREToXhhojMJCYmwtfXV+oyGkwmk+Grr76qs82YMWMwfPhwu9RDRPbHcEPkhMaMGQOZTFbtcfr0aalLQ2JioqkeuVyO5s2bIzY2FpcvX7bK8bOzs/HAAw8AALKysiCTyZCWlmbW5t1330ViYqJVPq82c+bMMX1PhUIBjUaDF154AVevXrXoOAxiRJbjquBETmro0KFYs2aN2bZmzZpJVI05b29vpKenw2g04vDhw4iNjcWlS5ewc+fOv3zs260eDwA+Pj5/+XPq46677sKuXbtgMBhw4sQJPPvss8jPz0dSUpJdPp+oqWLPDZGTUqlUCA4ONnsoFAosXboUXbp0gYeHBzQaDV555RUUFhbWepzDhw9j0KBB8PLygre3N3r16oXffvvN9P7evXsxYMAAuLm5QaPR4NVXX0VRUVGdtclkMgQHByM0NBQPPPAAXn31VezatQslJSUwGo1488030bx5c6hUKnTv3h07duww7avT6TB+/HiEhIRArVbjzjvvREJCgtmxq36WatmyJQCgR48ekMlk+Nvf/gbAvDfko48+QmhoqNkq3ADw6KOP4tlnnzW9/vrrr9GzZ0+o1Wq0atUKc+fOhV6vr/N7uri4IDg4GGFhYYiMjMSTTz6J7777zvS+wWDAc889h5YtW8LNzQ3t27fHu+++a3p/zpw5+PTTT/H111+beoF2794NADh//jxGjBgBX19f+Pv749FHH0VWVlad9RA1FQw3RE2MXC7Hv//9b/z+++/49NNP8f333+ONN96otf2oUaPQvHlz/Prrr0hJScHUqVPh6uoKADhz5gyGDh2Kxx9/HEeOHEFSUhL27t2L8ePHW1STm5sbjEYj9Ho93n33XSxZsgRvv/02jhw5gqioKDzyyCP4448/AAD//ve/sXXrVmzcuBHp6elYv349wsPDazzuwYMHAQC7du1CdnY2tmzZUq3Nk08+iT///BM//PCDadvVq1exY8cOjBo1CgCwZ88ejB49GhMnTsTx48fx4YcfIjExEQsWLKj3d8zKysLOnTuhVCpN24xGI5o3b45Nmzbh+PHjmD17NqZPn46NGzcCACZPnowRI0Zg6NChyM7ORnZ2Nvr164fy8nJERUXBy8sLe/bswb59++Dp6YmhQ4dCp9PVuyYip2XzpTmJyO5iYmKEQqEQHh4epscTTzxRY9tNmzaJO+64w/R6zZo1wsfHx/Tay8tLJCYm1rjvc889J1544QWzbXv27BFyuVyUlJTUuM+txz916pRo166d6N27txBCiNDQULFgwQKzfe6++27xyiuvCCGEmDBhgrjvvvuE0Wis8fgAxJdffimEECIzM1MAEIcOHTJrc+uK5o8++qh49tlnTa8//PBDERoaKgwGgxBCiMGDB4uFCxeaHWPdunUiJCSkxhqEECI+Pl7I5XLh4eEh1Gq1afXkpUuX1rqPEEKMGzdOPP7447XWWvXZ7du3NzsHZWVlws3NTezcubPO4xM1BRxzQ+SkBg0ahA8++MD02sPDA0BFL0ZCQgJOnjwJrVYLvV6P0tJSFBcXw93dvdpx4uLi8Pzzz2PdunWmn1Zat24NoOInqyNHjmD9+vWm9kIIGI1GZGZmomPHjjXWlp+fD09PTxiNRpSWluKee+7Bxx9/DK1Wi0uXLqF///5m7fv374/Dhw8DqPhJ6f7770f79u0xdOhQPPzwwxgyZMhfOlejRo3C2LFj8f7770OlUmH9+vV46qmnIJfLTd9z3759Zj01BoOhzvMGAO3bt8fWrVtRWlqKzz77DGlpaZgwYYJZmxUrVmD16tU4d+4cSkpKoNPp0L179zrrPXz4ME6fPg0vLy+z7aWlpThz5kwDzgCRc2G4IXJSHh4eaNOmjdm2rKwsPPzww3j55ZexYMEC+Pv7Y+/evXjuueeg0+lqvEjPmTMHI0eOxLZt2/Dtt98iPj4eGzZswN///ncUFhbixRdfxKuvvlptvxYtWtRam5eXF1JTUyGXyxESEgI3NzcAgFarve336tmzJzIzM/Htt99i165dGDFiBCIjI7F58+bb7lubYcOGQQiBbdu24e6778aePXvwzjvvmN4vLCzE3Llz8dhjj1XbV61W13pcpVJp+mewaNEiPPTQQ5g7dy7mzZsHANiwYQMmT56MJUuWICIiAl5eXli8eDF++eWXOustLCxEr169zEJllcYyaJxISgw3RE1ISkoKjEYjlixZYuqVqBrfUZd27dqhXbt2mDRpEp5++mmsWbMGf//739GzZ08cP368Woi6HblcXuM+3t7eCA0Nxb59+zBw4EDT9n379qFPnz5m7aKjoxEdHY0nnngCQ4cOxdWrV+Hv7292vKrxLQaDoc561Go1HnvsMaxfvx6nT59G+/bt0bNnT9P7PXv2RHp6usXf81YzZ87Efffdh5dfftn0Pfv164dXXnnF1ObWnhelUlmt/p49eyIpKQmBgYHw9vb+SzUROSMOKCZqQtq0aYPy8nK89957yMjIwLp167By5cpa25eUlGD8+PHYvXs3zp49i3379uHXX381/dw0ZcoU7N+/H+PHj0daWhr++OMPfP311xYPKL7Z66+/jn/9619ISkpCeno6pk6dirS0NEycOBEAsHTpUnzxxRc4efIkTp06hU2bNiE4OLjGiQcDAwPh5uaGHTt2IDc3F/n5+bV+7qhRo7Bt2zasXr3aNJC4yuzZs7F27VrMnTsXv//+O06cOIENGzZg5syZFn23iIgIdO3aFQsXLgQAtG3bFr/99ht27tyJU6dOYdasWfj111/N9gkPD8eRI0eQnp6OvLw8lJeXY9SoUQgICMCjjz6KPXv2IDMzE7t378arr76KCxcuWFQTkVOSetAPEVlfTYNQqyxdulSEhIQINzc3ERUVJdauXSsAiGvXrgkhzAf8lpWViaeeekpoNBqhVCpFaGioGD9+vNlg4YMHD4r7779feHp6Cg8PD9G1a9dqA4JvduuA4lsZDAYxZ84cERYWJlxdXUW3bt3Et99+a3r/o48+Et27dxceHh7C29tbDB48WKSmpprex00DioUQYtWqVUKj0Qi5XC4GDhxY6/kxGAwiJCREABBnzpypVteOHTtEv379hJubm/D29hZ9+vQRH330Ua3fIz4+XnTr1q3a9i+++EKoVCpx7tw5UVpaKsaMGSN8fHyEr6+vePnll8XUqVPN9rt8+bLp/AIQP/zwgxBCiOzsbDF69GgREBAgVCqVaNWqlRg7dqzIz8+vtSaipkImhBDSxisiIiIi6+HPUkRERORUGG6IiIjIqTDcEBERkVNhuCEiIiKnwnBDREREToXhhoiIiJwKww0RERE5FYYbIiIicioMN0RERORUGG6IiIjIqTDcEBERkVNhuCEiIiKn8v9XltYrvvn+iQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(1-tpr_100, 1-fpr_100)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81d22988-934c-4262-b84b-30ed9dcd8ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model: 92.85%\n"
     ]
    }
   ],
   "source": [
    "def pred_accuracy(y_test, predictions):\n",
    "\n",
    "    predictions_list = []\n",
    "    for pred in predictions:\n",
    "        #arbitrary cutoff of 0.5\n",
    "        if float(pred) > 0.5:\n",
    "            predictions_list.append(int(1))\n",
    "        elif float(pred) < 0.5:\n",
    "            predictions_list.append(int(0))\n",
    "            \n",
    "    accuracy = np.mean(predictions_list == y_test)\n",
    "    return accuracy\n",
    "\n",
    "accuracy_model = pred_accuracy(Y_val_100, list(preds_100))\n",
    "print(\"Accuracy of Model: {:.2%}\".format(accuracy_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c06f2567-c949-47bd-a97f-a99468632c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (False):\n",
    "    x_vals_all = []\n",
    "    y_vals_all = []\n",
    "    for m1 in mass_range[1:]:\n",
    "        for m2 in mass_range[1:]:\n",
    "            print(m1,m2)\n",
    "            x_aug_0 = np.append(np.append(x[0,0],m1*np.reshape(np.ones(len(x[0,0])),[len(x[0,0]),1]),1),m2*np.reshape(np.ones(len(x[0,0])),[len(x[0,0]),1]),1)\n",
    "            x_aug_m = np.append(np.append(x[m1,m2],m1*np.reshape(np.ones(len(x[m1,m2])),[len(x[m1,m2]),1]),1),m2*np.reshape(np.ones(len(x[m1,m2])),[len(x[m1,m2]),1]),1)\n",
    "            if (m1==0.5 and m2==0.5):\n",
    "                x_vals_all = np.concatenate([x_aug_0,x_aug_m])\n",
    "                y_vals_all = np.concatenate([np.ones(len(x_aug_0)),np.zeros(len(x_aug_m))])\n",
    "            else:\n",
    "                x_vals_all = np.concatenate([x_vals_all,x_aug_0,x_aug_m])\n",
    "                y_vals_all = np.concatenate([y_vals_all,np.ones(len(x_aug_0)),np.zeros(len(x_aug_m))])\n",
    "\n",
    "    np.save(\"x_vals_all\",x_vals_all)\n",
    "    np.save(\"y_vals_all\",y_vals_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a28cf353-6531-436c-9179-1a934125e35b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.72413866,  1.69355063,  1.11205286, -1.87386705,  6.        ,\n",
       "         6.        ],\n",
       "       [ 0.80799657,  0.66064736, -0.59943671, -2.09319001,  6.        ,\n",
       "         6.        ],\n",
       "       [ 2.17499885, -1.1884174 , -1.60538663, -1.95211824,  6.        ,\n",
       "         6.        ],\n",
       "       ...,\n",
       "       [ 2.25225265, -1.04538567, -1.74062478, -0.42062581,  6.        ,\n",
       "         6.        ],\n",
       "       [ 1.9191695 , -0.87384445, -1.59395235, -2.25172332,  6.        ,\n",
       "         6.        ],\n",
       "       [ 0.04826932,  1.34560735, -0.34342313, -1.79483175,  6.        ,\n",
       "         6.        ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_aug_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff957fc-43eb-4f59-8b86-21b916e9a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewrite cell above to understand\n",
    "x_valls_all = []\n",
    "y_valls_all = []\n",
    "\n",
    "for m1 in mass_range[1:]:\n",
    "    for m2 in mass_range[1:]:\n",
    "        x_aug_0 = np.append(np.append())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f41f4fd9-d932-4bc2-8ead-63d744ccbe76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " ...\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n"
     ]
    }
   ],
   "source": [
    "test = np.append([[1, 2],[3, 4]], [[5, 6]], 0)\n",
    "m1 = 0.5\n",
    "m2 = 0.5\n",
    "m1 = m1 * np.append(x[0,0],m1*np.reshape(np.ones(len(x[0,0])),[len(x[0,0]),1]),1)\n",
    "m2 = m2 * np.reshape(np.ones(len(x[0,0])),[len(x[0,0]),1])\n",
    "print(np.reshape(np.ones(len(x[0,0])),[len(x[0,0]), 1]))\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "281ce20a-e2a0-485f-a59b-3e0e5a9403ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_vals_all = np.load(\"x_vals_all.npy\")\n",
    "y_vals_all = np.load(\"y_vals_all.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cad55635-851c-46cc-bbfd-1182f16da2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_all, X_val_all, Y_train_all, Y_val_all = train_test_split(x_vals_all, y_vals_all, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b5d5d3f-0523-4911-a7d3-d5abaaaa0f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13594326"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "601d4b1a-2897-465d-9c38-724e3873aaca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gup-singh/Anomaly/runs/1u49n9di\" target=\"_blank\">young-eon-30</a></strong> to <a href=\"https://wandb.ai/gup-singh/Anomaly\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not wandb.run:\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"Anomaly\",\n",
    "        group=\"Parametrized\",\n",
    "        entity='gup-singh',\n",
    "\n",
    "        config={\n",
    "            \"layer_1\": 256,\n",
    "            \"activation_1\": \"relu\",\n",
    "            \"layer_2\": 256,\n",
    "            \"activation_2\": \"relu\",\n",
    "            \"layer_3\": 256,\n",
    "            \"activation_3\": \"relu\",\n",
    "            \"output_layer\": 1,\n",
    "            \"output_activation\": \"sigmoid\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"metric\": \"accuracy\",\n",
    "            \"epoch\": 20,\n",
    "            \"batch_size\": 1024\n",
    "        }\n",
    "    )\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f68541d3-0734-4e4a-ab49-3ad591f31744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             multiple                  1792      \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  65792     \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  65792     \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,633\n",
      "Trainable params: 133,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model_all = Sequential()\n",
    "# model_all.add(Dense(128, input_dim=6, activation='relu'))\n",
    "# model_all.add(Dense(128, activation='relu'))\n",
    "# model_all.add(Dense(128, activation='relu'))\n",
    "# model_all.add(Dense(1, activation='sigmoid'))\n",
    "# model_all.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_all = MyModel()\n",
    "model_all.build(input_shape=(None, X_train_all.shape[1]))\n",
    "model_all.compile(loss=config.loss, optimizer=config.optimizer, metrics=[\"accuracy\"])\n",
    "model_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d310961a-6cea-4058-9e5b-3cc3e472a4cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5309/5311 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9327"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 12s 2ms/step - loss: 0.1713 - accuracy: 0.9327 - val_loss: 0.1645 - val_accuracy: 0.9354\n",
      "Epoch 2/20\n",
      "5280/5311 [============================>.] - ETA: 0s - loss: 0.1624 - accuracy: 0.9363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1624 - accuracy: 0.9363 - val_loss: 0.1618 - val_accuracy: 0.9366\n",
      "Epoch 3/20\n",
      "5292/5311 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1617 - accuracy: 0.9366 - val_loss: 0.1616 - val_accuracy: 0.9365\n",
      "Epoch 4/20\n",
      "5293/5311 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 0.9367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 11s 2ms/step - loss: 0.1613 - accuracy: 0.9367 - val_loss: 0.1610 - val_accuracy: 0.9367\n",
      "Epoch 5/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1611 - accuracy: 0.9368 - val_loss: 0.1624 - val_accuracy: 0.9363\n",
      "Epoch 6/20\n",
      "5284/5311 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1609 - accuracy: 0.9368 - val_loss: 0.1610 - val_accuracy: 0.9368\n",
      "Epoch 7/20\n",
      "5288/5311 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1607 - accuracy: 0.9369 - val_loss: 0.1606 - val_accuracy: 0.9369\n",
      "Epoch 8/20\n",
      "5308/5311 [============================>.] - ETA: 0s - loss: 0.1606 - accuracy: 0.9370"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1606 - accuracy: 0.9370 - val_loss: 0.1606 - val_accuracy: 0.9369\n",
      "Epoch 9/20\n",
      "5307/5311 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9370"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1605 - accuracy: 0.9370 - val_loss: 0.1603 - val_accuracy: 0.9371\n",
      "Epoch 10/20\n",
      "5288/5311 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 0.9370"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1603 - accuracy: 0.9370 - val_loss: 0.1602 - val_accuracy: 0.9370\n",
      "Epoch 11/20\n",
      "5283/5311 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 0.9371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1603 - accuracy: 0.9371 - val_loss: 0.1598 - val_accuracy: 0.9372\n",
      "Epoch 12/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1602 - accuracy: 0.9371 - val_loss: 0.1600 - val_accuracy: 0.9372\n",
      "Epoch 13/20\n",
      "5294/5311 [============================>.] - ETA: 0s - loss: 0.1601 - accuracy: 0.9371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1601 - accuracy: 0.9371 - val_loss: 0.1595 - val_accuracy: 0.9374\n",
      "Epoch 14/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1600 - accuracy: 0.9372 - val_loss: 0.1596 - val_accuracy: 0.9374\n",
      "Epoch 15/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1600 - accuracy: 0.9372 - val_loss: 0.1597 - val_accuracy: 0.9373\n",
      "Epoch 16/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1599 - accuracy: 0.9372 - val_loss: 0.1599 - val_accuracy: 0.9372\n",
      "Epoch 17/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1598 - accuracy: 0.9373 - val_loss: 0.1600 - val_accuracy: 0.9372\n",
      "Epoch 18/20\n",
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1598 - accuracy: 0.9373 - val_loss: 0.1595 - val_accuracy: 0.9374\n",
      "Epoch 19/20\n",
      "5279/5311 [============================>.] - ETA: 0s - loss: 0.1597 - accuracy: 0.9373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1597 - accuracy: 0.9373 - val_loss: 0.1593 - val_accuracy: 0.9375\n",
      "Epoch 20/20\n",
      "5302/5311 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.9373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/global/u2/g/gupsingh/SULI/wandb/run-20230914_142542-1u49n9di/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311/5311 [==============================] - 10s 2ms/step - loss: 0.1596 - accuracy: 0.9373 - val_loss: 0.1592 - val_accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "myhistory_all = model_all.fit(x_vals_all, y_vals_all, epochs=config.epoch,validation_data=(X_val_all, Y_val_all),batch_size=config.batch_size*5, callbacks = [WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1c0821b-afa5-4e8c-8836-9af5710f2e24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇▇▇▇████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅▆▄▆▆▆▇▇▇▇██▇▇▇███</td></tr><tr><td>val_loss</td><td>█▄▄▃▅▃▃▃▂▂▂▂▁▁▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.93731</td></tr><tr><td>best_epoch</td><td>19</td></tr><tr><td>best_val_loss</td><td>0.15924</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.15961</td></tr><tr><td>val_accuracy</td><td>0.93745</td></tr><tr><td>val_loss</td><td>0.15924</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">young-eon-30</strong>: <a href=\"https://wandb.ai/gup-singh/Anomaly/runs/1u49n9di\" target=\"_blank\">https://wandb.ai/gup-singh/Anomaly/runs/1u49n9di</a><br/>Synced 5 W&B file(s), 1 media file(s), 40 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230914_142542-1u49n9di/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3d75fda-1aa3-4175-bf5e-8ea4af80a0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(myhistory_all.history['loss'])\n",
    "plt.plot(myhistory_all.history['val_loss'])\n",
    "plt.title('Model Loss All')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['loss', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18f227d8-c1bf-40ad-9bc2-93dadc7e9421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 683us/step\n"
     ]
    }
   ],
   "source": [
    "preds_all = model_all.predict(X_val_all[np.product(X_val_all[:,4:6]==[1.,1.],axis=1)==1],batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "669e8b25-00b9-4ed0-9cf1-edc4d2fa55a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr_all, tpr_all, _ = roc_curve(Y_val_all[np.product(X_val_all[:,4:6]==[1.,1.],axis=1)==1], preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1cb0aa1-9961-4d08-b350-e90d446c85b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1247661/2571013946.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  plt.plot(tpr_100,1./fpr_100,label=\"dedicated_100\")\n",
      "/tmp/ipykernel_1247661/2571013946.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  plt.plot(tpr_all,1./fpr_all,label=\"parameterized\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '$(m_B,m_C) = (100,100)$ GeV Dedicated vs Parametrized')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tpr_100,1./fpr_100,label=\"dedicated_100\")\n",
    "plt.plot(tpr_all,1./fpr_all,label=\"parameterized\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel(\"TPR\")\n",
    "plt.ylabel(\"1/FPR\")\n",
    "plt.title(\"$(m_B,m_C) = (100,100)$ GeV Dedicated vs Parametrized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01828ec5-ae2a-4328-97cc-d001a15b89c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#written by Nachman\n",
    "\n",
    "# for l in model_all.layers:\n",
    "#     l.trainable=False\n",
    "\n",
    "# inputs_hold = tf.keras.Input(shape=(1,))\n",
    "# simple_model = Dense(1,use_bias = False,activation='relu',kernel_initializer=tf.keras.initializers.Constant(2.))(inputs_hold)\n",
    "# model3 = Model(inputs = inputs_hold, outputs = simple_model)\n",
    "\n",
    "# inputs_hold2 = tf.keras.Input(shape=(1,))\n",
    "# simple_model2 = Dense(1,use_bias = False,activation='relu',kernel_initializer=tf.keras.initializers.Constant(3.))(inputs_hold2)\n",
    "# model32 = Model(inputs = inputs_hold2, outputs = simple_model2)\n",
    "\n",
    "# inputs = tf.keras.Input(shape=(4,))\n",
    "# inputs2 = tf.keras.layers.concatenate([inputs,model3(tf.ones_like(inputs)[:,0]),model32(tf.ones_like(inputs)[:,0])])\n",
    "# hidden_layer_1 = model_all(inputs2)\n",
    "# model_all2 = Model(inputs = inputs, outputs = hidden_layer_1)\n",
    "# model_all2.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "733d1d90-3f0c-4fcd-8e65-7f4e760fc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewrite cell above to understand/improve\n",
    "\n",
    "#freezes the layers of the model (i.e all trainable params)\n",
    "for l in model_all.layers:\n",
    "    l.trainable=False\n",
    "    \n",
    "#creates models with single node and arbitrary weight\n",
    "def createSimpleModel(weight):\n",
    "    input_layer = tf.keras.Input(shape=(1,))\n",
    "    simple_model = Dense(1,use_bias = False,activation='relu',kernel_initializer=tf.keras.initializers.Constant(weight))(input_layer)\n",
    "    model = Model(inputs=input_layer, outputs=simple_model)\n",
    "    return model\n",
    "    \n",
    "model3 = createSimpleModel(2.)\n",
    "model32 = createSimpleModel(3.)\n",
    "\n",
    "#create fnial model with everything combined\n",
    "inputs = tf.keras.Input(shape=(4,))\n",
    "concatenated_inputs = tf.keras.layers.concatenate([inputs, model3(tf.ones_like(inputs)[:,0]), model32(tf.ones_like(inputs)[:,0])])\n",
    "hidden_layer_1 = model_all(concatenated_inputs)\n",
    "model_all2 = Model(inputs = inputs, outputs = hidden_layer_1)\n",
    "model_all2.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65941a07-5f54-4f0d-acaa-380ce8152087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_8/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[2.]], dtype=float32)>,\n",
       " <tf.Variable 'dense_9/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[3.]], dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all2.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38501135-ebb5-4755-a986-1de1d5ddbddf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.ones_like (TFOpLambda)      (None, 4)            0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.ones_like_1 (TFOpLambda)    (None, 4)            0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None,)             0           ['tf.ones_like[0][0]']           \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None,)             0           ['tf.ones_like_1[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 1)            1           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 1)            1           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6)            0           ['input_3[0][0]',                \n",
      "                                                                  'model[0][0]',                  \n",
      "                                                                  'model_1[0][0]']                \n",
      "                                                                                                  \n",
      " my_model_1 (MyModel)           (None, 1)            133633      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 133,635\n",
      "Trainable params: 2\n",
      "Non-trainable params: 133,633\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bab5531b-cc63-4d98-8f54-a8fe2afa9493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 3.0209 - val_loss: 2.8133\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.7220 - val_loss: 2.6703\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.6401 - val_loss: 2.6347\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.6261 - val_loss: 2.6287\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.6226 - val_loss: 2.6262\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.6212 - val_loss: 2.6250\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.6205 - val_loss: 2.6243\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.6201 - val_loss: 2.6242\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.6198 - val_loss: 2.6234\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 2.6196 - val_loss: 2.6232\n"
     ]
    }
   ],
   "source": [
    "myhistory_all2 = model_all2.fit(x_vals_100[:,0:4], y_vals_100, epochs=10,validation_data=(X_val_100[:,0:4], Y_val_100),batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9461ad60-fe52-4dfd-bf18-586a8e5a8c36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 1.7536 - val_loss: 0.7409\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.6997 - val_loss: 0.6607\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.6386 - val_loss: 0.6185\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.6078 - val_loss: 0.5935\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5870 - val_loss: 0.5765\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5731 - val_loss: 0.5662\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5652 - val_loss: 0.5606\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5611 - val_loss: 0.5578\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5591 - val_loss: 0.5564\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5583 - val_loss: 0.5559\n",
      "0.5 0.5 0.5009282 9.0266\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 1.3725 - val_loss: 0.8066\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7674 - val_loss: 0.7429\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7281 - val_loss: 0.7215\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7171 - val_loss: 0.7172\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7145 - val_loss: 0.7161\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7137 - val_loss: 0.7157\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7135 - val_loss: 0.7157\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7135 - val_loss: 0.7157\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7134 - val_loss: 0.7159\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7134 - val_loss: 0.7157\n",
      "0.5 1 1.0162501 6.8402267\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.9914 - val_loss: 0.7477\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7029 - val_loss: 0.6698\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6555 - val_loss: 0.6458\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6436 - val_loss: 0.6411\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6408 - val_loss: 0.6395\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6398 - val_loss: 0.6389\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6395 - val_loss: 0.6388\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6394 - val_loss: 0.6388\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6394 - val_loss: 0.6387\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6393 - val_loss: 0.6388\n",
      "0.5 1.5 1.5197958 7.1196375\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.8756 - val_loss: 0.7287\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6747 - val_loss: 0.6402\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6212 - val_loss: 0.6111\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6051\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6036 - val_loss: 0.6031\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6027 - val_loss: 0.6028\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6024\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6023\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6023 - val_loss: 0.6024\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6023\n",
      "0.5 2 2.018391 7.3301506\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 1.0276 - val_loss: 0.9527\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7699 - val_loss: 0.6632\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6285 - val_loss: 0.6111\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 0.5987\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5923 - val_loss: 0.5939\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5899 - val_loss: 0.5927\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5892 - val_loss: 0.5923\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5890 - val_loss: 0.5921\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5889 - val_loss: 0.5921\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5889 - val_loss: 0.5921\n",
      "0.5 2.5 2.503654 7.5707154\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.9524 - val_loss: 0.7966\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.6730 - val_loss: 0.6113\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.6048 - val_loss: 0.5951\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5953 - val_loss: 0.5886\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5911 - val_loss: 0.5867\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5900 - val_loss: 0.5860\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5897 - val_loss: 0.5857\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5895 - val_loss: 0.5858\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5895 - val_loss: 0.5858\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5896 - val_loss: 0.5856\n",
      "0.5 3 2.9879217 7.7615304\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.9747 - val_loss: 0.7505\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.7504\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.7504\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.7504\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.7504\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.7504\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.7504\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.7504\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.7505\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.7504\n",
      "0.5 3.5 3.4590018 3.6896212\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 1.1050 - val_loss: 0.6749\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6753 - val_loss: 0.6739\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 0.6739\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 0.6741\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 0.6739\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 0.6739\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 0.6739\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 0.6739\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 0.6740\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 0.6739\n",
      "0.5 4 3.9164639 4.187815\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.3015 - val_loss: 0.6342\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.6203\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6203\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6203\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6203\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6203\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6203\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6203\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.6203\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.6194 - val_loss: 0.6203\n",
      "0.5 4.5 4.3715677 4.66682\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.0478 - val_loss: 0.2677\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2362 - val_loss: 0.2261\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2271 - val_loss: 0.2260\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2271 - val_loss: 0.2260\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2271 - val_loss: 0.2260\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2271 - val_loss: 0.2260\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2271 - val_loss: 0.2260\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2271 - val_loss: 0.2260\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2271 - val_loss: 0.2260\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2271 - val_loss: 0.2260\n",
      "0.5 5 0.50835377 5.0197644\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 2ms/step - loss: 1.1308 - val_loss: 0.3472\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.2669 - val_loss: 0.2321\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.2302 - val_loss: 0.2300\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.2298 - val_loss: 0.2300\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.2298 - val_loss: 0.2300\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.2298 - val_loss: 0.2300\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.2298 - val_loss: 0.2301\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.2298 - val_loss: 0.2300\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.2298 - val_loss: 0.2299\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.2298 - val_loss: 0.2299\n",
      "0.5 5.5 0.5079197 5.528953\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 1.1607 - val_loss: 0.4153\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.3167 - val_loss: 0.2439\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2346 - val_loss: 0.2303\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2317 - val_loss: 0.2302\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2317 - val_loss: 0.2302\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2317 - val_loss: 0.2303\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2317 - val_loss: 0.2302\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2317 - val_loss: 0.2302\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2317 - val_loss: 0.2302\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2317 - val_loss: 0.2303\n",
      "0.5 6 0.49373427 6.0384283\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 1.3652 - val_loss: 0.8109\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7717 - val_loss: 0.7463\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7319 - val_loss: 0.7250\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7208 - val_loss: 0.7207\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7183 - val_loss: 0.7194\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7176 - val_loss: 0.7190\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7173 - val_loss: 0.7189\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7173 - val_loss: 0.7190\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7173 - val_loss: 0.7189\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.7173 - val_loss: 0.7189\n",
      "1 0.5 1.0178778 6.8189354\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.9595 - val_loss: 0.4523\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.3985\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 0.3857\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.3808\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.3780\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3778 - val_loss: 0.3767\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.3758\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.3754\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.3752\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.3751\n",
      "1 1 1.0128239 7.455266\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.7688 - val_loss: 0.5750\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5439 - val_loss: 0.5244\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.5207\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5206\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5205\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5053 - val_loss: 0.4722\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.4632\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.4612\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.4601\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.4593\n",
      "1 1.5 1.0717642 8.157131\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.7042 - val_loss: 0.5957\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5623 - val_loss: 0.5497\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5442 - val_loss: 0.5450\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5413 - val_loss: 0.5431\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 0.5434\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 0.5428\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 0.5428\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 0.5428\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5405 - val_loss: 0.5428\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 0.5430\n",
      "1 2 2.0082774 6.7936416\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.7576 - val_loss: 0.7347\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7367 - val_loss: 0.7348\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7367 - val_loss: 0.7347\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7368 - val_loss: 0.7347\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7369 - val_loss: 0.7347\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7368 - val_loss: 0.7348\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7368 - val_loss: 0.7349\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7368 - val_loss: 0.7348\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7368 - val_loss: 0.7347\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.7368 - val_loss: 0.7347\n",
      "1 2.5 2.470603 2.5909207\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.3211 - val_loss: 0.1818\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1818\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1822\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1820\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1819\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1819\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1819\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1818\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1819\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1829 - val_loss: 0.1821\n",
      "1 3 1.0209821 3.055618\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.1855\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.1855\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.1855\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.1855\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.1855\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.1856\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.1855\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.1855\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.1855\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.1855\n",
      "1 3.5 1.0111709 3.5167542\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.4483 - val_loss: 0.1869\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1859 - val_loss: 0.1853\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.1853\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.1853\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.1854\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.1853\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.1854\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.1853\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.1853\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.1854\n",
      "1 4 1.0107794 4.01593\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.5589 - val_loss: 0.1992\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 3ms/step - loss: 0.1900 - val_loss: 0.1877\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1878 - val_loss: 0.1877\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1878 - val_loss: 0.1877\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1878 - val_loss: 0.1877\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1878 - val_loss: 0.1877\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1878 - val_loss: 0.1877\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1879 - val_loss: 0.1877\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1878 - val_loss: 0.1877\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1879 - val_loss: 0.1877\n",
      "1 4.5 1.0136992 4.5276814\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.6545 - val_loss: 0.2447\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2054 - val_loss: 0.1921\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.1920\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.1920\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.1920\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.1920\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.1920\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.1920\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.1921\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.1920\n",
      "1 5 1.0202298 5.0008583\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 2ms/step - loss: 0.7369 - val_loss: 0.3175\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2360 - val_loss: 0.1965\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1953 - val_loss: 0.1942\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1950 - val_loss: 0.1942\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1950 - val_loss: 0.1942\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1950 - val_loss: 0.1943\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1950 - val_loss: 0.1942\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1950 - val_loss: 0.1942\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1950 - val_loss: 0.1943\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1950 - val_loss: 0.1942\n",
      "1 5.5 1.0225587 5.514277\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.7819 - val_loss: 0.3748\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.2840 - val_loss: 0.2087\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.1944\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1968 - val_loss: 0.1943\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1968 - val_loss: 0.1943\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1968 - val_loss: 0.1944\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1968 - val_loss: 0.1943\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1968 - val_loss: 0.1944\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1968 - val_loss: 0.1944\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1968 - val_loss: 0.1945\n",
      "1 6 1.0164415 6.0236974\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.9653 - val_loss: 0.7360\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6890 - val_loss: 0.6593\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6414 - val_loss: 0.6324\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6283 - val_loss: 0.6267\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6251 - val_loss: 0.6248\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.6240\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6235 - val_loss: 0.6238\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6233 - val_loss: 0.6236\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6232 - val_loss: 0.6236\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6232 - val_loss: 0.6238\n",
      "1.5 0.5 1.5368409 7.1856747\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 0.7665 - val_loss: 0.5827\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5473 - val_loss: 0.5329\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 0.5285\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.5059 - val_loss: 0.4726\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.4612\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.4581\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.4564\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4544 - val_loss: 0.4548\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.4544\n",
      "1.5 1 1.0633861 8.313919\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.2983 - val_loss: 0.1295\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1270 - val_loss: 0.1293\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1269 - val_loss: 0.1293\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.1293\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1269 - val_loss: 0.1292\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.1292\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.1292\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.1292\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1269 - val_loss: 0.1292\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1269 - val_loss: 0.1292\n",
      "1.5 1.5 1.5016439 1.5075474\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.2111 - val_loss: 0.1429\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1427 - val_loss: 0.1429\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1427 - val_loss: 0.1429\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1428 - val_loss: 0.1429\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1427 - val_loss: 0.1429\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1427 - val_loss: 0.1430\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1428 - val_loss: 0.1429\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1428 - val_loss: 0.1430\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1428 - val_loss: 0.1429\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1428 - val_loss: 0.1433\n",
      "1.5 2 1.5224084 2.0316772\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.1817 - val_loss: 0.1506\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1507\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1506\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1508\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1506\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1507\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1507\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1506\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1506\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1508\n",
      "1.5 2.5 1.5031013 2.5041335\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 2ms/step - loss: 0.1700 - val_loss: 0.1549\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1540 - val_loss: 0.1547\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1547\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1548\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1540 - val_loss: 0.1547\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1549\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1548\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1548\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1547\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1540 - val_loss: 0.1547\n",
      "1.5 3 1.516498 3.027252\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 0.1852 - val_loss: 0.1561\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1561\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1561\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1561\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1562\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1561\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1561\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1561\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1561\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1561\n",
      "1.5 3.5 1.5268219 3.522271\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.2274 - val_loss: 0.1596\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1597 - val_loss: 0.1595\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1597 - val_loss: 0.1595\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1597 - val_loss: 0.1595\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.1595\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.1595\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.1595\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.1596\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.1596\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.1596\n",
      "1.5 4 1.5241574 4.000663\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.2899 - val_loss: 0.1651\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1634 - val_loss: 0.1614\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1630 - val_loss: 0.1614\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1614\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1630 - val_loss: 0.1615\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1614\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1614\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1614\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1613\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1614\n",
      "1.5 4.5 1.526813 4.525285\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.3569 - val_loss: 0.1939\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1712 - val_loss: 0.1638\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1664 - val_loss: 0.1638\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1664 - val_loss: 0.1638\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1664 - val_loss: 0.1638\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1664 - val_loss: 0.1638\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1664 - val_loss: 0.1638\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1664 - val_loss: 0.1638\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1664 - val_loss: 0.1638\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1665 - val_loss: 0.1639\n",
      "1.5 5 1.5413613 5.0158663\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.2602\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.1722\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1718\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1718\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1718\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1718\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1718\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1718\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1718\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1718\n",
      "1.5 5.5 1.5216454 5.510759\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 2ms/step - loss: 0.4640 - val_loss: 0.3139\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.2294 - val_loss: 0.1788\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1754 - val_loss: 0.1743\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1746 - val_loss: 0.1743\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1746 - val_loss: 0.1743\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1746 - val_loss: 0.1743\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1746 - val_loss: 0.1744\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1746 - val_loss: 0.1743\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1746 - val_loss: 0.1744\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1746 - val_loss: 0.1743\n",
      "1.5 6 1.5338582 6.023068\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 1s 2ms/step - loss: 0.8348 - val_loss: 0.7016\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.6459 - val_loss: 0.6101\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5917 - val_loss: 0.5784\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5750 - val_loss: 0.5712\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5704 - val_loss: 0.5691\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5689 - val_loss: 0.5680\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5685 - val_loss: 0.5677\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5682 - val_loss: 0.5680\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5682 - val_loss: 0.5675\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5682 - val_loss: 0.5675\n",
      "2 0.5 2.0280135 7.4120927\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.7029 - val_loss: 0.5923\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5602 - val_loss: 0.5456\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5408 - val_loss: 0.5410\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5377 - val_loss: 0.5389\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5368 - val_loss: 0.5386\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5367 - val_loss: 0.5387\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.5385\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5367 - val_loss: 0.5385\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5367 - val_loss: 0.5385\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.5368 - val_loss: 0.5385\n",
      "2 1 2.0092247 6.7918754\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.2098 - val_loss: 0.1419\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1419\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1419\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1420\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1418\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1419\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1421\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1419 - val_loss: 0.1418\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1419 - val_loss: 0.1419\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1419\n",
      "2 1.5 1.5206622 2.0043309\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 4ms/step - loss: 0.1417 - val_loss: 0.1132\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1133\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1134\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1132\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1133\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1132\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1133\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1132\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1145 - val_loss: 0.1135\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1145 - val_loss: 0.1132\n",
      "2 2 2.001674 2.013721\n",
      "Epoch 1/10\n",
      "193/193 [==============================] - 1s 3ms/step - loss: 0.1352 - val_loss: 0.1289\n",
      "Epoch 2/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1295 - val_loss: 0.1292\n",
      "Epoch 3/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1296 - val_loss: 0.1289\n",
      "Epoch 4/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1296 - val_loss: 0.1288\n",
      "Epoch 5/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1296 - val_loss: 0.1292\n",
      "Epoch 6/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1296 - val_loss: 0.1289\n",
      "Epoch 7/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1295 - val_loss: 0.1289\n",
      "Epoch 8/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1296 - val_loss: 0.1288\n",
      "Epoch 9/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1296 - val_loss: 0.1288\n",
      "Epoch 10/10\n",
      "193/193 [==============================] - 0s 2ms/step - loss: 0.1296 - val_loss: 0.1290\n",
      "2 2.5 2.0359812 2.5174804\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.1379 - val_loss: 0.1373\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1373\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1377\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1373\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1373\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1378\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1373\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1380 - val_loss: 0.1373\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1373\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1373\n",
      "2 3 2.0167105 3.012938\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.1486 - val_loss: 0.1426\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 0.1427\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 0.1428\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 0.1427\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 0.1427\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 0.1427\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 0.1430\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 0.1428\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 0.1426\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1427\n",
      "2 3.5 2.0305307 3.5040364\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.1764 - val_loss: 0.1504\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1505\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1504\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1505\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1508\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1504\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1504\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1504\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1504\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1504\n",
      "2 4 2.0107965 4.0225134\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.2184 - val_loss: 0.1562\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1544 - val_loss: 0.1558\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1544 - val_loss: 0.1560\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.1559\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.1559\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.1559\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1544 - val_loss: 0.1559\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.1558\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1544 - val_loss: 0.1558\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.1559\n",
      "2 4.5 2.016853 4.511236\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.2693 - val_loss: 0.1655\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1576 - val_loss: 0.1573\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1573\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1573\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1573\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1573\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1573\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1573\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1573\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1574\n",
      "2 5 2.0184052 5.0035634\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.3299 - val_loss: 0.2141\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1733 - val_loss: 0.1636\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1632 - val_loss: 0.1635\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1632 - val_loss: 0.1635\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1632 - val_loss: 0.1635\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1632 - val_loss: 0.1636\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1632 - val_loss: 0.1635\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1632 - val_loss: 0.1636\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1633 - val_loss: 0.1636\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1632 - val_loss: 0.1636\n",
      "2 5.5 2.025956 5.5313635\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.2705\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1985 - val_loss: 0.1663\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1641 - val_loss: 0.1647\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1648\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1640 - val_loss: 0.1648\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1647\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1648\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1649\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1647\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1648\n",
      "2 6 2.0489054 6.017295\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 2ms/step - loss: 0.9255 - val_loss: 0.8680\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.7183 - val_loss: 0.6083\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5769 - val_loss: 0.5562\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.5418\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5367 - val_loss: 0.5360\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.5340\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 0.5333\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 0.5329\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5315 - val_loss: 0.5327\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 0.5326\n",
      "2.5 0.5 2.5165713 7.703162\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.7430 - val_loss: 0.7229\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7219 - val_loss: 0.7229\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7219 - val_loss: 0.7229\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7220 - val_loss: 0.7229\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7220 - val_loss: 0.7231\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7220 - val_loss: 0.7234\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7220 - val_loss: 0.7229\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7219 - val_loss: 0.7229\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7220 - val_loss: 0.7230\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.7220 - val_loss: 0.7229\n",
      "2.5 1 2.4736054 2.580866\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.1817 - val_loss: 0.1506\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1506\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1506\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1506\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1507\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1506\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1507\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1509 - val_loss: 0.1506\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1508\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1506\n",
      "2.5 1.5 1.5140699 2.5319836\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.1353 - val_loss: 0.1288\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.1287\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.1287\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.1287\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.1288\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.1289\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1293 - val_loss: 0.1287\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1293 - val_loss: 0.1287\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.1287\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1293 - val_loss: 0.1287\n",
      "2.5 2 2.0286958 2.501594\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.1160 - val_loss: 0.1090\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1090\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1090\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1089\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1090\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1089\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1091\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1090\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1090\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1090\n",
      "2.5 2.5 2.488491 2.4972022\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.1270 - val_loss: 0.1217\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1218\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1218\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1217\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1217\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1218\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1217\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1219\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1219\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1217\n",
      "2.5 3 2.5111766 3.0054803\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.1477 - val_loss: 0.1348\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1343 - val_loss: 0.1349\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1343 - val_loss: 0.1348\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1344 - val_loss: 0.1350\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1344 - val_loss: 0.1350\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1344 - val_loss: 0.1350\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1344 - val_loss: 0.1349\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1344 - val_loss: 0.1349\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1343 - val_loss: 0.1349\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1344 - val_loss: 0.1350\n",
      "2.5 3.5 2.4966986 3.5082495\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.1771 - val_loss: 0.1409\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1408 - val_loss: 0.1409\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1409 - val_loss: 0.1409\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1409 - val_loss: 0.1410\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1409 - val_loss: 0.1409\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1409 - val_loss: 0.1409\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1409 - val_loss: 0.1410\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1409 - val_loss: 0.1410\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1409 - val_loss: 0.1410\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1409 - val_loss: 0.1409\n",
      "2.5 4 2.5348744 3.9995432\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.2198 - val_loss: 0.1463\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1462\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1462\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1461\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1462\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1462\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1462\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1463\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1463\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1462\n",
      "2.5 4.5 2.5073977 4.5137763\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.3117 - val_loss: 0.1668\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1509\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1509\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1508\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1508\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1508\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1508\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1509\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1509\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1508\n",
      "2.5 5 2.513382 4.9881353\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 2ms/step - loss: 0.3959 - val_loss: 0.2698\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1852 - val_loss: 0.1557\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1554\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1554\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1555\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1554\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1555\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1557 - val_loss: 0.1554\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1554\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1555\n",
      "2.5 5.5 2.5392284 5.5182214\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 1s 2ms/step - loss: 0.4469 - val_loss: 0.3418\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.2420 - val_loss: 0.1678\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1597 - val_loss: 0.1591\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1591\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1592\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1592\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1591\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1591\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1592\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1591\n",
      "2.5 6 2.5251117 6.0261817\n",
      "Epoch 1/10\n",
      "173/173 [==============================] - 1s 3ms/step - loss: 0.8217 - val_loss: 0.7327\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.6294 - val_loss: 0.5464\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5286 - val_loss: 0.5179\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5145 - val_loss: 0.5099\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5080 - val_loss: 0.5055\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5053 - val_loss: 0.5042\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5043 - val_loss: 0.5035\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5039 - val_loss: 0.5035\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5038 - val_loss: 0.5033\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 0s 2ms/step - loss: 0.5038 - val_loss: 0.5034\n",
      "3 0.5 2.991205 7.9518857\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3165 - val_loss: 0.1780\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1788 - val_loss: 0.1780\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1780\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1780\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1780\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1783\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1781\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1780\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1782\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1780\n",
      "3 1 1.0099683 3.0223796\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.1688 - val_loss: 0.1521\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1530 - val_loss: 0.1522\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1530 - val_loss: 0.1521\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1530 - val_loss: 0.1522\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1530 - val_loss: 0.1521\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1530 - val_loss: 0.1521\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1530 - val_loss: 0.1523\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1530 - val_loss: 0.1523\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1530 - val_loss: 0.1522\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1531 - val_loss: 0.1521\n",
      "3 1.5 1.5213554 3.0255756\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.1373 - val_loss: 0.1375\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1374 - val_loss: 0.1374\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1373 - val_loss: 0.1375\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1373 - val_loss: 0.1372\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1374 - val_loss: 0.1374\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1373 - val_loss: 0.1373\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1373 - val_loss: 0.1373\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1374 - val_loss: 0.1372\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1374 - val_loss: 0.1372\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1373 - val_loss: 0.1373\n",
      "3 2 2.0320766 3.0148184\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.1282 - val_loss: 0.1238\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1238\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1238\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1225 - val_loss: 0.1238\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1238\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1238\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1239\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1238\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1227 - val_loss: 0.1239\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1239\n",
      "3 2.5 2.5262554 2.965192\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.1248 - val_loss: 0.1071\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1073\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1071\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1071\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1071\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1071\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1071\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1071\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1071\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1071\n",
      "3 3 3.0054333 3.004053\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.1504 - val_loss: 0.1189\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1189\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1189\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1190\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1190\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1190\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1190\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1189\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1189\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1190\n",
      "3 3.5 3.0207875 3.5164635\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.1947 - val_loss: 0.1346\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1346\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1347\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1346\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1347\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1347\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1348\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1346\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1347\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1347\n",
      "3 4 3.0014591 4.0109553\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.2560 - val_loss: 0.1379\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1376\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1376\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1377\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1376\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1376\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1376\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1376\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1376\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1376\n",
      "3 4.5 3.0127313 4.5290456\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 0.3203 - val_loss: 0.1666\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1469 - val_loss: 0.1455\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1455\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1456\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1456\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1456\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1456\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1455\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1455\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1456\n",
      "3 5 3.0130742 5.016049\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.3794 - val_loss: 0.2395\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1695 - val_loss: 0.1526\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 0.1526\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 0.1526\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 0.1526\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 0.1526\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 0.1526\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 0.1526\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 0.1526\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 0.1526\n",
      "3 5.5 3.0144002 5.48193\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.4166 - val_loss: 0.2795\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.1551\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1542 - val_loss: 0.1545\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1545\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1542 - val_loss: 0.1545\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1542 - val_loss: 0.1545\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1542 - val_loss: 0.1545\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1545\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1545\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1545\n",
      "3 6 3.0221262 6.0172873\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 0.8000 - val_loss: 0.6031\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6030\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6030\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6030\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6030\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6030\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6030\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6030\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6030\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 0s 2ms/step - loss: 0.6015 - val_loss: 0.6030\n",
      "3.5 0.5 3.4577434 3.689562\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.1774\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.1774\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.1774\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.1774\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.1774\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.1774\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.1773\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.1774\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.1776\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1796 - val_loss: 0.1774\n",
      "3.5 1 1.0164344 3.5068028\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1833 - val_loss: 0.1537\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1537\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1537\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1537\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1538\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1537\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1538\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1537\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1538\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1538\n",
      "3.5 1.5 1.5346197 3.505796\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.1488 - val_loss: 0.1425\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1422\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1422\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1441 - val_loss: 0.1422\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1422\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1422\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1422\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1424\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1422\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 0.1422\n",
      "3.5 2 2.0161848 3.488334\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.1467 - val_loss: 0.1338\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1331 - val_loss: 0.1338\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1332 - val_loss: 0.1338\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1332 - val_loss: 0.1338\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1332 - val_loss: 0.1338\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1331 - val_loss: 0.1338\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1332 - val_loss: 0.1339\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1332 - val_loss: 0.1338\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1332 - val_loss: 0.1339\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1332 - val_loss: 0.1339\n",
      "3.5 2.5 2.5170388 3.4731243\n",
      "Epoch 1/10\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 0.1492 - val_loss: 0.1184\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1187 - val_loss: 0.1182\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1184\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1187 - val_loss: 0.1182\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1183\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1182\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1182\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1187 - val_loss: 0.1183\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1183\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 0.1187 - val_loss: 0.1184\n",
      "3.5 3 2.9983544 3.4994059\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 2ms/step - loss: 0.1830 - val_loss: 0.1147\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1096 - val_loss: 0.1101\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1100\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1100\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1100\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1100\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1100\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1100\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1100\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.1101\n",
      "3.5 3.5 3.4956875 3.4889507\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.2462 - val_loss: 0.1347\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1237 - val_loss: 0.1228\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1227\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1227\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1227\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1228\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1228\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1227\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1228\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1227\n",
      "3.5 4 3.531091 3.9902914\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.3254 - val_loss: 0.1733\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1521 - val_loss: 0.1384\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.1356 - val_loss: 0.1345\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1346 - val_loss: 0.1346\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1345\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1345\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1345\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1345\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1345\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1345\n",
      "3.5 4.5 3.5272114 4.519797\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.2223\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2047 - val_loss: 0.1778\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1564 - val_loss: 0.1421\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1422 - val_loss: 0.1405\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1405\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1407\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1406\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1406\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1405\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1418 - val_loss: 0.1405\n",
      "3.5 5 3.5100012 5.011502\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 1s 2ms/step - loss: 0.4489 - val_loss: 0.2681\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2553 - val_loss: 0.2387\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2089 - val_loss: 0.1747\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1574 - val_loss: 0.1492\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1487 - val_loss: 0.1481\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1484 - val_loss: 0.1481\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1484 - val_loss: 0.1481\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1484 - val_loss: 0.1481\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1484 - val_loss: 0.1481\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1484 - val_loss: 0.1481\n",
      "3.5 5.5 3.5176547 5.5082703\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.4835 - val_loss: 0.2979\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2895 - val_loss: 0.2799\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2579 - val_loss: 0.2311\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1982 - val_loss: 0.1675\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1560 - val_loss: 0.1511\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.1502\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1502\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1502\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1502\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1501\n",
      "3.5 6 3.5129879 6.0320387\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.8778 - val_loss: 0.5090\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5095 - val_loss: 0.5076\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5076\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5076\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5076\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5076\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5076\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5076\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5076\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5077\n",
      "4 0.5 3.9272816 4.182773\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 2ms/step - loss: 0.4403 - val_loss: 0.1813\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1801 - val_loss: 0.1797\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1797\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.1796\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1796\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.1796\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1797\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1796\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1796\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1796\n",
      "4 1 1.0159961 4.0199523\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 3s 14ms/step - loss: 0.2258 - val_loss: 0.1573\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 3s 14ms/step - loss: 0.1584 - val_loss: 0.1571\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 3s 14ms/step - loss: 0.1583 - val_loss: 0.1571\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 3s 14ms/step - loss: 0.1583 - val_loss: 0.1571\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 3s 14ms/step - loss: 0.1584 - val_loss: 0.1571\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 3s 14ms/step - loss: 0.1584 - val_loss: 0.1571\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 3s 14ms/step - loss: 0.1584 - val_loss: 0.1571\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 2s 9ms/step - loss: 0.1583 - val_loss: 0.1571\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1584 - val_loss: 0.1570\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1583 - val_loss: 0.1571\n",
      "4 1.5 1.5214286 4.0258794\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.1734 - val_loss: 0.1476\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1476\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1476\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1477\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1477\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1476\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1476\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1476\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1476\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1481\n",
      "4 2 1.9905581 4.0195456\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.1760 - val_loss: 0.1392\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1394\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1392\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1392\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1392\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1392\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1393\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1392\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1402 - val_loss: 0.1393\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1392\n",
      "4 2.5 2.5249085 4.0071855\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.1937 - val_loss: 0.1321\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1321\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1321\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1321\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1321\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1323\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1321\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1322\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1321\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.1321\n",
      "4 3 3.0142093 3.9863546\n",
      "Epoch 1/10\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.2456 - val_loss: 0.1323\n",
      "Epoch 2/10\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.1225 - val_loss: 0.1208\n",
      "Epoch 3/10\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1206 - val_loss: 0.1208\n",
      "Epoch 4/10\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1206 - val_loss: 0.1208\n",
      "Epoch 5/10\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1206 - val_loss: 0.1207\n",
      "Epoch 6/10\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1206 - val_loss: 0.1208\n",
      "Epoch 7/10\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1206 - val_loss: 0.1208\n",
      "Epoch 8/10\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1206 - val_loss: 0.1207\n",
      "Epoch 9/10\n",
      "189/189 [==============================] - 3s 14ms/step - loss: 0.1206 - val_loss: 0.1208\n",
      "Epoch 10/10\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.1206 - val_loss: 0.1208\n",
      "4 3.5 3.5314355 3.9896586\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.3205 - val_loss: 0.1609\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1135\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.1115\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1113\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.1113\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.1113\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.1113\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.1113\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.1113\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.1113\n",
      "4 4 3.9916272 3.996141\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 0.1868\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 0.1268\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1242 - val_loss: 0.1247\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.1247\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.1247\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.1247\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.1247\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.1247\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.1247\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.1247\n",
      "4 4.5 4.009239 4.5030975\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 2ms/step - loss: 0.5100 - val_loss: 0.2422\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1769 - val_loss: 0.1484\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1370\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.1354\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1359 - val_loss: 0.1353\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1358 - val_loss: 0.1353\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1358 - val_loss: 0.1353\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1358 - val_loss: 0.1353\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1358 - val_loss: 0.1353\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1358 - val_loss: 0.1353\n",
      "4 5 4.030552 4.9962583\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 1s 2ms/step - loss: 0.5745 - val_loss: 0.2863\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2210 - val_loss: 0.1936\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1773 - val_loss: 0.1585\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1435\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1438 - val_loss: 0.1422\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1434 - val_loss: 0.1421\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1434 - val_loss: 0.1421\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1434 - val_loss: 0.1421\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1434 - val_loss: 0.1421\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1434 - val_loss: 0.1422\n",
      "4 5.5 4.013627 5.5084968\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 1s 2ms/step - loss: 0.6096 - val_loss: 0.3180\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2544 - val_loss: 0.2346\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2201 - val_loss: 0.2024\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1814 - val_loss: 0.1617\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1522 - val_loss: 0.1482\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1468 - val_loss: 0.1472\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.1472\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.1472\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.1472\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.1472\n",
      "4 6 4.0107865 6.0354643\n",
      "Epoch 1/10\n",
      "156/156 [==============================] - 1s 2ms/step - loss: 0.9822 - val_loss: 0.5347\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.4336\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4336\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4336\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4336\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4336\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4336\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4336\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4336\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4336\n",
      "4.5 0.5 4.3784432 4.644892\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 2ms/step - loss: 0.5384 - val_loss: 0.1966\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.1806\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.1805\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.1805\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.1805\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.1805\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.1805\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.1806\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.1805\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1823 - val_loss: 0.1805\n",
      "4.5 1 1.0159115 4.5146675\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 2ms/step - loss: 0.2822 - val_loss: 0.1616\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1592 - val_loss: 0.1566\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1566\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1566\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1566\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1567\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1566\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1566\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1566\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1568\n",
      "4.5 1.5 1.5351195 4.4998384\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 2ms/step - loss: 0.2118 - val_loss: 0.1514\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1510 - val_loss: 0.1506\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1510 - val_loss: 0.1506\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1511 - val_loss: 0.1506\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1509 - val_loss: 0.1506\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1510 - val_loss: 0.1506\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1510 - val_loss: 0.1515\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1510 - val_loss: 0.1506\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1510 - val_loss: 0.1508\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1510 - val_loss: 0.1507\n",
      "4.5 2 2.0351179 4.4994273\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.2165 - val_loss: 0.1448\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1447\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1448\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1447\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1447\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1449 - val_loss: 0.1447\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1447\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1449 - val_loss: 0.1448\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1449 - val_loss: 0.1448\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1449 - val_loss: 0.1451\n",
      "4.5 2.5 2.4854193 4.529391\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.2552 - val_loss: 0.1429\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.1425\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.1425\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.1425\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.1425\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.1425\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.1425\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.1425\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.1425\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1395 - val_loss: 0.1425\n",
      "4.5 3 3.0223515 4.500298\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 1s 2ms/step - loss: 0.3231 - val_loss: 0.1716\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1385\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1347 - val_loss: 0.1346\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1346\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1346\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1346\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1346\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1346\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1337 - val_loss: 0.1346\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1337 - val_loss: 0.1346\n",
      "4.5 3.5 3.5264838 4.5002646\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 1s 2ms/step - loss: 0.4133 - val_loss: 0.1870\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1481 - val_loss: 0.1266\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1239 - val_loss: 0.1243\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1243\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1243\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1243\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1243\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1243\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1243\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1243\n",
      "4.5 4 4.013939 4.504255\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 2ms/step - loss: 0.5173 - val_loss: 0.1845\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1640 - val_loss: 0.1421\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1161\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.1152\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.1151\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1150\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1150\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1150\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1150\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1150\n",
      "4.5 4.5 4.5017266 4.516884\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 2ms/step - loss: 0.6290 - val_loss: 0.2218\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1803 - val_loss: 0.1500\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1328 - val_loss: 0.1269\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1262\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1262\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1262\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1262\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1262\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1262\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1262\n",
      "4.5 5 4.515528 4.999113\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 2ms/step - loss: 0.7143 - val_loss: 0.2895\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.2157 - val_loss: 0.1629\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1425\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1383 - val_loss: 0.1390\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1367 - val_loss: 0.1385\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1366 - val_loss: 0.1385\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1366 - val_loss: 0.1385\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1366 - val_loss: 0.1385\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1366 - val_loss: 0.1385\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1366 - val_loss: 0.1385\n",
      "4.5 5.5 4.5189605 5.5253167\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 2ms/step - loss: 0.7540 - val_loss: 0.3257\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.2517 - val_loss: 0.1946\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.1662\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.1460\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.1407\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1401\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1398 - val_loss: 0.1400\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1398 - val_loss: 0.1401\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1398 - val_loss: 0.1400\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1398 - val_loss: 0.1400\n",
      "4.5 6 4.503919 6.0326366\n",
      "Epoch 1/10\n",
      "151/151 [==============================] - 1s 3ms/step - loss: 1.0490 - val_loss: 0.5572\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.4217 - val_loss: 0.3709\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3709\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3709\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3709\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3709\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.3710\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3709\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3709\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3709\n",
      "5 0.5 4.8434663 5.126603\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 1s 2ms/step - loss: 0.6211 - val_loss: 0.2448\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1997 - val_loss: 0.1840\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1835 - val_loss: 0.1836\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1834 - val_loss: 0.1836\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1834 - val_loss: 0.1836\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1834 - val_loss: 0.1836\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1834 - val_loss: 0.1836\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1834 - val_loss: 0.1836\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1834 - val_loss: 0.1836\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1834 - val_loss: 0.1836\n",
      "5 1 1.0194576 5.025462\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.2002\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1710 - val_loss: 0.1645\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1645\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1645\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1646\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1645\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1645\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1645\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1646\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1645\n",
      "5 1.5 1.5168847 5.021487\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 2ms/step - loss: 0.2695 - val_loss: 0.1700\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1577 - val_loss: 0.1585\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1584\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1584\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1586\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1585\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1585\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1585\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1584\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1585\n",
      "5 2 2.027399 5.0274277\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 2ms/step - loss: 0.3167 - val_loss: 0.1739\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1516 - val_loss: 0.1504\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1504\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1504\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1504\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1504\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1504\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1505\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1504\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1503\n",
      "5 2.5 2.5123212 5.0048623\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 2ms/step - loss: 0.3148 - val_loss: 0.1612\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1461\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1452 - val_loss: 0.1461\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1452 - val_loss: 0.1461\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1452 - val_loss: 0.1461\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1452 - val_loss: 0.1462\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1452 - val_loss: 0.1462\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1452 - val_loss: 0.1461\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1452 - val_loss: 0.1461\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1452 - val_loss: 0.1462\n",
      "5 3 3.0426013 5.0013638\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 2ms/step - loss: 0.3890 - val_loss: 0.2213\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2033 - val_loss: 0.1780\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1560 - val_loss: 0.1421\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1419 - val_loss: 0.1403\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1415 - val_loss: 0.1403\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1415 - val_loss: 0.1404\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1415 - val_loss: 0.1403\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1415 - val_loss: 0.1404\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1415 - val_loss: 0.1403\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1415 - val_loss: 0.1404\n",
      "5 3.5 3.4971528 5.0047255\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 2ms/step - loss: 0.5061 - val_loss: 0.2363\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1744 - val_loss: 0.1457\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1349\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1340 - val_loss: 0.1334\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1335 - val_loss: 0.1334\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.1334\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.1334\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.1334\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.1334\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.1334\n",
      "5 4 4.0241776 4.999903\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 1s 2ms/step - loss: 0.6263 - val_loss: 0.2190\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1799 - val_loss: 0.1487\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1329 - val_loss: 0.1262\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.1257\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.1257\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1257\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.1257\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.1257\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.1257\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.1257\n",
      "5 4.5 4.519847 4.9937916\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 1s 2ms/step - loss: 0.7429 - val_loss: 0.2146\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1799 - val_loss: 0.1605\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1278\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1207 - val_loss: 0.1174\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.1171\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1168 - val_loss: 0.1170\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1170\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1170\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1170\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1170\n",
      "5 5 4.9650345 5.0241942\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.8506 - val_loss: 0.2758\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2042 - val_loss: 0.1717\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1514 - val_loss: 0.1336\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1279 - val_loss: 0.1250\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1247\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1247\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1247\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1247\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1247\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1247\n",
      "5 5.5 5.004769 5.505489\n",
      "Epoch 1/10\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.9044 - val_loss: 0.3386\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2466 - val_loss: 0.1950\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1594 - val_loss: 0.1409\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1352 - val_loss: 0.1342\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1323 - val_loss: 0.1332\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1331\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1331\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1331\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1331\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1331\n",
      "5 6 5.0022006 6.0182276\n",
      "Epoch 1/10\n",
      "146/146 [==============================] - 1s 3ms/step - loss: 0.8378 - val_loss: 0.2927\n",
      "Epoch 2/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.2441 - val_loss: 0.2124\n",
      "Epoch 3/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.2046 - val_loss: 0.2027\n",
      "Epoch 4/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2024\n",
      "Epoch 5/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2024\n",
      "Epoch 6/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2024\n",
      "Epoch 7/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2024\n",
      "Epoch 8/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2024\n",
      "Epoch 9/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2024\n",
      "Epoch 10/10\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2024\n",
      "5.5 0.5 0.4544459 5.596171\n",
      "Epoch 1/10\n",
      "171/171 [==============================] - 1s 2ms/step - loss: 0.6717 - val_loss: 0.3009\n",
      "Epoch 2/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.2334 - val_loss: 0.1904\n",
      "Epoch 3/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1871 - val_loss: 0.1850\n",
      "Epoch 4/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1859 - val_loss: 0.1850\n",
      "Epoch 5/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1859 - val_loss: 0.1850\n",
      "Epoch 6/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1859 - val_loss: 0.1850\n",
      "Epoch 7/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1859 - val_loss: 0.1850\n",
      "Epoch 8/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1859 - val_loss: 0.1850\n",
      "Epoch 9/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1859 - val_loss: 0.1851\n",
      "Epoch 10/10\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 0.1859 - val_loss: 0.1851\n",
      "5.5 1 1.0362408 5.5363903\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.2554\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1918 - val_loss: 0.1673\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1659 - val_loss: 0.1664\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1657 - val_loss: 0.1664\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1657 - val_loss: 0.1664\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1657 - val_loss: 0.1664\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1657 - val_loss: 0.1664\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1657 - val_loss: 0.1664\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1657 - val_loss: 0.1665\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1658 - val_loss: 0.1664\n",
      "5.5 1.5 1.5263282 5.509689\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 2ms/step - loss: 0.3193 - val_loss: 0.2120\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1695 - val_loss: 0.1599\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1590 - val_loss: 0.1598\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.1598\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.1599\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.1599\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1590 - val_loss: 0.1598\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1590 - val_loss: 0.1598\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.1599\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.1598\n",
      "5.5 2 2.0329604 5.5084414\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 1s 2ms/step - loss: 0.3881 - val_loss: 0.2666\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1855 - val_loss: 0.1547\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1543\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1543\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1542\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1542\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1542\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1542\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1542\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1542\n",
      "5.5 2.5 2.5207503 5.520516\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 1s 2ms/step - loss: 0.3667 - val_loss: 0.2144\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1596 - val_loss: 0.1502\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1502\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1504\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1502\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1503\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1502\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1502\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1502\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1503\n",
      "5.5 3 3.0262523 5.509977\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 1s 2ms/step - loss: 0.4446 - val_loss: 0.2634\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2521 - val_loss: 0.2337\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2062 - val_loss: 0.1725\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1485\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1476\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1470 - val_loss: 0.1476\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1470 - val_loss: 0.1476\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1473 - val_loss: 0.1476\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1471 - val_loss: 0.1476\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.1470 - val_loss: 0.1476\n",
      "5.5 3.5 3.4985743 5.50664\n",
      "Epoch 1/10\n",
      "183/183 [==============================] - 1s 2ms/step - loss: 0.5700 - val_loss: 0.2867\n",
      "Epoch 2/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.2200 - val_loss: 0.1944\n",
      "Epoch 3/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1753 - val_loss: 0.1581\n",
      "Epoch 4/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1445\n",
      "Epoch 5/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1434 - val_loss: 0.1432\n",
      "Epoch 6/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1429 - val_loss: 0.1431\n",
      "Epoch 7/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1429 - val_loss: 0.1431\n",
      "Epoch 8/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1429 - val_loss: 0.1431\n",
      "Epoch 9/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1429 - val_loss: 0.1431\n",
      "Epoch 10/10\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.1429 - val_loss: 0.1431\n",
      "5.5 4 4.020901 5.512592\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 2ms/step - loss: 0.7123 - val_loss: 0.2866\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.2176 - val_loss: 0.1621\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1473 - val_loss: 0.1403\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1369\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.1364\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.1364\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.1364\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.1363 - val_loss: 0.1364\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.1364\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.1364\n",
      "5.5 4.5 4.5195084 5.524369\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 1s 2ms/step - loss: 0.8571 - val_loss: 0.2760\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2049 - val_loss: 0.1713\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1317\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.1236\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1242 - val_loss: 0.1233\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.1233\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.1233\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.1233\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.1233\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.1233\n",
      "5.5 5 5.000952 5.5074167\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 2ms/step - loss: 0.9689 - val_loss: 0.3766\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.2143 - val_loss: 0.1680\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1585 - val_loss: 0.1438\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 0.1223\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1158\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.1152\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.1152\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.1151\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.1151\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.1151\n",
      "5.5 5.5 5.44192 5.5557413\n",
      "Epoch 1/10\n",
      "174/174 [==============================] - 1s 2ms/step - loss: 1.0195 - val_loss: 0.4736\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.2534 - val_loss: 0.1768\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1612 - val_loss: 0.1459\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1340 - val_loss: 0.1240\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1209 - val_loss: 0.1194\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 0.1191\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1191\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1191\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1191\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1191\n",
      "5.5 6 5.50017 5.9884315\n",
      "Epoch 1/10\n",
      "141/141 [==============================] - 1s 3ms/step - loss: 0.7419 - val_loss: 0.3110\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.2702 - val_loss: 0.2300\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.2087 - val_loss: 0.1952\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.1956 - val_loss: 0.1930\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.1947 - val_loss: 0.1923\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.1928 - val_loss: 0.1869\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.1845 - val_loss: 0.1807\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.1831 - val_loss: 0.1807\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.1831 - val_loss: 0.1807\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.1831 - val_loss: 0.1807\n",
      "6 0.5 -0.013084436 6.079378\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - 1s 3ms/step - loss: 0.6948 - val_loss: 0.3437\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.2746 - val_loss: 0.2119\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1923 - val_loss: 0.1866\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1855 - val_loss: 0.1862\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1854 - val_loss: 0.1862\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1854 - val_loss: 0.1862\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1854 - val_loss: 0.1862\n",
      "Epoch 8/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1854 - val_loss: 0.1862\n",
      "Epoch 9/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1854 - val_loss: 0.1862\n",
      "Epoch 10/10\n",
      "166/166 [==============================] - 0s 2ms/step - loss: 0.1854 - val_loss: 0.1862\n",
      "6 1 1.0329654 6.043732\n",
      "Epoch 1/10\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 0.4361 - val_loss: 0.3039\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.2282 - val_loss: 0.1782\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1707 - val_loss: 0.1709\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1691 - val_loss: 0.1709\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1691 - val_loss: 0.1709\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1691 - val_loss: 0.1709\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1691 - val_loss: 0.1709\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1692 - val_loss: 0.1709\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1691 - val_loss: 0.1709\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1691 - val_loss: 0.1709\n",
      "6 1.5 1.531228 6.020751\n",
      "Epoch 1/10\n",
      "177/177 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.2669\n",
      "Epoch 2/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1965 - val_loss: 0.1647\n",
      "Epoch 3/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1618 - val_loss: 0.1623\n",
      "Epoch 4/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1615 - val_loss: 0.1623\n",
      "Epoch 5/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1615 - val_loss: 0.1623\n",
      "Epoch 6/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1615 - val_loss: 0.1626\n",
      "Epoch 7/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1615 - val_loss: 0.1627\n",
      "Epoch 8/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1615 - val_loss: 0.1624\n",
      "Epoch 9/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1615 - val_loss: 0.1623\n",
      "Epoch 10/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1615 - val_loss: 0.1623\n",
      "6 2 2.0266945 6.0020895\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4380 - val_loss: 0.3364\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2368 - val_loss: 0.1671\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1578 - val_loss: 0.1584\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1584\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1584\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1584\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1584\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1584\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1585\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1586\n",
      "6 2.5 2.502782 5.9915724\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.2818\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1976 - val_loss: 0.1534\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1526 - val_loss: 0.1524\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1524 - val_loss: 0.1525\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1525 - val_loss: 0.1525\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1525 - val_loss: 0.1524\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1525 - val_loss: 0.1524\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1525 - val_loss: 0.1524\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1525 - val_loss: 0.1525\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1525 - val_loss: 0.1524\n",
      "6 3 3.031739 6.011756\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4759 - val_loss: 0.2952\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.2767\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2561 - val_loss: 0.2308\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1971 - val_loss: 0.1669\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1557 - val_loss: 0.1511\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.1505\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1505\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1504\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1504\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1505\n",
      "6 3.5 3.5168025 6.018329\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6097 - val_loss: 0.3150\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2519 - val_loss: 0.2307\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.2174 - val_loss: 0.2011\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1801 - val_loss: 0.1616\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1518 - val_loss: 0.1475\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.1461\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1459 - val_loss: 0.1461\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1460\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1460\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1461\n",
      "6 4 3.9969168 6.023332\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 2ms/step - loss: 0.7494 - val_loss: 0.3213\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.2498 - val_loss: 0.1923\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1791 - val_loss: 0.1646\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1547 - val_loss: 0.1452\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.1402\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1398\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1398\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1398\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1398\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1398\n",
      "6 4.5 4.4995327 6.029265\n",
      "Epoch 1/10\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.9057 - val_loss: 0.3387\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.1953\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1601 - val_loss: 0.1422\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.1358\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1346\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1344\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1344\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1344\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1344\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1344\n",
      "6 5 5.009152 6.0153384\n",
      "Epoch 1/10\n",
      "174/174 [==============================] - 1s 2ms/step - loss: 1.0195 - val_loss: 0.4824\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.2544 - val_loss: 0.1786\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1619 - val_loss: 0.1469\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1250\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1215 - val_loss: 0.1196\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1196 - val_loss: 0.1193\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1193\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1193\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1193\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1193\n",
      "6 5.5 5.501779 6.0062027\n",
      "Epoch 1/10\n",
      "170/170 [==============================] - 1s 2ms/step - loss: 1.0645 - val_loss: 0.5854\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.1688\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1564 - val_loss: 0.1451\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.1298\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1237 - val_loss: 0.1151\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1134 - val_loss: 0.1100\n",
      "Epoch 7/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1111 - val_loss: 0.1096\n",
      "Epoch 8/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.1095\n",
      "Epoch 9/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.1095\n",
      "Epoch 10/10\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.1095\n",
      "6 6 5.9198833 6.0828505\n"
     ]
    }
   ],
   "source": [
    "xx = []\n",
    "mm = []\n",
    "for m1 in mass_range[1:]:\n",
    "        for m2 in mass_range[1:]:\n",
    "\n",
    "            #freeze layers\n",
    "            for l in model_all.layers:\n",
    "                l.trainable=False\n",
    "\n",
    "            #create simple models\n",
    "            model3 = createSimpleModel(2.)\n",
    "            model32 = createSimpleModel(3.)\n",
    "\n",
    "            #combine everything\n",
    "            inputs = tf.keras.Input(shape=(4,))\n",
    "            inputs2 = tf.keras.layers.concatenate([inputs,model3(tf.ones_like(inputs)[:,0]),model32(tf.ones_like(inputs)[:,0])])\n",
    "            hidden_layer_1 = model_all(inputs2)\n",
    "            model_all2 = Model(inputs = inputs, outputs = hidden_layer_1)\n",
    "            model_all2.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01))\n",
    "\n",
    "            x_vals_ = np.concatenate([x[0,0],x[m1,m2]])\n",
    "            y_vals_ = np.concatenate([np.ones(len(x[0,0])),np.zeros(len(x[m1,m2]))])\n",
    "            X_train_, X_val_, Y_train_, Y_val_ = train_test_split(x_vals_, y_vals_, test_size=0.5)\n",
    "            myhistory_hack_ = model_all2.fit(x_vals_[:,0:4], y_vals_, epochs=10,validation_data=(X_val_[:,0:4], Y_val_),batch_size=1024)\n",
    "            print(m1,m2,np.array(model_all2.trainable_weights).flatten()[0],np.array(model_all2.trainable_weights).flatten()[1])\n",
    "            xx += [[np.array(model_all2.trainable_weights).flatten()[0],np.array(model_all2.trainable_weights).flatten()[1]]]\n",
    "            mm += [[m1,m2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43403e1a-5362-4f51-bafb-6c950afa689a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5] [0.5009282 9.0266   ]\n",
      "[0.5 1. ] [1.0162501 6.8402267]\n",
      "[0.5 1.5] [1.5197958 7.1196375]\n",
      "[0.5 2. ] [2.018391  7.3301506]\n",
      "[0.5 2.5] [2.503654  7.5707154]\n",
      "[0.5 3. ] [2.9879217 7.7615304]\n",
      "[0.5 3.5] [3.4590018 3.6896212]\n",
      "[0.5 4. ] [3.9164639 4.187815 ]\n",
      "[0.5 4.5] [4.3715677 4.66682  ]\n",
      "[1.  0.5] [1.0178778 6.8189354]\n",
      "[1. 1.] [1.0128239 7.455266 ]\n",
      "[1.  1.5] [1.0717642 8.157131 ]\n",
      "[1. 2.] [2.0082774 6.7936416]\n",
      "[1.  2.5] [2.470603  2.5909207]\n",
      "[1.5 0.5] [1.5368409 7.1856747]\n",
      "[1.5 1. ] [1.0633861 8.313919 ]\n",
      "[2.  0.5] [2.0280135 7.4120927]\n",
      "[2. 1.] [2.0092247 6.7918754]\n",
      "[2.5 0.5] [2.5165713 7.703162 ]\n",
      "[2.5 1. ] [2.4736054 2.580866 ]\n",
      "[3.  0.5] [2.991205  7.9518857]\n",
      "[3.5 0.5] [3.4577434 3.689562 ]\n",
      "[4.  0.5] [3.9272816 4.182773 ]\n",
      "[4.5 0.5] [4.3784432 4.644892 ]\n",
      "[5.  0.5] [4.8434663 5.126603 ]\n",
      "[6.  0.5] [-0.01308444  6.079378  ]\n",
      "found both: 0.8194444444444444\n",
      "found one: 0.18055555555555555\n",
      "found none: 0.0\n"
     ]
    }
   ],
   "source": [
    "xx = np.array(xx)\n",
    "mm = np.array(mm)\n",
    "\n",
    "found_both = 0.\n",
    "found_one = 0.\n",
    "found_none = 0.\n",
    "for i in range(len(mm)):\n",
    "    diff1 = abs(mm[i][0]-xx[i][0])\n",
    "    diff2 = abs(mm[i][1]-xx[i][0])\n",
    "    diff3 = abs(mm[i][0]-xx[i][1])\n",
    "    diff4 = abs(mm[i][1]-xx[i][1])\n",
    "    diffs = [diff1,diff2,diff3,diff4]\n",
    "    if (diff1 < 0.2 and diff4 < 0.2) or (diff2 < 0.2 and diff3 < 0.2):\n",
    "        #print(mm[i],xx[i])\n",
    "        found_both+=1\n",
    "    elif (min(diffs) < 0.2):\n",
    "        print(mm[i],xx[i])\n",
    "        found_one+=1\n",
    "        pass\n",
    "    else:\n",
    "        print(mm[i],xx[i])\n",
    "        found_none+=1\n",
    "        pass\n",
    "print(\"found both:\",found_both/(found_both+found_one+found_none))\n",
    "print(\"found one:\",found_one/(found_both+found_one+found_none))\n",
    "print(\"found none:\",found_none/(found_both+found_one+found_none))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfaaa0-d2d5-452c-9533-7a7a29d24029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
