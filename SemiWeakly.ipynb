{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b6b372-c1fc-4bfc-bd57-cb869b56af0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649e940b-e9ff-4522-ae65-3b44946b38f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mass_range = [0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6]\n",
    "\n",
    "x = {}\n",
    "x_array_read = np.load(\"x_array.npy\",allow_pickle=True)\n",
    "mycounter = -1\n",
    "for m1 in mass_range:\n",
    "    for m2 in mass_range:\n",
    "        if (m1==0 and m2>0 or m2==0 and m1>0):\n",
    "            continue\n",
    "        mycounter+=1\n",
    "        x[m1,m2] = x_array_read[mycounter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1453c9ad-d296-4886-838e-bc087e209669",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals_all = np.load(\"x_vals_all.npy\")\n",
    "y_vals_all = np.load(\"y_vals_all.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36088d56-ff3f-4299-836c-edfcec98f996",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.08511704, -0.13951411,  0.29623825, -1.38625319,  0.5       ,\n",
       "         0.5       ],\n",
       "       [-0.99621376, -0.3906208 ,  1.87209617, -1.20087092,  0.5       ,\n",
       "         0.5       ],\n",
       "       [-1.10503705,  1.30397829,  1.37879233, -0.51460752,  0.5       ,\n",
       "         0.5       ],\n",
       "       ...,\n",
       "       [ 2.25225265, -1.04538567, -1.74062478, -0.42062581,  6.        ,\n",
       "         6.        ],\n",
       "       [ 1.9191695 , -0.87384445, -1.59395235, -2.25172332,  6.        ,\n",
       "         6.        ],\n",
       "       [ 0.04826932,  1.34560735, -0.34342313, -1.79483175,  6.        ,\n",
       "         6.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa4bae0-9bda-4d9b-abc3-bf77bae185f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b945de-3cce-4bc0-a517-afcb467a5cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_all_BCE = tf.keras.models.load_model(\"model_all_BCE_3_4096\")\n",
    "model_all_MSE = tf.keras.models.load_model(\"model_all_MSE_3_4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e39e348-2b2b-4234-acf1-49912b7b3b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createSimpleModel(weight):\n",
    "    input_layer = tf.keras.Input(shape=(1,))\n",
    "    simple_model = Dense(1,use_bias = False,activation=\"relu\",\n",
    "                         kernel_initializer=tf.keras.initializers.Constant(weight))(input_layer)\n",
    "    model = Model(inputs=input_layer, outputs=simple_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ea809-3fcf-489f-b5aa-246be0cdc50b",
   "metadata": {},
   "source": [
    "4 Features 2 Parameter Semi Weakly Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9059fbb5-4a5a-46f2-b1bd-93cdd273fcc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Fraction:  0.07\n",
      "30232 90698 2116 0.06999206139190262\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 11ms/step - loss: 0.2450 - val_loss: 0.2449\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2449 - val_loss: 0.2448\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2448 - val_loss: 0.2447\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2447 - val_loss: 0.2446\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2447 - val_loss: 0.2446\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2446 - val_loss: 0.2446\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2446 - val_loss: 0.2445\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2445 - val_loss: 0.2444\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2445 - val_loss: 0.2443\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2445 - val_loss: 0.2442\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2443 - val_loss: 0.2442\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2442 - val_loss: 0.2440\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2441 - val_loss: 0.2440\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2441 - val_loss: 0.2439\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2440 - val_loss: 0.2439\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2440 - val_loss: 0.2438\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2439 - val_loss: 0.2438\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2439 - val_loss: 0.2438\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2438 - val_loss: 0.2438\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2438 - val_loss: 0.2438\n",
      "4.5 6 3.1130736 4.5656056\n",
      "60/60 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "sig_list = []\n",
    "w1_list = []\n",
    "w2_list = []\n",
    "w3_list = []\n",
    "\n",
    "max_SIC1 = []\n",
    "max_SIC2 = []\n",
    "\n",
    "test_list = []\n",
    "\n",
    "epsilon = 1e-6\n",
    "\n",
    "sig_space = np.logspace(-3, -1, 20)\n",
    "#for sigfrac in sig_space:\n",
    "sigfrac = .07\n",
    "print(\"Signal Fraction: \", sigfrac)\n",
    "for l in model_all_MSE.layers:\n",
    "    l.trainable=False\n",
    "\n",
    "model3 = createSimpleModel(2)\n",
    "model32 = createSimpleModel(3)\n",
    "\n",
    "inputs_hold3 = tf.keras.Input(shape=(1,))\n",
    "simple_model3 = tf.exp(Dense(1,use_bias = False,activation='linear',kernel_initializer=tf.keras.initializers.Constant(-1))(inputs_hold3))\n",
    "model33 = Model(inputs = inputs_hold3, outputs = simple_model3)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(4,))\n",
    "inputs2 = tf.keras.layers.concatenate([inputs,model3(tf.ones_like(inputs)[:,0]),model32(tf.ones_like(inputs)[:,0])])\n",
    "hidden_layer_1 = model_all_MSE(inputs2)\n",
    "LLR = hidden_layer_1 / (1.-hidden_layer_1 + epsilon)\n",
    "LLR_xs = 1 + sigfrac * LLR - sigfrac\n",
    "#LLR_xs = 1. + model33(tf.ones_like(inputs)[:,0]) * LLR - model33(tf.ones_like(inputs)[:,0])\n",
    "ws = (LLR_xs / (1.+ LLR_xs))\n",
    "model_all2 = Model(inputs = inputs, outputs = ws)\n",
    "model_all2.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01))\n",
    "\n",
    "m1 = 4.5\n",
    "m2 = 6\n",
    "\n",
    "test_background = int(1/2 *len(x[0,0]))\n",
    "train_background = int(1/4 * len(x[0,0]))\n",
    "train_data = int(1/4 * len(x[0,0]))\n",
    "train_reference = int(1/4 * len(x[0,0]))\n",
    "#signal\n",
    "test_signal_length = int(1/2*len(x[m1,m2]))\n",
    "N = int(1/4 * (len(x[0,0])))\n",
    "signal = x[m1, m2][test_signal_length:test_signal_length + int(sigfrac*N)]\n",
    "\n",
    "x_vals_ = np.concatenate([x[0,0][test_background:],signal])\n",
    "#[reference (1), data_background (0), signal(0)]\n",
    "y_vals_ = np.concatenate([np.zeros(train_reference),np.ones(train_data + 1),np.ones(len(signal))])\n",
    "print(train_reference,len(x[0,0])-train_reference,len(x[m1,m2][0:int(sigfrac*train_reference)]),len(x[m1,m2][0:int(sigfrac*train_reference)])/train_reference)\n",
    "\n",
    "X_train_, X_val_, Y_train_, Y_val_ = train_test_split(x_vals_, y_vals_, test_size=0.5)\n",
    "\n",
    "myhistory_hack_ = model_all2.fit(X_train_[:,0:4], Y_train_, epochs=20,validation_data=(X_val_[:,0:4], Y_val_),batch_size=1024, callbacks = [es])\n",
    "\n",
    "sig_list+=[sigfrac]\n",
    "w1_list+=[model_all2.trainable_weights[0].numpy()[0][0]]\n",
    "w2_list+=[model_all2.trainable_weights[1].numpy()[0][0]]\n",
    "#w3_list+=[np.exp(model_all2.trainable_weights[2].numpy()[0][0])]\n",
    "\n",
    "print(m1, m2,model_all2.trainable_weights[0].numpy()[0][0],model_all2.trainable_weights[1].numpy()[0][0])\n",
    "\n",
    "scores = model_all2.predict(np.concatenate([x[0,0][0:train_background],x[m1,m2][0:test_signal_length]]),batch_size=1024)\n",
    "y = np.concatenate([np.zeros(train_background),np.ones(test_signal_length)])\n",
    "fpr, tpr, _ = metrics.roc_curve(y, scores)\n",
    "    \n",
    "    #CWOLA\n",
    "#     model_cwola = Sequential()\n",
    "#     model_cwola.add(Dense(128, input_dim=4, activation='relu'))\n",
    "#     model_cwola.add(Dense(128, activation='relu'))\n",
    "#     model_cwola.add(Dense(128, activation='relu'))\n",
    "#     model_cwola.add(Dense(1, activation='sigmoid'))\n",
    "#     model_cwola.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     myhistory_cwola = model_cwola.fit(X_train_[:,0:4], Y_train_, epochs=10,validation_data=(X_val_[:,0:4], Y_val_),batch_size=1024)\n",
    "    \n",
    "#     scores2 = model_cwola.predict(np.concatenate([x[0,0][0:test_background],x[m1,m2][0:test_signal_length]]),batch_size=1024)\n",
    "#     y2 = np.concatenate([np.zeros(test_background),np.ones(test_signal_length)])\n",
    "#     fpr2, tpr2, _ = metrics.roc_curve(y2, scores2)\n",
    "#     plt.plot(tpr,tpr/np.sqrt(fpr + epsilon))\n",
    "#     plt.plot(tpr2,tpr2/np.sqrt(fpr2 + epsilon))\n",
    "    \n",
    "#     max_SIC1+=[np.max(tpr/np.sqrt(fpr+epsilon))]\n",
    "#     max_SIC2+=[np.max(tpr2/np.sqrt(fpr2+epsilon))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69cbf17a-ccf6-4442-bd5d-a63ad3e48ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1_list = np.unique(x_vals_all[:, -2])\n",
    "m2_list = np.unique(x_vals_all[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89344c8d-758e-4688-abfa-86c34b65a9db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f91c9-6b4c-4f61-bf11-46a577d2fd79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Fraction:  0.05\n",
      "0.5 0.5\n",
      "30232 90698 1511 0.049980153479756546\n",
      "1937/1937 [==============================] - 2s 1ms/step - loss: 0.2508\n",
      "Signal Fraction:  0.05\n",
      "0.5 1.0\n",
      "30232 90698 1511 0.049980153479756546\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.2501\n",
      "Signal Fraction:  0.05\n",
      "0.5 1.5\n",
      "30232 90698 1511 0.049980153479756546\n",
      "1937/1937 [==============================] - 3s 1ms/step - loss: 0.2488\n",
      "Signal Fraction:  0.05\n",
      "0.5 2.0\n",
      "30232 90698 1511 0.049980153479756546\n",
      "1937/1937 [==============================] - 2s 1ms/step - loss: 0.2479\n",
      "Signal Fraction:  0.05\n",
      "0.5 2.5\n",
      "30232 90698 1511 0.049980153479756546\n",
      "1937/1937 [==============================] - 2s 1ms/step - loss: 0.2470\n",
      "Signal Fraction:  0.05\n",
      "0.5 3.0\n",
      "30232 90698 1511 0.049980153479756546\n",
      "1937/1937 [==============================] - 2s 1ms/step - loss: 0.2465\n",
      "Signal Fraction:  0.05\n",
      "0.5 3.5\n",
      "30232 90698 1511 0.049980153479756546\n",
      "1937/1937 [==============================] - 2s 1ms/step - loss: 0.2465\n",
      "Signal Fraction:  0.05\n",
      "0.5 4.0\n",
      "30232 90698 1511 0.049980153479756546\n",
      "1937/1937 [==============================] - 2s 1ms/step - loss: 0.2465\n",
      "Signal Fraction:  0.05\n",
      "0.5 4.5\n",
      "30232 90698 1511 0.049980153479756546\n",
      " 755/1937 [==========>...................] - ETA: 1s - loss: 0.2414"
     ]
    }
   ],
   "source": [
    "z = {}\n",
    "\n",
    "epsilon = 1e-6\n",
    "\n",
    "for w1 in m1_list:\n",
    "    for w2 in m2_list:        \n",
    "        sigfrac = 0.05\n",
    "        print(\"Signal Fraction: \", sigfrac)\n",
    "        for l in model_all_MSE.layers:\n",
    "            l.trainable=False\n",
    "            \n",
    "        print(w1, w2)\n",
    "\n",
    "        model3 = createSimpleModel(w1)\n",
    "        model32 = createSimpleModel(w2)\n",
    "\n",
    "        inputs_hold3 = tf.keras.Input(shape=(1,))\n",
    "        simple_model3 = tf.exp(Dense(1,use_bias = False,activation='linear',kernel_initializer=tf.keras.initializers.Constant(-1))(inputs_hold3))\n",
    "        model33 = Model(inputs = inputs_hold3, outputs = simple_model3)\n",
    "\n",
    "        inputs = tf.keras.Input(shape=(4,))\n",
    "        inputs2 = tf.keras.layers.concatenate([inputs,model3(tf.ones_like(inputs)[:,0]),model32(tf.ones_like(inputs)[:,0])])\n",
    "        hidden_layer_1 = model_all_MSE(inputs2)\n",
    "        LLR = hidden_layer_1 / (1.-hidden_layer_1 + epsilon)\n",
    "        LLR_xs = 1 + sigfrac*LLR - sigfrac\n",
    "        #LLR_xs = 1. + model33(tf.ones_like(inputs)[:,0]) * LLR\n",
    "        ws = LLR_xs / (1.+ LLR_xs)\n",
    "        model_all2 = Model(inputs = inputs, outputs = ws)\n",
    "        model_all2.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01))\n",
    "\n",
    "        m1 = 3\n",
    "        m2 = 4.5\n",
    "\n",
    "        test_background = int(1/2 *len(x[0,0]))\n",
    "        train_background = int(1/4 * len(x[0,0]))\n",
    "        train_data = int(1/4 * len(x[0,0]))\n",
    "        train_reference = int(1/4 * len(x[0,0]))\n",
    "        #signal\n",
    "        test_signal_length = int(1/2*len(x[m1,m2]))\n",
    "        N = int(1/4 * (len(x[0,0])))\n",
    "        signal = x[m1, m2][test_signal_length:test_signal_length + int(sigfrac*N)]\n",
    "\n",
    "        x_vals_ = np.concatenate([x[0,0][test_background:],signal])\n",
    "        #[reference (0), data_background (1), signal(1)]\n",
    "        y_vals_ = np.concatenate([np.zeros(train_reference),np.ones(train_data + 1),np.ones(len(signal))])\n",
    "        print(train_reference,len(x[0,0])-train_reference,len(x[m1,m2][0:int(sigfrac*train_reference)]),len(x[m1,m2][0:int(sigfrac*train_reference)])/train_reference)\n",
    "\n",
    "        X_train_, X_val_, Y_train_, Y_val_ = train_test_split(x_vals_, y_vals_, test_size=0.5)\n",
    "        \n",
    "        #myhistory_hack_ = model_all2.fit(X_train_[:,0:4], Y_train_, epochs=20,validation_data=(X_val_[:,0:4], Y_val_),batch_size=1024, callbacks = [es])\n",
    "                \n",
    "        z[w1, w2] = model_all2.evaluate(x_vals_, y_vals_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf770a-5d1b-47df-a342-bde9db475adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_list = []\n",
    "w1_list = []\n",
    "w2_list = []\n",
    "w3_list = []\n",
    "\n",
    "max_SIC1 = []\n",
    "max_SIC2 = []\n",
    "\n",
    "test_list = []\n",
    "\n",
    "epsilon = 1e-6\n",
    "\n",
    "sig_space = np.logspace(-3, -1, 20)\n",
    "for sigfrac in sig_space:\n",
    "    print(\"Signal Fraction: \", sigfrac)\n",
    "    for l in model_all_MSE.layers:\n",
    "        l.trainable=False\n",
    "\n",
    "    model3 = createSimpleModel(2)\n",
    "    model32 = createSimpleModel(3)\n",
    "\n",
    "    inputs_hold3 = tf.keras.Input(shape=(1,))\n",
    "    simple_model3 = tf.exp(Dense(1,use_bias = False,activation='linear',kernel_initializer=tf.keras.initializers.Constant(-1))(inputs_hold3))\n",
    "    model33 = Model(inputs = inputs_hold3, outputs = simple_model3)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(4,))\n",
    "    inputs2 = tf.keras.layers.concatenate([inputs,model3(tf.ones_like(inputs)[:,0]),model32(tf.ones_like(inputs)[:,0])])\n",
    "    hidden_layer_1 = model_all_MSE(inputs2)\n",
    "    LLR = hidden_layer_1 / (1.-hidden_layer_1 + epsilon)\n",
    "    LLR_xs = 1 + sigfrac * LLR - sigfrac\n",
    "    #LLR_xs = 1. + model33(tf.ones_like(inputs)[:,0]) * LLR - model33(tf.ones_like(inputs)[:,0])\n",
    "    ws = (LLR_xs / (1.+ LLR_xs))\n",
    "    model_all2 = Model(inputs = inputs, outputs = ws)\n",
    "    model_all2.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01))\n",
    "\n",
    "    m1 = 4.5\n",
    "    m2 = 6\n",
    "\n",
    "    test_background = int(1/2 *len(x[0,0]))\n",
    "    train_background = int(1/4 * len(x[0,0]))\n",
    "    train_data = int(1/4 * len(x[0,0]))\n",
    "    train_reference = int(1/4 * len(x[0,0]))\n",
    "    #signal\n",
    "    test_signal_length = int(1/2*len(x[m1,m2]))\n",
    "    N = int(1/4 * (len(x[0,0])))\n",
    "    signal = x[m1, m2][test_signal_length:test_signal_length + int(sigfrac*N)]\n",
    "\n",
    "    x_vals_ = np.concatenate([x[0,0][test_background:],signal])\n",
    "    #[reference (1), data_background (0), signal(0)]\n",
    "    y_vals_ = np.concatenate([np.zeros(train_reference),np.ones(train_data + 1),np.ones(len(signal))])\n",
    "    print(train_reference,len(x[0,0])-train_reference,len(x[m1,m2][0:int(sigfrac*train_reference)]),len(x[m1,m2][0:int(sigfrac*train_reference)])/train_reference)\n",
    "\n",
    "    X_train_, X_val_, Y_train_, Y_val_ = train_test_split(x_vals_, y_vals_, test_size=0.5)\n",
    "\n",
    "    myhistory_hack_ = model_all2.fit(X_train_[:,0:4], Y_train_, epochs=20,validation_data=(X_val_[:,0:4], Y_val_),batch_size=1024, callbacks = [es])\n",
    "\n",
    "    sig_list+=[sigfrac]\n",
    "    w1_list+=[model_all2.trainable_weights[0].numpy()[0][0]]\n",
    "    w2_list+=[model_all2.trainable_weights[1].numpy()[0][0]]\n",
    "    #w3_list+=[np.exp(model_all2.trainable_weights[2].numpy()[0][0])]\n",
    "\n",
    "    print(m1, m2,model_all2.trainable_weights[0].numpy()[0][0],model_all2.trainable_weights[1].numpy()[0][0])\n",
    "\n",
    "    scores = model_all2.predict(np.concatenate([x[0,0][0:train_background],x[m1,m2][0:test_signal_length]]),batch_size=1024)\n",
    "    y = np.concatenate([np.zeros(train_background),np.ones(test_signal_length)])\n",
    "    fpr, tpr, _ = metrics.roc_curve(y, scores)\n",
    "    \n",
    "    #CWOLA\n",
    "#     model_cwola = Sequential()\n",
    "#     model_cwola.add(Dense(128, input_dim=4, activation='relu'))\n",
    "#     model_cwola.add(Dense(128, activation='relu'))\n",
    "#     model_cwola.add(Dense(128, activation='relu'))\n",
    "#     model_cwola.add(Dense(1, activation='sigmoid'))\n",
    "#     model_cwola.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     myhistory_cwola = model_cwola.fit(X_train_[:,0:4], Y_train_, epochs=10,validation_data=(X_val_[:,0:4], Y_val_),batch_size=1024)\n",
    "    \n",
    "#     scores2 = model_cwola.predict(np.concatenate([x[0,0][0:test_background],x[m1,m2][0:test_signal_length]]),batch_size=1024)\n",
    "#     y2 = np.concatenate([np.zeros(test_background),np.ones(test_signal_length)])\n",
    "#     fpr2, tpr2, _ = metrics.roc_curve(y2, scores2)\n",
    "#     plt.plot(tpr,tpr/np.sqrt(fpr + epsilon))\n",
    "#     plt.plot(tpr2,tpr2/np.sqrt(fpr2 + epsilon))\n",
    "    \n",
    "#     max_SIC1+=[np.max(tpr/np.sqrt(fpr+epsilon))]\n",
    "#     max_SIC2+=[np.max(tpr2/np.sqrt(fpr2+epsilon))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59389ccc-9524-4d46-989c-4b7ae7fe735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sig_list,np.array(w1_list)*100)\n",
    "plt.plot(sig_list,np.array(w2_list)*100)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"S/B\")\n",
    "plt.ylabel(\"Fitted masses [GeV]\")\n",
    "plt.title(\"Trainable Weights vs Signal Fractions MSE (3 params)\")\n",
    "plt.axhline(m2 * 100,ls=\":\",color='orange')\n",
    "plt.axhline(m1 * 100,ls=\":\",color='blue')\n",
    "#plt.legend()\n",
    "plt.ylim([0,700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf7a4f-4c06-4da7-a696-740ae3b32477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sig_list,np.array(w3_list))\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(sig_list,sig_list,ls=\":\",color=\"black\")\n",
    "plt.xlabel(\"S/B\")\n",
    "plt.ylabel(\"Fitted S/B\")\n",
    "plt.title(\"S/B vs Fitted S/B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741031c-4b43-4563-b46e-469eb61d8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sig_list,max_SIC1,label=\"Weakly, Semisupervised\")\n",
    "plt.plot(sig_list,max_SIC2,label=\"Weakly Supervised\")\n",
    "plt.title(\"CWOLA vs Semi Weakly (Trainable mu)\")\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Signal region S/B\")\n",
    "plt.ylabel(\"max SIC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
