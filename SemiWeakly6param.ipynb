{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffffb324-ca98-4d22-96d1-a1485b89d69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Dense #Dropout, BatchNormalization\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0ac30dd-0f3f-4dff-a4b2-38129508630b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computemjj_pd(event):\n",
    "    px1 = event[[\"pxj1\"]].to_numpy()\n",
    "    py1 = event[[\"pyj1\"]].to_numpy()\n",
    "    pz1 = event[[\"pzj1\"]].to_numpy()\n",
    "    pE1 = np.sqrt(px1**2+py1**2+pz1**2+event[[\"mj1\"]].to_numpy()**2)\n",
    "    \n",
    "    px2 = event[[\"pxj2\"]].to_numpy()\n",
    "    py2 = event[[\"pyj2\"]].to_numpy()\n",
    "    pz2 = event[[\"pzj2\"]].to_numpy()\n",
    "    pE2 = np.sqrt(px1**2+py1**2+pz1**2+event[[\"mj2\"]].to_numpy()**2)\n",
    "    \n",
    "    m2 = (pE1+pE2)**2-(px1+px2)**2-(py1+py2)**2-(pz1+pz2)**2\n",
    "    return np.array(np.sqrt(m2)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ebabd60-9af8-424e-99c0-abb88c79b9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computemjj_txt(event):\n",
    "    pT1 = np.array([float(event[2*i][0]) for i in range(int(len(event)/2))])\n",
    "    eta1 = np.array([float(event[2*i][1]) for i in range(int(len(event)/2))])\n",
    "    phi1 = np.array([float(event[2*i][2]) for i in range(int(len(event)/2))])\n",
    "    m1 = np.array([float(event[2*i][3]) for i in range(int(len(event)/2))])\n",
    "    px1 = pT1*np.cos(phi1)\n",
    "    py1 = pT1*np.sin(phi1)\n",
    "    pz1 = pT1*np.sinh(eta1)\n",
    "    pE1 = np.sqrt(px1**2+py1**2+pz1**2+m1**2)\n",
    "    \n",
    "    pT2 = np.array([float(event[2*i+1][0]) for i in range(int(len(event)/2))])\n",
    "    eta2 = np.array([float(event[2*i+1][1]) for i in range(int(len(event)/2))])\n",
    "    phi2 = np.array([float(event[2*i+1][2]) for i in range(int(len(event)/2))])\n",
    "    m2 = np.array([float(event[2*i+1][3]) for i in range(int(len(event)/2))])\n",
    "    px2 = pT2*np.cos(phi2)\n",
    "    py2 = pT2*np.sin(phi2)\n",
    "    pz2 = pT2*np.sinh(eta2)\n",
    "    pE2 = np.sqrt(px2**2+py2**2+pz2**2+m2**2)\n",
    "    \n",
    "    m2 = (pE1+pE2)**2-(px1+px2)**2-(py1+py2)**2-(pz1+pz2)**2\n",
    "    return np.array(np.sqrt(m2)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d40e20ee-a221-40ed-b2f5-56cfde7e4283",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on ... 0 0 qq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2072305/3658239227.py:13: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.array(np.sqrt(m2)).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on ... 0 0 qqq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2072305/3658239227.py:13: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.array(np.sqrt(m2)).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on ... 0 0.5 qq\n",
      "on ... 0 0.5 qqq\n",
      "on ... 0 1 qq\n",
      "on ... 0 1 qqq\n",
      "on ... 0 1.5 qq\n",
      "on ... 0 1.5 qqq\n",
      "on ... 0 2 qq\n",
      "on ... 0 2 qqq\n",
      "on ... 0 2.5 qq\n",
      "on ... 0 2.5 qqq\n",
      "on ... 0 3 qq\n",
      "on ... 0 3 qqq\n",
      "on ... 0 3.5 qq\n",
      "on ... 0 3.5 qqq\n",
      "on ... 0 4 qq\n",
      "on ... 0 4 qqq\n",
      "on ... 0 4.5 qq\n",
      "on ... 0 4.5 qqq\n",
      "on ... 0 5 qq\n",
      "on ... 0 5 qqq\n",
      "on ... 0 5.5 qq\n",
      "on ... 0 5.5 qqq\n",
      "on ... 0 6 qq\n",
      "on ... 0 6 qqq\n",
      "on ... 0.5 0 qq\n",
      "on ... 0.5 0 qqq\n",
      "on ... 0.5 0.5 qq\n",
      "on ... 0.5 0.5 qqq\n",
      "on ... 0.5 1 qq\n",
      "on ... 0.5 1 qqq\n",
      "on ... 0.5 1.5 qq\n",
      "on ... 0.5 1.5 qqq\n",
      "on ... 0.5 2 qq\n",
      "on ... 0.5 2 qqq\n",
      "on ... 0.5 2.5 qq\n",
      "on ... 0.5 2.5 qqq\n",
      "on ... 0.5 3 qq\n",
      "on ... 0.5 3 qqq\n",
      "on ... 0.5 3.5 qq\n",
      "on ... 0.5 3.5 qqq\n",
      "on ... 0.5 4 qq\n",
      "on ... 0.5 4 qqq\n",
      "on ... 0.5 4.5 qq\n",
      "on ... 0.5 4.5 qqq\n",
      "on ... 0.5 5 qq\n",
      "on ... 0.5 5 qqq\n",
      "on ... 0.5 5.5 qq\n",
      "on ... 0.5 5.5 qqq\n",
      "on ... 0.5 6 qq\n",
      "on ... 0.5 6 qqq\n",
      "on ... 1 0 qq\n",
      "on ... 1 0 qqq\n",
      "on ... 1 0.5 qq\n",
      "on ... 1 0.5 qqq\n",
      "on ... 1 1 qq\n",
      "on ... 1 1 qqq\n",
      "on ... 1 1.5 qq\n",
      "on ... 1 1.5 qqq\n",
      "on ... 1 2 qq\n",
      "on ... 1 2 qqq\n",
      "on ... 1 2.5 qq\n",
      "on ... 1 2.5 qqq\n",
      "on ... 1 3 qq\n",
      "on ... 1 3 qqq\n",
      "on ... 1 3.5 qq\n",
      "on ... 1 3.5 qqq\n",
      "on ... 1 4 qq\n",
      "on ... 1 4 qqq\n",
      "on ... 1 4.5 qq\n",
      "on ... 1 4.5 qqq\n",
      "on ... 1 5 qq\n",
      "on ... 1 5 qqq\n",
      "on ... 1 5.5 qq\n",
      "on ... 1 5.5 qqq\n",
      "on ... 1 6 qq\n",
      "on ... 1 6 qqq\n",
      "on ... 1.5 0 qq\n",
      "on ... 1.5 0 qqq\n",
      "on ... 1.5 0.5 qq\n",
      "on ... 1.5 0.5 qqq\n",
      "on ... 1.5 1 qq\n",
      "on ... 1.5 1 qqq\n",
      "on ... 1.5 1.5 qq\n",
      "on ... 1.5 1.5 qqq\n",
      "on ... 1.5 2 qq\n",
      "on ... 1.5 2 qqq\n",
      "on ... 1.5 2.5 qq\n",
      "on ... 1.5 2.5 qqq\n",
      "on ... 1.5 3 qq\n",
      "on ... 1.5 3 qqq\n",
      "on ... 1.5 3.5 qq\n",
      "on ... 1.5 3.5 qqq\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 95\u001b[0m\n\u001b[1;32m     93\u001b[0m ts2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([ltau3_m_m\u001b[38;5;241m/\u001b[39m(ltau2_m_m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),stau3_m_m\u001b[38;5;241m/\u001b[39m(stau2_m_m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.001\u001b[39m)],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     94\u001b[0m order1 \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39margmax(ms[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ms))]\n\u001b[0;32m---> 95\u001b[0m order2 \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39margmin(ms[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ms))]\n\u001b[1;32m     96\u001b[0m mJ1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([ms[i][order1[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ms))])\n\u001b[1;32m     97\u001b[0m mJ2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([ms[i][order2[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ms))])\n",
      "Cell \u001b[0;32mIn[36], line 95\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     93\u001b[0m ts2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([ltau3_m_m\u001b[38;5;241m/\u001b[39m(ltau2_m_m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),stau3_m_m\u001b[38;5;241m/\u001b[39m(stau2_m_m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.001\u001b[39m)],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     94\u001b[0m order1 \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39margmax(ms[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ms))]\n\u001b[0;32m---> 95\u001b[0m order2 \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ms))]\n\u001b[1;32m     96\u001b[0m mJ1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([ms[i][order1[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ms))])\n\u001b[1;32m     97\u001b[0m mJ2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([ms[i][order2[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ms))])\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1312\u001b[0m, in \u001b[0;36margmin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;124;03mReturns the indices of the minimum values along an axis.\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if (True): #This step is slow, so I am saving the output.  Can set this to True if you want to recompute.\n",
    "    lmass_vec = {}\n",
    "    x = {}\n",
    "    mjjs = {}\n",
    "\n",
    "    mu_m = 0.\n",
    "    mu_t = 0.\n",
    "    mu_t2 = 0.\n",
    "    sd_m = 0.\n",
    "    sd_t = 0.\n",
    "    sd_t2 = 0.\n",
    "\n",
    "    for m1 in [0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6]:\n",
    "        for m2 in [0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6]:\n",
    "            for qq in ['qq','qqq']:\n",
    "\n",
    "                print(\"on ...\",m1,m2,qq)\n",
    "\n",
    "                ltau1_m_m = []\n",
    "                ltau2_m_m = []\n",
    "                ltau3_m_m = []\n",
    "                stau1_m_m = []\n",
    "                stau2_m_m = []\n",
    "                stau3_m_m = []\n",
    "                if (m1>0 and m2>0):\n",
    "                    myfile = open(\"/global/cfs/projectdirs/m3246/AnomalyDetection/ILC/Delphes-3.5.0/LHCO_RnD_qq/LHCO_RnD_qq_\"+str(int(m1*100))+\"_\"+str(int(100*m2))+\".txt\")\n",
    "                    if (qq=='qqq'):\n",
    "                        myfile = open(\"/global/cfs/projectdirs/m3246/AnomalyDetection/ILC/Delphes-3.5.0/LHCO_RnD_qqq/LHCO_RnD_qqq2_\"+str(int(m1*100))+\"_\"+str(int(100*m2))+\".txt\")\n",
    "                    jets_m_m = []\n",
    "                    for line in myfile:\n",
    "                        jets_m_m+=[line.split(\"J\")[1].split(\"P\")[0].split()]\n",
    "                        pass\n",
    "                    ljet_m_m = [jets_m_m[2*n] for n in range(int(len(jets_m_m)/2))]\n",
    "                    sjet_m_m = [jets_m_m[2*n+1] for n in range(int(len(jets_m_m)/2))]\n",
    "\n",
    "                    lmass_m_m = np.array([float(ljet_m_m[i][3]) for i in range(len(ljet_m_m))])/1000.\n",
    "                    smass_m_m = np.array([float(sjet_m_m[i][3]) for i in range(len(sjet_m_m))])/1000.\n",
    "\n",
    "                    ltau1_m_m = np.array([float(ljet_m_m[i][5]) for i in range(len(ljet_m_m))])\n",
    "                    ltau2_m_m = np.array([float(ljet_m_m[i][6]) for i in range(len(ljet_m_m))])\n",
    "                    ltau3_m_m = np.array([float(ljet_m_m[i][7]) for i in range(len(ljet_m_m))])\n",
    "\n",
    "                    stau1_m_m = np.array([float(sjet_m_m[i][5]) for i in range(len(ljet_m_m))])\n",
    "                    stau2_m_m = np.array([float(sjet_m_m[i][6]) for i in range(len(ljet_m_m))])\n",
    "                    stau3_m_m = np.array([float(sjet_m_m[i][7]) for i in range(len(ljet_m_m))])\n",
    "\n",
    "                    mjj = computemjj_txt(jets_m_m)/1000.\n",
    "                    mjjs[m1,m2] = mjj\n",
    "                    passcut = (mjj > 3.3) * (mjj < 3.7)\n",
    "                    lmass_m_m = lmass_m_m[passcut]\n",
    "                    smass_m_m = smass_m_m[passcut]\n",
    "                    ltau1_m_m = ltau1_m_m[passcut]\n",
    "                    ltau2_m_m = ltau2_m_m[passcut]\n",
    "                    ltau3_m_m = ltau3_m_m[passcut]\n",
    "                    stau1_m_m = stau1_m_m[passcut]\n",
    "                    stau2_m_m = stau2_m_m[passcut]\n",
    "                    stau3_m_m = stau3_m_m[passcut]\n",
    "                    pass\n",
    "                elif m1==0 and m2==0:\n",
    "                    df_QCD = pd.read_hdf(\"/global/cfs/projectdirs/m3246/AnomalyDetection/LHCO/events_anomalydetection_DelphesPythia8_v2_qcd_features.h5\")\n",
    "                    lmass_m_m = np.array(df_QCD[[\"mj1\"]]).flatten()/1000.\n",
    "                    smass_m_m = np.array(df_QCD[[\"mj2\"]]).flatten()/1000.\n",
    "                    ltau1_m_m = np.array(df_QCD[[\"tau1j1\"]]).flatten()\n",
    "                    ltau2_m_m = np.array(df_QCD[[\"tau2j1\"]]).flatten()\n",
    "                    ltau3_m_m = np.array(df_QCD[[\"tau3j1\"]]).flatten()\n",
    "                    stau1_m_m = np.array(df_QCD[[\"tau1j2\"]]).flatten()\n",
    "                    stau2_m_m = np.array(df_QCD[[\"tau2j2\"]]).flatten()\n",
    "                    stau3_m_m = np.array(df_QCD[[\"tau3j2\"]]).flatten()\n",
    "                    mjj = computemjj_pd(df_QCD)/1000.\n",
    "                    mjjs[m1,m2] = mjj\n",
    "                    passcut = (mjj > 3.3) * (mjj < 3.7)\n",
    "                    lmass_m_m = lmass_m_m[passcut]\n",
    "                    smass_m_m = smass_m_m[passcut]\n",
    "                    ltau1_m_m = ltau1_m_m[passcut]\n",
    "                    ltau2_m_m = ltau2_m_m[passcut]\n",
    "                    ltau3_m_m = ltau3_m_m[passcut]\n",
    "                    stau1_m_m = stau1_m_m[passcut]\n",
    "                    stau2_m_m = stau2_m_m[passcut]\n",
    "                    stau3_m_m = stau3_m_m[passcut]\n",
    "\n",
    "                    mu_m = np.mean(lmass_m_m)\n",
    "                    mu_t = np.mean(ltau2_m_m/(ltau1_m_m+0.0001))\n",
    "                    mu_t2 = np.mean(ltau3_m_m/(ltau2_m_m+0.0001))\n",
    "                    sd_m = np.std(lmass_m_m)\n",
    "                    sd_t = np.std(ltau2_m_m/(ltau1_m_m+0.0001))\n",
    "                    sd_t2 = np.std(ltau3_m_m/(ltau2_m_m+0.0001))\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                ms = np.stack([lmass_m_m,smass_m_m],axis=1)\n",
    "                ts = np.stack([ltau2_m_m/(ltau1_m_m+0.0001),stau2_m_m/(stau1_m_m+0.001)],axis=1)\n",
    "                ts2 = np.stack([ltau3_m_m/(ltau2_m_m+0.0001),stau3_m_m/(stau2_m_m+0.001)],axis=1)\n",
    "                order1 = [np.argmax(ms[i]) for i in range(len(ms))]\n",
    "                order2 = [np.argmin(ms[i]) for i in range(len(ms))]\n",
    "                mJ1 = np.array([ms[i][order1[i]] for i in range(len(ms))])\n",
    "                mJ2 = np.array([ms[i][order2[i]] for i in range(len(ms))])\n",
    "                x[m1,m2,qq] = np.stack([(mJ2 - mu_m)/sd_m,\n",
    "                                        ((mJ1 - mJ2) - mu_m)/sd_m,\n",
    "                                        ([ts[i][order2[i]] for i in range(len(ts))] - mu_t)/sd_t,\n",
    "                                        ([ts[i][order1[i]] for i in range(len(ts))] - mu_t)/sd_t,\n",
    "                                        ([ts2[i][order2[i]] for i in range(len(ts2))] - mu_t2)/sd_t2,\n",
    "                                        ([ts2[i][order1[i]] for i in range(len(ts2))] - mu_t2)/sd_t2],axis=1)\n",
    "                lmass_vec[m1,m2]=lmass_m_m\n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    x_array = []\n",
    "    for m1 in [0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6]:\n",
    "        for m2 in [0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6]:\n",
    "            for qq in ['qq','qqq']:\n",
    "                if (m1==0 and m2>0 or m2==0 and m1>0):\n",
    "                    continue\n",
    "                x_array+=[x[m1,m2,qq]]\n",
    "np.save(\"x_array_qq\",x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f0c591-9637-4220-9e45-f3d331e24a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_vals_qq = np.load(\"/global/cfs/projectdirs/m3246/AnomalyDetection/LHCO/x_vals_qq.npy\")\n",
    "y_vals_qq = np.load(\"/global/cfs/projectdirs/m3246/AnomalyDetection/LHCO/y_vals_qq.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c36e24f9-409e-434d-b950-f421ad2522b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_qq, X_val_qq, Y_train_qq, Y_val_qq = train_test_split(x_vals_qq, y_vals_qq, test_size=0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0433688c-31d2-424b-bb31-95820f914b38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 12:35:40.796000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-15 12:35:41.961268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12919 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:c3:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model_qq = tf.keras.models.load_model('models/model_qq_BCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7ffd765-28fc-414e-ac19-f0a8b6835546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mass_range = [0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb3d21c1-0277-406b-a510-170ed04aa6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = {}\n",
    "x_array_read = np.load(\"/global/cfs/projectdirs/m3246/AnomalyDetection/LHCO/x_vals_qq.npy\",allow_pickle=True)\n",
    "mycounter = -1\n",
    "for m1 in mass_range:\n",
    "    for m2 in mass_range:\n",
    "        if (m1==0 and m2>0 or m2==0 and m1>0):\n",
    "            continue\n",
    "        mycounter+=1\n",
    "        x[m1,m2] = x_array_read[mycounter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4e5a159-d2f4-4cfb-90dd-45726733ef38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96b6ed12-c552-4c88-8651-d55b9a96e2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m m1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3.5\u001b[39m\n\u001b[1;32m     54\u001b[0m m2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5.5\u001b[39m\n\u001b[0;32m---> 56\u001b[0m test_background \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mx\u001b[49m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     57\u001b[0m train_background \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(x[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     58\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(x[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "initial_learning_rate = 0.05 #placeholder till callback\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=30*3, decay_rate=0.8, staircase=True\n",
    ")\n",
    "\n",
    "epsilon = 1e-6\n",
    "\n",
    "xx = []\n",
    "yy = []\n",
    "zz = []\n",
    "ww = []\n",
    "\n",
    "msic1 = []\n",
    "msic2 = []\n",
    "\n",
    "for sigfrac in np.logspace(-3,-1,10):\n",
    "    print(sigfrac)\n",
    "    #sigfrac = 0.05\n",
    "    if (sigfrac > 0.5):\n",
    "        continue\n",
    "\n",
    "    for l in model_qq.layers:\n",
    "        l.trainable=False\n",
    "        \n",
    "    w1 = 2\n",
    "    w2 = 3\n",
    "\n",
    "    inputs_hold = tf.keras.Input(shape=(1,))\n",
    "    simple_model = Dense(1,use_bias = False,activation='relu',kernel_initializer=tf.keras.initializers.Constant(w1))(inputs_hold)\n",
    "    model3 = Model(inputs = inputs_hold, outputs = simple_model)\n",
    "\n",
    "    inputs_hold2 = tf.keras.Input(shape=(1,))\n",
    "    simple_model2 = Dense(1,use_bias = False,activation='relu',kernel_initializer=tf.keras.initializers.Constant(w2))(inputs_hold2)\n",
    "    model32 = Model(inputs = inputs_hold2, outputs = simple_model2)\n",
    "    \n",
    "    inputs_hold3 = tf.keras.Input(shape=(1,))\n",
    "    simple_model3 = tf.exp(Dense(1,use_bias = False,activation='linear',kernel_initializer=tf.keras.initializers.Constant(-1))(inputs_hold3))\n",
    "    model33 = Model(inputs = inputs_hold3, outputs = simple_model3)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(6,))\n",
    "    inputs2 = tf.keras.layers.concatenate([inputs,model3(tf.ones_like(inputs)[:,0]),model32(tf.ones_like(inputs)[:,0])])\n",
    "    hidden_layer_1 = model_qq(inputs2)\n",
    "    LLR = hidden_layer_1 / (1.-hidden_layer_1+epsilon)\n",
    "    LLR_xs = 1.+sigfrac*LLR-sigfrac\n",
    "    #LLR_xs = 1.+model33(tf.ones_like(inputs)[:,0])*LLR\n",
    "    backtoprob = LLR_xs / (1.+LLR_xs+0.0001)\n",
    "    model_all2 = Model(inputs = inputs, outputs = backtoprob)\n",
    "    model_all2.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01))\n",
    "\n",
    "    m1 = 3.5\n",
    "    m2 = 5.5\n",
    "\n",
    "    test_background = int(1/2 *len(x[0,0]))\n",
    "    train_background = int(1/4 * len(x[0,0]))\n",
    "    train_data = int(1/4 * len(x[0,0]))\n",
    "    train_reference = int(1/4 * len(x[0,0]))\n",
    "    #signal\n",
    "    test_signal_length = int(1/2*len(x[m1,m2]))\n",
    "    sig_frac = sigfrac\n",
    "\n",
    "    x_vals_ = np.concatenate([x[0,0][test_background:],x[m1,m2,qq][test_signal_length:test_signal_length+int(sig_frac*tot)]])\n",
    "    y_vals_ = np.concatenate([np.zeros(train_set_reference),np.ones(train_set_data),np.ones(len(x[m1,m2][test_set_sig:test_set_sig+int(sig_frac*tot)]))])\n",
    "\n",
    "    print(tot,len(x[0,0])-tot,len(x[m1,m2][0:int(sig_frac*tot)]),len(x[m1,m2][0:int(sig_frac*tot)])/tot)\n",
    "\n",
    "    X_train_, X_val_, Y_train_, Y_val_ = train_test_split(x_vals_, y_vals_, test_size=0.5)\n",
    "    \n",
    "    myhistory_hack_ = model_all2.fit(X_train_[:,0:6], Y_train_, epochs=20,validation_data=(X_val_[:,0:6], Y_val_),batch_size=1024)\n",
    "    print(m1,m2,model_all2.trainable_weights[0].numpy()[0][0],model_all2.trainable_weights[1].numpy()[0][0])\n",
    "    xx+=[sigfrac]\n",
    "    yy+=[model_all2.trainable_weights[0].numpy()[0][0]]\n",
    "    zz+=[model_all2.trainable_weights[1].numpy()[0][0]]\n",
    "    ww+=[np.exp(model_all2.trainable_weights[2].numpy()[0][0])]\n",
    "    scores = model_all2.predict(np.concatenate([x[0,0][0:test_set_back],x[m1,m2][0:test_set_sig]]),batch_size=1024)\n",
    "    y = np.concatenate([np.zeros(test_set_back),np.ones(test_set_sig)])\n",
    "    fpr, tpr, _ = metrics.roc_curve(y, scores)    \n",
    "    \n",
    "#     model_cwola = Sequential()\n",
    "#     model_cwola.add(Dense(128, input_dim=6, activation='relu'))\n",
    "#     model_cwola.add(Dense(128, activation='relu'))\n",
    "#     model_cwola.add(Dense(128, activation='relu'))\n",
    "#     model_cwola.add(Dense(1, activation='sigmoid'))\n",
    "#     model_cwola.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     myhistory_cwola = model_cwola.fit(X_train_[:,0:6], Y_train_, epochs=10,validation_data=(X_val_[:,0:6], Y_val_),batch_size=1024)\n",
    "    \n",
    "#     scores2 = model_cwola.predict(np.concatenate([x[0,0][0:test_set_back],x[m1,m2][0:test_set_sig]]),batch_size=1024)\n",
    "#     y2 = np.concatenate([np.zeros(test_set_back),np.ones(test_set_sig)])\n",
    "#     fpr2, tpr2, _ = metrics.roc_curve(y2, scores2)\n",
    "#     plt.plot(tpr,tpr/np.sqrt(fpr+0.0001))\n",
    "#     plt.plot(tpr2,tpr2/np.sqrt(fpr2+0.0001))\n",
    "    \n",
    "#     msic1+=[np.max(tpr/np.sqrt(fpr+0.0001))]\n",
    "#     msic2+=[np.max(tpr2/np.sqrt(fpr2+0.0001))]\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf842b-1c8b-4d3c-9027-f91755aeeb0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
